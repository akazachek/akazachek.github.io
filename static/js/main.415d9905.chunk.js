(this["webpackJsonpakazachek.github.io"]=this["webpackJsonpakazachek.github.io"]||[]).push([[0],{32:function(e,t,a){},33:function(e,t,a){},42:function(e,t,a){"use strict";a.r(t);var i=a(1),n=a(2),s=a.n(n),o=a(25),r=a.n(o),h=(a(32),a(33),a(18)),l=a(8),c=a(4),d=a(7),m=a(6),u=a(5),b=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(e){var i;return Object(c.a)(this,a),(i=t.call(this,e)).state={classes:"hvr-sweep-to-right"},i}return Object(d.a)(a,[{key:"componentDidMount",value:function(){"Who Am I?"===this.props.item&&this.setState({classes:"hvr-sweep-to-right navActive"})}},{key:"render",value:function(){return Object(i.jsx)("li",{id:this.props.item,class:this.state.classes,children:Object(i.jsx)(h.b,{to:this.props.tolink,onClick:this.props.click.bind(this,this.props.item),children:this.props.item})})}}]),a}(n.Component),f=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(e){var i;return Object(c.a)(this,a),(i=t.call(this,e)).handleClick=function(e){i.state.NavActiveItem.length>0&&document.getElementById(i.state.NavActiveItem).classList.remove("navActive"),i.setState({NavActiveItem:e},(function(){document.getElementById(i.state.NavActiveItem).classList.add("navActive")}))},i.state={NavActiveItem:"Who Am I?"},i}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsx)("div",{class:"navContainer centredBox",children:Object(i.jsx)("nav",{children:Object(i.jsxs)("ul",{children:[Object(i.jsx)(b,{item:"Who Am I?",tolink:"/",click:this.handleClick}),Object(i.jsx)(b,{item:"Posts",tolink:"/Posts",click:this.handleClick}),Object(i.jsx)(b,{item:"Contact",tolink:"/Contact",click:this.handleClick})]})})})}}]),a}(n.Component),p=a(19),g=function(){var e=Object(n.useState)(window.innerWidth),t=Object(p.a)(e,2),a=t[0],i=t[1],s=function(){i(window.innerWidth)};return Object(n.useEffect)((function(){return window.addEventListener("resize",s),function(){window.removeEventListener("resize",s)}}),{}),a<=768},j=a.p+"static/media/me.5a56aa7d.jpg",y=a.p+"static/media/shortcv.033996e3.pdf";var w=function(){var e=g()?"above":"to the left";return Object(i.jsx)("div",{className:"coDiv",children:Object(i.jsxs)("div",{className:"about centredBox leftMarginWide",id:"aboutSec",children:[Object(i.jsx)("img",{src:j,alt:"Headshot",className:"pfp"}),Object(i.jsx)("br",{}),Object(i.jsx)("h1",{children:" Hey, I'm Alex! "}),Object(i.jsxs)("h3",{style:{paddingTop:"1vh"},children:[" ","I just finished the second year of my undergraduate at"," ",Object(i.jsx)("a",{className:"linkPurple",href:"https://www.uwo.ca/",children:"UWO"})," ","in mathematics and data science."]}),Object(i.jsx)("br",{}),Object(i.jsxs)("p",{children:["I enjoy anything mathematical. Broadly, I'm most interested in geometric and analytical subjects, and my favourite coursework has been in complex analysis and statistics. This summer, I'm doing an undergraduate research project under"," ",Object(i.jsx)("a",{className:"linkPurple",href:"https://www.math.uwo.ca/faculty/barron/barron.html",children:"Dr. Tatyana Barron"})," ","through an NSERC USRA. The project is broadly in quantum information theory, examining the geometry of density matrices and how it may be related to various notions of entanglement."]}),Object(i.jsxs)("p",{children:["I'm also involved with the mathematics community in other ways. Currently, I'm a committee member for the upcoming"," ",Object(i.jsx)("a",{className:"linkPurple",href:"https://cumc.math.ca/2021/",children:"2021 CUMC"}),", Canada's largest mathematics conference for undergraduates. My biggest role is designing and maintaining the new website. During the school year, I have an executive role on"," ",Object(i.jsx)("a",{className:"linkPurple",href:"https://www.uwo.ca/math/undergraduate/current_students/macaw/index.html",children:"MaCAW"}),", the official club of Western's mathematics department. I help write and grade our biweekly contests, and organize our once-a-semester student seminars."]}),Object(i.jsxs)("p",{children:["Outside of mathematics, I have an interest in linguistics. I'm intrigued by how different languages communicate the same ideas. One of my favourite examples is describing colour: Japanese doesn't distinguish between ",Object(i.jsx)("i",{children:"green"})," and ",Object(i.jsx)("i",{children:"blue"})," like English, and instead treats both as \u9752\u3044, whereas Russian further separates"," ",Object(i.jsx)("i",{children:"blue"})," and ",Object(i.jsx)("i",{children:"light blue"})," as ",Object(i.jsx)("i",{children:"\u0441\u0438\u043d\u0438\u0439"})," and ",Object(i.jsx)("i",{children:"\u0433\u043e\u043b\u0443\u0431\u043e\u0439"}),". Incidentally, I know (varying degrees of) those 3 languages."]}),Object(i.jsx)("p",{children:"I also enjoy designing things. I find front-end web development fun for that reason; this website is written in React.js. Similarly, I like tinkering with \\(\\LaTeX\\), despite its constantly overfull hboxes."}),Object(i.jsxs)("p",{children:["Feel free to read my blog posts or get in touch with me on my socials, both of which are ",e,". I hope you enjoy your stay. Food and drink is not provided."]}),Object(i.jsxs)("p",{className:"cv",children:[" ","My resume is available"," ",Object(i.jsx)("a",{className:"linkPurple",href:y,children:"here"}),". Last updated ","2021-06-21","."]})]})})},v=a(24),x=function(e){var t=Object(n.useState)(!1),a=Object(p.a)(t,2),s=a[0],o=a[1],r=Object(v.b)(s,null,{from:{zIndex:-1,opacity:0,transform:"translateX(-30vw)"},enter:{zIndex:-1,opacity:1,transform:"translateX(0vw)"},leave:{zIndex:-1,opacity:0,transform:"translateX(-30vw)"}});function h(){o((function(e){return!e}))}return Object(i.jsxs)("div",{children:[Object(i.jsxs)("li",{className:s?"postPreview postOpen":"postPreview",id:e.date,onClick:h,children:[Object(i.jsx)("table",{className:"postHead",children:Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"postTitle",children:Object(i.jsx)("h2",{children:e.name})}),Object(i.jsx)("td",{className:"postDate",children:Object(i.jsx)("h4",{children:e.date})})]})}),Object(i.jsx)("div",{children:Object(i.jsx)("p",{id:e.dummyID,className:"postSummary",children:e.summary})})]}),r.map((function(t){var a=t.item,n=t.key,s=t.props;return a&&Object(i.jsxs)(v.a.div,{className:"post",style:s,children:[e.full,Object(i.jsx)("button",{className:"postEndButton hvr-overline-from-right leftMargin",onClick:h,children:"Hide Post"})]},n)}))]})},$=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsxs)("table",{className:"figureContainer",children:[Object(i.jsx)("tr",{children:Object(i.jsx)("td",{className:"figure centredBox leftMarginWide",children:Object(i.jsx)("img",{src:this.props.src,alt:this.props.caption})})}),Object(i.jsx)("tr",{children:Object(i.jsx)("td",{className:"caption",children:Object(i.jsxs)("h4",{children:["Figure ",this.props.no,": ",this.props.caption]})})})]})}}]),a}(n.Component),_=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(e){var i;return Object(c.a)(this,a),(i=t.call(this,e)).state={theoremTitle:null==i.props.name?null==i.props.no?"Theorem. ":"Theorem "+e.no+". ":null==i.props.no?"Theorem ("+e.name+"). ":"Theorem "+e.no+" ("+e.name+"). "},i}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsx)("div",{class:"theorem",children:Object(i.jsxs)("p",{children:[Object(i.jsx)("strong",{children:this.state.theoremTitle}),Object(i.jsx)("i",{children:this.props.statement})]})})}}]),a}(n.Component),k=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsx)("div",{class:"proof",children:Object(i.jsxs)("p",{children:[Object(i.jsx)("i",{children:"Proof. "}),this.props.proof,Object(i.jsx)("span",{style:{float:"right"},children:"\\(\\square\\)"})]})})}}]),a}(n.Component),O=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"componentDidMount",value:function(){window.KaTeXRender()}},{key:"render",value:function(){return Object(i.jsxs)("div",{class:"postContent leftMargin",children:[Object(i.jsx)("p",{children:"In middle school I wanted to be a physicist. The motivating factor was quantum mechanics, or at least my pop science understanding of it. Entangled particles! Quantum tunneling! Superpositions! Of course, I didn't actually understand anything, being many years away from learning the mathematical prerequisites, but it still marked a general cardinal direction on my academic map. As the years went on, my interests slowly veered from the physics to the mathematics, abstracting all the way to mathematical logic and the various set theories. I later grew to find these subjects too callous and symbolic, returning to where I am now with more geometric interests. My work this summer, however, brought me back in some sense to where it all started: quantum physics. This time my perspective was purely mathematical, with no care for the pop science which originally set me on my journey. This mathematics is what I'm going to write about today, specifically that of entanglement."}),Object(i.jsxs)("p",{children:["The concept of entanglement, morally, seeks to formalize the situation in which the combination of parts may only be understood as just that - a combination; one cannot infer, fully, what the component parts are. The setting for our story is the ",Object(i.jsx)("strong",{children:"tensor product"}),". Its construction begins with a desire for ",Object(i.jsx)("strong",{children:"bilinearity"})," ","over vector spaces. Given two vectors spaces ","\\(U,V\\)"," over"," ","\\(F\\)",", we would like a third vector space, say ","\\(W\\)",", for which there exists a map ","\\(T\\colon U\\times V\\to W\\)"," such that for any ","\\(\\lambda\\in F,u_1,u_2\\in U,v_1,v_2\\in V\\)"," we have","\\[T\\left(\\lambda u_1,v_1\\right)=\\lambda T(u_1,v_1)=T(u_1,\\lambda v_1)\\]","\\[T\\left(u_1+u_2,v_1+v_2\\right)=T(u_1,v_1+v_2)+T(u_2,v_1+v_2)=T(u_1,v_1)+T(u_1,v_2)+T(u_2,v_1)+T(u_2,v_2).\\]","That is, ","\\(T\\)"," is linear in both components. So, fix bases"," ","\\(\\{e_i\\},\\{f_i\\}\\)"," of ","\\(U,V\\)",", respectively, and consider some scalars ","\\(\\alpha_i,\\beta_i\\in F\\)",". What we then need from our tensor product ","\\(W\\)"," is for","\\[T\\left(\\sum_i \\alpha_i e_i,\\sum_i\\beta_i f_i\\right)=\\sum_{i,j}\\alpha_i\\beta_j T(e_i,f_j).\\]","In order to accomplish this, we define the formal symbol"," ","\\(e_i\\otimes f_j\\coloneqq T(e_i,f_j)\\)","; this is our tensor, and the vector space ","\\(W\\eqqcolon U\\otimes V\\)"," is composed of linear combinations of these symbols. This construction is actually universal, in the sense that given any other bilinear construction on"," ","\\(U\\times V\\)",", we can uniquely describe it in terms of this"," ","\\(U\\otimes V\\)","."]}),Object(i.jsxs)("p",{children:["There may be apprehension to us defining ","\\(U\\otimes V\\)"," in terms of some explicit bases. There is indeed an equivalent definition of the tensor product as a quotient space with respect to a bilinearity relation, however this basis-free construction is less useful in our current context, hence it will not be shown. As an aside, there is something I find quite comedic in defining tensors as the symbols themselves, but I'm not quite sure what."]}),Object(i.jsxs)("p",{children:["Something important to note is that given a vector"," ","\\(t\\in U\\otimes V\\)",", we cannot necessarily write"," ","\\(t=u\\otimes v\\)"," for some ","\\(u\\in U,v\\in V\\)",". Vectors for which this is possible are called ",Object(i.jsx)("strong",{children:"decomposable"}),". Two other facts are that if ","\\(\\{e_i\\},\\{f_i\\}\\)"," are orthonormal bases for ","\\(U,V\\)",", then"," ","\\(\\{e_i\\otimes f_j\\}\\)"," will be an orthonormal basis for"," ","\\(U\\otimes V\\)",". Of course, orthonormality implies an inner product, and indeed one exists, given by","\\[\\langle e_i\\otimes f_j,e_k\\otimes f_\\ell\\rangle_{U\\otimes V}= \\langle e_i,e_k\\rangle_U\\langle f_j,f_\\ell\\rangle_V\\]","extended to non-basis vectors."]}),Object(i.jsxs)("p",{children:["We can also bring linear transforms over to the tensor product. Specifically, given linear maps ","\\(\\sigma\\colon U\\to U'\\)"," and"," ","\\(\\tau\\colon V\\to V'\\)",", we may define the linear map"," ","\\(\\sigma\\otimes\\tau\\colon U\\otimes V\\to U'\\otimes V'\\)"," by"," ","\n          \\[\n            (\\sigma\\otimes\\tau)(u\\otimes v)=\\sigma u\\otimes\\tau v.\n          \\]\n          ","There is a simple matrix representation of this new linear map, given by the ",Object(i.jsx)("strong",{children:"Kronecker product"})," of matrices. Fixing two bases ","\\(\\{e_1,\\dots,e_n\\},\\{f_i\\}\\)"," of ","\\(U,V\\)"," and representing ","\\(\\sigma,\\tau\\)"," with respect to them, the block matrix","\\[\n              \\sigma\\otimes\\tau=\\begin{pmatrix}\\sigma_{11}\\tau & \\cdots & \\sigma_{1n}\\tau\\\\\n              \\vdots & \\ddots &\\vdots \\\\\n              \\sigma_{n1}\\tau & \\cdots & \\sigma_{nn}\\tau\n              \\end{pmatrix}\n          \\]","gives the matrix of ","\\(\\sigma\\otimes\\tau\\)"," with respect to the"," ",Object(i.jsx)("strong",{children:"lexicographically-ordered"})," basis","\\[\n          (e_i\\otimes f_j : e_i \\otimes f_j \\leq e_k\\otimes f_\\ell \\textrm{ if } i < k \\textrm{ or } i=k, j<\\ell ).\n          \\]"]}),Object(i.jsxs)("p",{children:["With the setting understood, we move on to our story's characters. Recall a vector space ","\\(V\\)"," equipped with an inner product"," ","\\(\\langle\\cdot,\\cdot\\rangle\\)"," induces a norm"," ","\\(\\|\\cdot\\|\\)"," by"," ","\\(\\|v\\|=\\sqrt{\\langle v,v\\rangle}\\)",". If the associated metric space is complete, ","\\(V\\)"," is a"," ",Object(i.jsx)("strong",{children:"Hilbert space"}),". This definition comes from functional analysis, however, and so is slightly overkill for us, as we will only look at finite-dimensional spaces (where we always have completion). The canonical Hilbert space is ","\\(\\mathbb{C}^n\\)"," equipped with the standard inner product."]}),Object(i.jsxs)("p",{children:["Our parts will be operators over Hilbert spaces, and our combinations will be their tensor products. We will first go over what kind of operators we are considering. Consider a Hilbert space"," ","\\(\\mathcal{H}\\)"," lying over the field ","\\(\\mathbb{F}\\)",". The"," ",Object(i.jsx)("strong",{children:"dual space"})," ","\\(\\mathcal{H}^\\ast\\)"," is the set of"," ",Object(i.jsx)("strong",{children:"linear functionals"}),", linear maps"," ","\\(\\mathcal{H}\\to\\mathbb{F}\\)","."]}),Object(i.jsx)(_,{no:"1",name:"Riesz\u2013Fr\xe9chet",statement:"\r Consider some \\(\\varphi\\in\\mathcal{H}^\\ast\\). Then, there exists a unique \\(f_{\\varphi}\\in\\mathcal{H}\\) such that \\(\\varphi(x)=\\langle x,f_{\\varphi}\\rangle\\) for every \\(x\\in\\mathcal{H}\\)."}),Object(i.jsx)(k,{proof:"\r Let \\(\\{e_1,\\dots,e_n\\}\\) be an orthonormal basis of \\(\\mathcal{H}\\). Then, using properties of orthonormality and linear functionals, for arbitrary \\(x\\) we have\r \\[\r \\varphi(x)=\\varphi\\left(\\sum_{i=1}^n \\langle x,e_i\\rangle e_i\\right)=\\sum_{i=1}^n\\langle x,e_i\\rangle\\varphi(e_i)=\\sum_{i=1}^n \\langle x,\\overline{\\varphi(e_i)}e_i\\rangle=\\left\\langle x,\\sum_{i=1}^n\\overline{\\varphi(e_i)}e_i\\right\\rangle. \r \\]\r Let us take the latter component as a candidate for \\(f_{\\varphi}\\) (indeed, observe it is independent of \\(x\\)). For uniqueness, suppose there is some other satisfactory \\(g_{\\varphi}\\) such that\r \\[\r \\langle x,f_{\\varphi}\\rangle=\\varphi(x)=\\langle x,g_{\\varphi}\\rangle.\r \\]\r Then,\r \\[\r \\langle x,f_{\\varphi}\\rangle-\\langle x,g_{\\varphi}\\rangle =\\langle x,f_{\\varphi}-g_{\\varphi}\\rangle=0\r \\]\r and it remains only to consider \\(x=0\\) to see \\(f_{\\varphi}=g_{\\varphi}\\)."}),Object(i.jsxs)("p",{children:["There is a subtly in the above theorem and its proof, namely in regards to the assumption that ","\\(\\mathcal{H}\\)"," is finite-dimensional. The theorem is (partially) true in infinite-dimensional Hilbert spaces (the requirement"," ","\\(\\varphi\\)"," be continuous must be appended), however the proof technique must change as there are no orthonormal bases in such spaces. A further remark, for those familiar with Dirac notation, is that the above theorem legitmizes the identification of a unique bra"," ","\\(\\langle \\psi |\\)"," for each ket ","\\(|\\psi\\rangle\\)","."]}),Object(i.jsxs)("p",{children:["This theorem lets us define the ",Object(i.jsx)("strong",{children:"adjoint"}),". Fix a linear operator ","\\(T\\)"," on ","\\(\\mathcal{H}\\)"," and some vector"," ","\\(y\\in\\mathcal{H}\\)",". The map"," ","\\(x\\mapsto\\langle T x,y\\rangle\\)"," defines a linear functional, and hence we obtain a unique ","\\(T_y\\in\\mathcal{H}\\)"," such that"," ","\\(x\\mapsto \\langle x, T_y\\rangle\\)",". We use this process to define the linear map ","\\(T^\\ast\\)"," by"," ","\\(T^\\ast y\\coloneqq T_y\\)",". Equivalently, ","\\(T^\\ast\\)"," is the unique linear operator such that"," ","\\(\\langle Tx,y\\rangle=\\langle x,T^\\ast y\\rangle\\)"," for all"," ","\\(x,y\\in\\mathcal{H}\\)",". When ","\\(T\\)"," is a matrix,"," ","\\(T^\\ast\\)"," is given by conjugate transposition. If"," ","\\(T=T^\\ast\\)",", we say ","\\(T\\)"," is"," ",Object(i.jsx)("strong",{children:"self-adjoint"})," (or ",Object(i.jsx)("strong",{children:"Hermitian"}),")."]}),Object(i.jsxs)("p",{children:["We need one more definition: a linear operator is called"," ",Object(i.jsx)("strong",{children:"positive"})," if its ",Object(i.jsx)("strong",{children:"spectrum"})," (in finite dimensions, precisely its set of eigenvalues) is entirely non-negative. When working with matrices,"," ",Object(i.jsx)("strong",{children:"positive-semidefinite"})," is often seen instead. At last, we arrive at ",Object(i.jsx)("strong",{children:"density operators"})," over a Hilbert space (correspondingly, ",Object(i.jsx)("strong",{children:"density matrices"}),", and also"," ",Object(i.jsx)("strong",{children:"states"}),"), the set of self-adjoint positive operators with unit trace."]}),Object(i.jsxs)("p",{children:["As we will be working over finite-dimensional complex vector spaces (and note"," ","\\(\\mathbb{C}^m\\otimes\\mathbb{C}^n\\cong\\mathbb{C}^{mn}\\)","), we will make constant (implicit) appeals to the following spectral theorem. The proof is not hard, but it involves introducing another theorem (that of Schur), which is slightly out-of-scope. The statement may actually be strengthened from just self-adjoint operators to normal operators, however this is similarly digressive."]}),Object(i.jsx)(_,{no:"2",statement:"\r Every self-adjoint linear operator over a finite-dimensional complex vector space has a diagonal matrix of its eigenvalues with respect to its orthonormal set of eigenvectors."}),Object(i.jsxs)("p",{children:["This means given any state, say ","\\(\\rho\\)",", we may take its eigenvectors ","\\(\\{v_i\\}\\)"," and eigenvalues"," ","\\(\\{\\lambda_i\\}\\)",", and write its"," ",Object(i.jsx)("strong",{children:"eigendecomposition"}),"\\[\n          \\rho=\\sum_i \\lambda_i P_{v_i}\n        \\]","where ","\\(P_{v}\\)"," is the orthogonal projection onto the one-dimensional subspace spanned by ","\\(v\\)",". Due to the definition of state, each ","\\(\\lambda_i\\geq 0\\)"," and"," ","\\(\\sum_i \\lambda_i=1\\)",". In general, given any set of coefficients ","\\(p_i\\geq 0\\)"," for ","\\(i=1,\\dots,k\\)"," such that"," ","\\(\\sum_{i=1}^k p_i=1\\)",", and a set of unit vectors"," ","\\(\\{u_1,\\dots, u_k\\}\\)",", we call","\\[\n          \\sum_{i=1}^k p_i P_{u_i}\n        \\]","an ",Object(i.jsx)("strong",{children:"ensemble"}),". These representation of a state as an ensemble is generally not unique (not even in length!), due to the following."]}),Object(i.jsx)(_,{no:"3",name:"Schr\xf6dinger",statement:"\r Consider a state \\(\\rho\\) represented by the ensemble \\(\\sum_{i=1}^k p_iP_{u_i}\\). Then, we may also write \\(\\rho\\) as the ensemble \\(\\sum_{j=1}^\\ell q_iP_{v_i}\\) if and only if there exists some unitary \\(\\ell\\)-by-\\(\\ell\\) matrix \\(U\\) such that \\[\r v_i=\\frac{1}{\\sqrt{q_i}}\\sum_{j=1}^k U_{ij}\\sqrt{p_j}u_j.\r \\]"}),Object(i.jsxs)("p",{children:["As a reminder, a matrix ","\\(U\\)"," is ",Object(i.jsx)("strong",{children:"unitary"})," if"," ","\\(U^\\ast=U^{-1}\\)",". One situation where the ensemble representation is unique is if ","\\(\\rho\\)"," itself is a projector (that is, ","\\(\\rho=P_v\\)"," for some unit vector ","\\(v\\)","). This follows immediately from the defining properties of states. Such"," ","\\(\\rho\\)"," are called ",Object(i.jsx)("strong",{children:"pure"}),". States which are not pure are ",Object(i.jsx)("strong",{children:"mixed"}),"."]}),Object(i.jsxs)("p",{children:["We will now travel toward the tensor product, wherein resides entanglement. For the remainder of this post, unless otherwise stated,"," ","\\(\\mathcal{H}=\\mathcal{H}_m\\otimes\\mathcal{H}_n\\)"," where"," ","\\(\\mathcal{H}_m\\)"," is a Hilbert space of dimension ","\\(m\\)",". As ","\\(\\mathcal{H}\\)"," itself is a Hilbert space, the notion of pure and mixed states remains identical. However, we may now have the ability to describe states in ","\\(\\mathcal{H}\\)"," in terms of states in ","\\(\\mathcal{H}_m\\)"," and ","\\(\\mathcal{H}_n\\)",". Given some ","\\(\\rho\\)"," over ","\\(\\mathcal{H}\\)",", if we can write","\\[\n            \\rho=\\sum_i p_i\\sigma_i\\otimes\\tau_i\n            \\]","where ","\\(p_i\\geq 0\\)"," and ","\\(\\sum_i p_i=1\\)",", and the"," ","\\(\\sigma_i,\\tau_i\\)"," are themselves pure states in the component Hilbert spaces, we call ","\\(\\rho\\)"," ",Object(i.jsx)("strong",{children:"separable"})," (or ",Object(i.jsx)("strong",{children:"disentangled"}),"). If a state is not separable, it is ",Object(i.jsx)("strong",{children:"entangled"}),". Note that the case where the ","\\(\\sigma_i,\\tau_i\\)"," are instead mixed actually describes the same set (the proof for this hinges on Carath\xe9odory's result for convex hulls and the compactness of pure states in the component Hilbert spaces), so purity is assumed without loss of generality."]}),Object(i.jsxs)("p",{children:["Now, how do we determine if a state is entangled or separable? Moreover, are there different levels of entanglement? Unfortunately, there is no nice answer to either of these questions. Given an arbitrary state, there is no straightforward process to determine its separability (of course, some special cases exist, e.g. the Peres\u2013Horodecki critereon for"," ","\\(\\mathcal{H}_m\\otimes\\mathcal{H}_n\\)"," when"," ","\\(mn\\leq 6\\)","). There are also multiple mutually-inconsistent ways to measure levels of entanglement; two such measures will be our focus today."]}),Object(i.jsxs)("p",{children:["Before we discuss them, let us precisely define what we mean by measure. Such a map on states over ","\\(\\mathcal{H}\\)",", call it"," ","\\(E\\)",", must satisfy three properties. Firstly, that"," ","\\(E(\\rho)=0\\)"," if and only if ","\\(\\rho\\)"," is separable. Secondly, ","\\(E\\)"," must be invariant under"," ",Object(i.jsx)("strong",{children:"locally unitary operations"}),", meaning that if given unitary ","\\(U\\in\\mathcal{H}_m\\)"," and"," ","\\(V\\in\\mathcal{H}_n\\)",", then"," ","\\[E(\\rho)=E((U\\otimes V)\\rho(U^\\ast\\otimes V^\\ast)).\\]"," We also require ",Object(i.jsx)("strong",{children:"convexity"}),", meaning for any"," ","\\(\\alpha\\in [0,1]\\)"," we have","\\[E(\\alpha\\rho +(1-\\alpha)\\sigma)\\leq \\alpha E(\\rho)+(1-\\alpha)E(\\sigma).\\]","The reason for the first property is obvious. The latter two are related to the physical motivation behind the postulates of quantum mechanics, as well as state geometry. It should also be noted that this list is a bare minimum. There are several other desirable properties (e.g. continuity), however the difficulty in constructing such maps, known as ",Object(i.jsx)("strong",{children:"entanglement measures"}),", means we cannot be too picky and demand everything at once. In fact, it is usually extremely hard to determine whether an entanglement measure has these extra properties, given how tricky they are to work with (as we will soon see)."]}),Object(i.jsxs)("p",{children:["The construction of our first entanglement measure begins on pure states. We start with a definition. Given two linear operators"," ","\\(S,T\\)"," over ","\\(\\mathcal{H}_m,\\mathcal{H}_n\\)",", the"," ",Object(i.jsx)("strong",{children:"partial trace"})," of ","\\(S\\otimes T\\)"," is"," ","\\[\\operatorname{tr}_2(S\\otimes T)=\\operatorname{tr}(T)S,\\]","extended linearly. Then, the ",Object(i.jsx)("strong",{children:"entanglement entropy"})," of a unit vector ","\\(v\\in\\mathcal{H}\\)"," is","\\[E(v)=-\\sum_{\\lambda_i \\in\\,\\operatorname{spec}\\operatorname{tr}_2 P_v}\\lambda_i\\ln\\lambda_i\\]","with the convention ","\\(\\ln 0=0\\)",". There exists a nicer, more explicit formula, which also shows it does not matter which partial trace we use in the definition (i.e. ","\\(\\operatorname{tr}_1\\)"," ","versus ","\\(\\operatorname{tr}_2\\)",")."]}),Object(i.jsx)(_,{no:"4",name:"Schmidt",statement:"\r Let \\(v\\in\\mathcal{H}_m\\otimes\\mathcal{H}_n\\). Then, there exist orthonormal bases \\(\\{e_i\\},\\{f_i\\}\\) for \\(\\mathcal{H}_m,\\mathcal{H}_n\\), respectively, such that \\[v=\\sum_{i=1}^{\\min\\{m,n\\}} \\alpha_i e_i\\otimes f_i\\]\r and the \\(\\alpha_i\\) are uniquely-given, real, and non-negative."}),Object(i.jsxs)("p",{children:["The proof of the Schmidt decomposition is essentially the same as that of the singular value decomposition. The above ","\\(\\alpha_i\\)"," are called the ",Object(i.jsx)("strong",{children:"Schmidt coefficients"})," of ","\\(v\\)","."]}),Object(i.jsx)(_,{no:"5",statement:"\r The entanglement entropy of a unit vector \\(v\\in\\mathcal{H}\\) is \\[E(v)=-\\sum_i \\alpha_i^2\\ln\\alpha_i^2\\] where the \\(\\alpha_i\\) are the Schmidt coefficients of \\(v\\)."}),Object(i.jsx)(k,{proof:"\r Recall that the matrix representing the projector \\(P_v\\) is given by \\(vv^\\ast\\), where \\(v^\\ast\\) is the conjugate transpose of the column vector of \\(v\\). Written with respect to the Schmidt decomposition, we have\r \\[\r vv^\\ast=\\left(\\sum_i \\alpha_i e_i\\otimes f_i\\right)\\left(\\sum_i \\alpha_i e_i\\otimes f_i\\right)^\\ast=\\sum_{i,j} \\alpha_i\\overline{\\alpha_j} (e_i\\otimes f_i)(e_j\\otimes f_j)^\\ast.\r \\]\r Distributing the conjugate transposition and multiplying through using properties of the Kronecker product, we obtain\r \\[\r vv^\\ast=\\sum_{i,j} \\alpha_i\\overline{\\alpha_j}(e_ie_j^\\ast\\otimes f_if_j^\\ast)=\\sum_i \\alpha_i^2 (e_ie_i^\\ast\\otimes f_if_i^\\ast)\r \\]\r with the last equality following from the orthonormality of our bases. Taking the partial trace,\r \\[\\begin{aligned}\r \\operatorname{tr}_2(vv^\\ast) &= \\operatorname{tr}_2\\left(\\sum_i \\alpha_i^2 (e_ie_i^\\ast\\otimes f_if_i^\\ast)\\right) \\\\\r &= \\sum_i \\alpha_i^2 \\operatorname{tr}_2{(e_ie_i^\\ast\\otimes f_if_i^\\ast)} \\\\\r &= \\sum_i \\alpha_i^2 \\operatorname{tr}(f_if_i^\\ast)e_ie_i^\\ast.\r \\end{aligned}\\]\r However, \\(f_if_i^\\ast=P_{f_i}\\), and so \\(\\operatorname{tr}(f_if_i^\\ast)=1\\) for each \\(i\\). The \\(e_ie_i^\\ast=P_{e_i}\\) are also projectors, and moreover they are all orthogonal to each other, hence we see \\(\r \\operatorname{spec}\\operatorname{tr}_2P_v=\\{\\alpha_i^2\\}\r \\), as desired."}),Object(i.jsxs)("p",{children:["To see entropy in action, denote by ","\\(\\{e_1,e_2\\}\\)"," the standard basis for ","\\(\\mathbb{C}^2\\)",", and examine the unit vector ","\\(e_1\\otimes e_1\\in\\mathbb{C}^2\\otimes\\mathbb{C}^2\\)",". We can project onto it by"," ","\\[P_{e_1\\otimes e_1}=(e_1\\otimes e_1)(e_1\\otimes e_1)^\\ast= e_1e_1^\\ast\\otimes e_1e_1^\\ast=P_{e_1}\\otimes P_{e_1}.\\]","This is clearly separable, and the partial trace is just"," ","\\(\\operatorname{tr}_2 P_{e_1\\otimes e_1}=P_{e_1}\\)",", giving"," ","\\(E(e_1\\otimes e_1)=0\\)"," as expected. All pure separable states will have zero entropy for this reason. For an entangled state, consider","\\[v=\\frac{1}{\\sqrt{2}}(e_1\\otimes e_1+e_2\\otimes e_2)\\in\\mathbb{C}^2\\otimes\\mathbb{C}^2.\\]","Then, with respect to the standard (lexicographic) basis of the tensor product,","\\[\n            P_v=\\begin{pmatrix}\n            \\frac{1}{2} & 0 & 0 & \\frac{1}{2} \\\\\n            0 & 0 & 0 & 0 \\\\\n            0 & 0 & 0 & 0 \\\\\n            \\frac{1}{2} & 0 & 0 & \\frac{1}{2}\n           \\end{pmatrix}.\n            \\]","Computing partial trace is simple given an actual matrix (we just trace over the blocks), obtaining","\\[\\operatorname{tr}_2 P_v=\\begin{pmatrix}\n            \\operatorname{tr}\\begin{pmatrix}\\frac{1}{2} & 0 \\\\ 0 & 0\\end{pmatrix} &  \\operatorname{tr}\\begin{pmatrix}0 & \\frac{1}{2} \\\\ 0 & 0\\end{pmatrix} \\\\\n            \\operatorname{tr}\\begin{pmatrix}0 & 0 \\\\ \\frac{1}{2} & 0\\end{pmatrix} &  \\operatorname{tr}\\begin{pmatrix}0 & 0 \\\\ 0 & \\frac{1}{2}\\end{pmatrix}\n           \\end{pmatrix}=\\begin{pmatrix}\\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2}\\end{pmatrix}.\\]","Therefore,","\\[E(v)=-\\left(\\frac{1}{2}\\ln\\frac{1}{2}+\\frac{1}{2}\\ln\\frac{1}{2}\\right)=\\ln 2\\]","and so the state given by ","\\(v\\)"," is entangled (in fact, this is the most entangled a state can be in"," ","\\(\\mathbb{C}^2\\otimes\\mathbb{C}^2\\)",")."]}),Object(i.jsxs)("p",{children:["The question now is how to extend ","\\(E\\)"," from pure states (though we technically defined it for vectors, these are just projectors up to a rotational identification) to mixed states. The natural approach is to weigh the entropy with respect to the coefficients of an ensemble, defining","\\[E(\\rho)=\\sum_i p_i E(v_i).\\]","However, recall that, due to Schr\xf6dinger, ensemble representations are generally not unique. This would be fine if the above were invariant under choice, but unfortunately this is not the case. One solution is to iterate over the entire ensemble space, writing say","\\[E_F(\\rho)=\\inf_{\\mathrm{ensembles}}\\sum_i p_iE(v_i),\\]","which defines ",Object(i.jsx)("strong",{children:"entanglement of formation"}),". This process may actually be done for any of notion of entanglement initially defined on pure states, and is called a"," ",Object(i.jsx)("strong",{children:"convex roof construction"}),"."]}),Object(i.jsxs)("p",{children:["Though the definition is intuitive and easy to write down, the value is devilishly hard to compute. Indeed, closed-form expressions are only known for special cases (e.g. over"," ","\\(\\mathbb{C}^2\\otimes\\mathbb{C}^2\\)",", see"," ",Object(i.jsx)("a",{className:"linkPurple",href:"https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.80.2245",children:"here"}),"). The question of whether this infimum is ever even attained (that is, whether some ensemble realizes ","\\(E_F\\)",") is also non-trivial (though it is known to be true in many cases, see"," ",Object(i.jsx)("a",{className:"linkPurple",href:"https://www.mdpi.com/1099-4300/12/7/1799",children:"here"}),"). The reason ","\\(E_F(\\rho)=0\\)"," when ","\\(\\rho\\)"," is separable, however, is that the ensemble showing it is separable will satisfy ","\\(E(v_i)=0\\)"," for each ","\\(i\\)",", as seen earlier, and so the infimum will be attained there."]}),Object(i.jsxs)("p",{children:["Another approach is to construct some notion of distance between states, and see how far away a state is from the set of separable ones. For this, we introduce ",Object(i.jsx)("strong",{children:"von Neumann entropy"}),",","\\[S(\\rho)=-\\operatorname{tr}\\rho\\ln\\rho.\\]"," The notation warrants a brief discussion. The actual matrix logarithm"," ","\\(\\ln\\rho\\)"," will not always exist (as density matrices may be singular), so some care must be taken. It may be easier to understand this as notational shorthand applied to the eigendecomposition, where","\\[\\rho\\ln\\rho=\\sum_i (\\lambda_i\\ln\\lambda_i) P_{v_i}\\]"," ","with ","\\(\\ln 0=0\\)"," as before. When the matrix ","\\(\\ln\\rho\\)"," ","exists, the two definitions coincide. This quantity is closely related to entanglement entropy (indeed, entanglement entropy is sometimes called the reduced von Neumann entropy, as"," ","\\(E(v)=S(\\operatorname{tr}_2 P_v)\\)",")."]}),Object(i.jsxs)("p",{children:["With this, we may now define the ",Object(i.jsx)("strong",{children:"relative entropy"})," of"," ","\\(\\rho\\)"," with respect to ","\\(\\sigma\\)"," by"," ","\\[S(\\rho\\|\\sigma)=\\operatorname{tr}(\\rho(\\ln\\rho-\\ln\\sigma)).\\]","This gives us the notion of entropic distance we desired (but note it is just a notion, not a literal metric). So, we go on to define the measure","\\[E_R(\\rho)=\\inf_{\\textrm{separable}} S(\\rho\\|\\sigma)\\]","called ",Object(i.jsx)("strong",{children:"relative entanglement"})," (the infimum is iterating over each separable state ","\\(\\sigma\\)","). If"," ","\\(\\rho\\)"," is not entangled, this quantity will vanish once the entropy is taken relative to itself."]}),Object(i.jsxs)("p",{children:["Unfortunately, just like for entanglement of formation, actually computing relative entanglement is quite hard. It is interesting to note though that both ","\\(E_F\\)"," and ","\\(E_R\\)"," reduce to the entanglement entropy ","\\(E\\)"," over pure states (this is trivial for the former, but the argument for the latter is involved, see"," ",Object(i.jsx)("a",{className:"linkPurple",href:"https://journals.aps.org/pra/abstract/10.1103/PhysRevA.57.1619",children:"here"}),")."]}),Object(i.jsx)("p",{children:"This subject, best described as quantum information theory, is situated at an interesting place for me. I remember in high school posting a question on Stack Exchange, asking what the quotient of a vector space even means and why it would ever come up. A couple of years later, and I see them show up here (as one of the ways) to define tensor products, which are then used to discuss what happens during very expensive laboratory experiments. Though I can't say I feel particularly motivated to learn about the actual physics and real-world interpretations behind all of this, I nonetheless find it really fascinating (or maybe comforting?) to know that some of the seemingly abstract theory I've been working with this summer has interpretations this tangible and uses this practical. But maybe this is just me reorienting my compass again, this time embarking to become an applied mathematician. Who knows?"})]})}}]),a}(n.Component),T=a.p+"static/media/fig1(koch).b55a4c6d.png",I=a.p+"static/media/fig2(transv).eaa3dc15.png",q=a.p+"static/media/fig3(wind).3c138aea.png",A=a.p+"static/media/fig4(gp).52edce34.jpg",X=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"componentDidMount",value:function(){window.KaTeXRender()}},{key:"render",value:function(){return Object(i.jsxs)("div",{class:"postContent leftMargin",children:[Object(i.jsx)("p",{children:"If I were to draw a circle or some polygon, like a square, on a piece of paper, and ask you to identify the inside and outside, you would likely look at me as if I had gone mad. It is incredibly easy to both define what the inside is and identify where it lies, as these curves can be described by a product of intervals, or some simple parametrization. But what of, say, the Koch snowflake, as in figure 1? The precise curve is actually the limit case of the figure - a fractal. The curve is still continuous, being without holes, and does not overlap (except at the beginning and end). However, its perimetre is infinite, and its parametrization is nowhere differentiable. How would you formally describe what lies inside it? In fact, for a curve like this it is not unreasonable to suspect that may not be well-defined in the first place; perhaps some point behaves weirdly in the limit case and cannot be simply classified."}),Object(i.jsx)($,{no:"1",src:T,caption:"Koch snowflake"}),Object(i.jsxs)("p",{children:["Thankfully someone, specifically Jordan, proved we don't need to worry about such a thing. His result on these curves gave them a special name, ",Object(i.jsx)("strong",{children:"Jordan curves"}),". These are simple closed curves on the plane, meaning they are continuous curves in"," ","\\(\\mathbb{R}^2\\)"," with no self-intersections, except at the start and end. His precise result was as follows."]}),Object(i.jsx)(_,{name:"Jordan",statement:"\r Every Jordan curve divides the plane into two components, an unbounded exterior and a bounded interior, such that the curve is the boundary of each component."}),Object(i.jsx)("p",{children:'What is interesting is that such a seemingly "obvious" result, something that every school child understands implicitly when they are told to "colour inside the lines", has an entirely non-obvious proof. Indeed, even today there are no easy proofs of it. They all span multiple pages, and use machinery which, at least on the surface, appears to be overkill for such a simple sounding statement.'}),Object(i.jsxs)("p",{children:["This can actually be considered as a special case of a stronger result proved by Brouwer a few decades after Jordan's initial publication. However, to get there we will need a few definitions. I have already discussed manifolds in the past, however there is an object which slightly generalizes them. We call these"," ",Object(i.jsx)("strong",{children:"manifolds with boundary"}),". While a \\(k\\)-manifold is diffeomorphic to ","\\(\\mathbb{R}^k\\)",", we require only that manifolds with boundary are diffeomorphic to the"," ",Object(i.jsx)("strong",{children:"upper-half plane "}),"\\[\\mathcal{H}^k:=\\{(x_1,\\dots x_k)\\in\\mathbb{R}^k : x_k\\geq 0\\}.\\]"]}),Object(i.jsxs)("p",{children:["Visually, the obvious notion of a boundary on the upper-half plane occurs precisely where \\(x_k=0\\), and we denote it by"," ","\\(\\partial\\mathcal{H}^k\\)",". It is important to note that this is completely different from a topological boundary, even though we use the same notation. A manifold with boundary \\(X\\) of dimension \\(k\\), then, has a neighbourhood around each point diffeomorphic to"," ","\\(\\mathcal{H}^k\\)",", and its boundary \\(\\partial X\\) is the set of points which lie in ","\\(\\partial\\mathcal{H}^k\\)"," under some set of local coordinates (one can show this is well-defined and will in fact be identical for any arbitrary system). It is immediate the boundary then is itself a manifold of dimension \\(k-1\\), as we can parametrize it to ","\\(\\mathbb{R}^{k-1}\\)"," by cutting off the last coordinate (as it will always be \\(0\\)), and composing."]}),Object(i.jsx)("p",{children:"Of note is that any compact, connected \\(1\\)-manifold with boundary is diffeomorphic to the unit interval \\([0,1]\\) or to the unit circle \\(S^1\\) (visually, compactness and connectedness means you can only end somewhere or loop back to where you started). This is actually non-trivial to show as well, much like the Jordan curve theorem, despite being intuitively quite obvious. We will take it for granted, as we will need the following fact later."}),Object(i.jsx)(_,{no:"1",statement:"\r Every compact \\(1\\)-manifold with boundary has an even number of points in its boundary."}),Object(i.jsx)(k,{proof:"\r Every component will be diffeomorphic to \\([0,1]\\) or \\(S^1\\), which have \\(2\\) and \\(0\\) points in the boundary, respectively."}),Object(i.jsxs)("p",{children:["This is the only definition we need to generalize Jordan's result. We call a manifold ","\\(X\\subseteq\\mathbb{R}^n\\)"," a"," ",Object(i.jsx)("strong",{children:"hypersurface"})," if it is of dimension \\(n-1\\) (note that this can be generalized to submanifolds and codimensions, but we will not need that)."]}),Object(i.jsx)(_,{name:"Jordan-Brouwer",statement:"\r If \\(X\\) is a compact, connected hypersurface in \\(\\mathbb{R}^n\\), then \\(\\mathbb{R}^n\\setminus X\\) consists of two open connected components, \\(D_0\\) and \\(D_1\\), such that \\(\\overline{D_0}\\) is a compact manifold with boundary, and in particular \\(\\partial\\overline{D_0}=X\\)."}),Object(i.jsx)("p",{children:"Perhaps being slightly misleading, I will not be talking about the Jordan-Brouwer theorem itself in this post. Instead, I will be talking about something intimately related to it. To prove this theorem, we must at some point have candidates for \\(D_0\\) and \\(D_1\\), and this is what I will be discussing: how do we define inside and outside in the first place?"}),Object(i.jsxs)("p",{children:["The first stop is at the intersections of curves. Recall that there is a nice condition for when the preimage of a map \\(f\\colon X\\to Y\\) would have ","\\(f^{-1}(y)\\)"," be a manifold. Specifically, it was when \\(y\\) was a regular value, meaning \\(df_x\\) was surjective at each point ","\\(x\\in f^{-1}(y)\\)",". This is, in fact, a special case of the more general concept of"," ",Object(i.jsx)("strong",{children:"transversal intersections"}),". In particular, \\(f\\) is transversal to a submanifold \\(Z\\subseteq Y\\), written \\(f\\pitchfork Z\\), if ","\\(T_{f(x)}(Z)+\\operatorname{im}df_x=T_{f(x)}(Y)\\)"," for every ","\\(x\\in f^{-1}(Z)\\)","."]}),Object(i.jsx)(_,{no:"2",statement:"\r For smooth \\(f\\colon X\\to Y\\) with \\(Z\\) a submanifold of \\(Y\\), then \\(f^{-1}(Z)\\) is a submanifold of \\(X\\) if \\(f\\pitchfork Z\\)."}),Object(i.jsx)(k,{proof:"Consider some \\(x\\in f^{-1}(Z)\\), and let \\(y=f(x)\\). Let \\(\\ell=\\operatorname{codim}Z\\). Take local coordinates around \\(y\\) such that the last \\(\\ell\\) coordinates vanish on \\(Y\\setminus Z\\) (locally); call these last \\(\\ell\\) coordinates \\(g=(g_1,\\dots,g_\\ell)\\). Consider the composition \\(g\\circ f\\colon f^{-1}(Z)\\to\\mathbb{R}^\\ell\\), and note \\[d(g\\circ f)_x=dg_y\\circ df_x.\\] As\\(f\\pitchfork Z\\), this derivative is surjective at \\(x\\). However, \\(x\\) was an arbitrary point in the preimage and we have \\((g\\circ f)(x)=0\\), meaning \\(0\\) is a regular value of \\(f\\). Then, \\(f^{-1}(Z)=(g\\circ f)^{-1}(0)\\) is a submanifold. "}),Object(i.jsx)("p",{children:"This is a very visual idea, essentially meaning that tangent spaces add up to the ambient space. However, this has the caveat of therefore being dependent on the ambient space, and so intersections transversal in one setting may not be transversal elsewhere. This is demonstrated in figure 2 below."}),Object(i.jsx)($,{no:"2",src:I,caption:"Transversal intersection (left) and non-transversal intersection (right)"}),Object(i.jsxs)("p",{children:["This is quite a nice, simple condition to verify if a preimage will be a submanifold, and captures the spirit of differential topology: for us to learn about behaviour globally (being a manifold), we reduce it to local linear behaviour (a union of vector spaces). However, there is the very real question of whether intersections like this exist, in general. After all, intersections can be very tricky. If we take any function ","\\(\\mathbb{R}\\to\\mathbb{R}\\)"," which crosses the \\(x\\)-axis, any slight variation of that function will undoubtedly move that crossing point, and so it is very hard, in general, to find a function which has a root at a specific value (outside of contrived examples). Might it be the same for transversal intersections? Thankfully, no; in fact, essentially all intersections are transversal, and these intersections are not affected by perturbations. To formalize this idea, we introduce homotopy."]}),Object(i.jsxs)("p",{children:["Two maps \\(f_0,f_1\\colon X\\to Y\\) are ",Object(i.jsx)("strong",{children:"homotopic"}),", written \\(f_0\\sim f_1\\), if there exists some smooth map \\(F\\colon X\\times [0,1]\\to Y\\) such that \\(F(x,0)=f_0(x)\\) and \\(F(x,1)=f_1(x)\\). A property of \\(f_0\\) is said to be"," ",Object(i.jsx)("strong",{children:"stable"})," if for any homotopy \\(F(x,t)\\eqqcolon f_t(x)\\), there exists some \\(\\varepsilon \\gt 0\\) such that \\(f_t\\) has that property when \\(t \\lt \\varepsilon\\). A great deal of interesting properties are stable, such as embeddings, submersions, etc. In particular, as transversal intersections at the heart rely on submersions, it follows that they are stable as well. The proofs for these all essentially rely on these conditions being a statement about the determinant of some matrix, by the inverse function theorem, and the determinant function being continuous."]}),Object(i.jsx)("p",{children:"What is far more interesting is that transversality is generic, meaning that given any smooth map \\(f\\) and any submanifold \\(Z\\), we can find some \\(g\\) homotopic to \\(f\\) so \\(g\\pitchfork Z\\). This is quite remarkable given that the behaviour of \\(f\\) with respect to \\(Z\\) can be as pathological as we want - we need only to slightly wiggle it to get a nice intersection. Proving transversal intersections are generic is dry and lengthy (it would involve numerous technical lemmas, all for a rather technical result). It could be a whole post in and of itself, so instead I will simply state the two results we will need."}),Object(i.jsx)(_,{no:"2",name:"Transversality-Homotopy",statement:"\r Let \\(f\\colon X\\to Y\\) be smooth between a manifold \\(X\\) and a boundaryless manifold \\(Y\\). If \\(Z\\) is a boundaryless submanifold of \\(Y\\), there is some smooth \\(g\\sim f\\) such that \\(g\\pitchfork Z\\) and \\(\\partial g\\pitchfork Z\\), where \\(\\partial g :\\equiv g\\vert_{\\partial X}\\)."}),Object(i.jsxs)("p",{children:["For \\(f\\colon X\\to Y\\) we say that \\(f\\pitchfork Z\\) on a subset \\(C\\) of \\(X\\) if ","\\(f\\vert_{C\\cap f^{-1}(Z)}\\pitchfork Z\\)",". We can slightly strengthen theorem 2, useful in some situations."]}),Object(i.jsx)(_,{no:"3",name:"Extension Theorem",statement:"\r Let \\(f\\colon X\\to Y\\) be smooth between a manifold \\(X\\) and a boundaryless manifold \\(Y\\), and \\(C\\subseteq X\\) be closed. If \\(Z\\) is a closed boundaryless submanifold of \\(Y\\) such that \\(f\\pitchfork Z\\) on \\(C\\) and \\(\\partial f\\pitchfork Z\\) on \\(C\\cap\\partial X\\), there is some \\(g\\sim f\\) such that \\(g\\pitchfork Z\\) and \\(\\partial g\\pitchfork Z\\) and \\(g\\equiv f\\) on a neighbourhood of \\(C\\)."}),Object(i.jsxs)("p",{children:["We will use these to continue our trek toward the main result, and that is determining what lies inside and outside a hypersurface. We will do this with transversal intersections of a specific function and a special invariant. This invariant will come from the"," ",Object(i.jsx)("strong",{children:"intersection number"}),". For \\(f\\colon X\\to Y\\) and \\(f\\pitchfork Z\\) a closed submanifold of \\(Y\\), such that"," ","\\(\\operatorname{dim}X+\\operatorname{dim}Z=\\operatorname{dim}Y\\)",", we define the intersection number modulo 2 of \\(f\\) with respect to \\(Z\\), written \\(I_2(f,Z)\\), to be"," ","\\(\\left|f^{-1}(Z)\\right|_2\\)"," (the cardinality of the preimage modulo 2). Observe that due to the condition on our dimensions,"," ","\\(f^{-1}(Z)\\)"," will be a manifold of dimension \\(0\\) (hence a finite set), so the intersection number is well-defined. Of course, not all maps will intersect \\(Z\\) transversally, but recall that transversality is generic, and theorem 1 gives us a nice statement about cardinalities of boundaries modulo 2, to get the following result."]}),Object(i.jsx)(_,{no:"4",statement:"\r If \\(f_0,f_1\\colon X\\to Y\\) are homotopic so \\(f_0\\pitchfork Z\\) and \\(f_1\\pitchfork Z\\), where \\(Z\\) is a closed submanifold of \\(Y\\) so \\(\\operatorname{dim}X+\\operatorname{dim}Z=\\operatorname{dim}Y\\), then \\(I_2(f_0,Z)=I_2(f_1,Z)\\)."}),Object(i.jsx)(k,{proof:"\r Let \\(F\\colon X\\times [0,1]\\to Y\\) be a homotopy of \\(f_0\\) and \\(f_1\\). Without loss of generality, take \\(F\\pitchfork Z\\), for otherwise observe that \\(F\\pitchfork Z\\) on \\(X\\times \\{0,1\\}\\) (as \\(f_0\\) and \\(f_1\\) are both transversal), which is closed in \\(X\\times [0,1]\\). Then, the extension theorem lets us take some \\(G\\sim F\\) so \\(G\\pitchfork Z\\) yet \\(G\\equiv F\\) on \\(X\\times \\{0,1\\}\\) (in fact, it will be true on a neighbourhood thereof), hence \\(G(x,0)=f_0(x)\\) and \\(G(x,1)=f_1(x)\\).\\[\\] \r Now, note that \\(\\partial (X\\times [0,1])=X\\times\\{0\\}\\cup X\\times\\{1\\}\\), hence \\(F\\equiv f_0\\) or \\(F\\equiv f_1\\) on \\(\\partial (X\\times [0,1])\\), so \\(\\partial F\\pitchfork Z\\). Then,\r \\[\r \\operatorname{dim}(X\\times [0,1])-\\operatorname{dim}F^{-1}(Z) =\\operatorname{dim}X+1-\\operatorname{dim}F^{-1}(Z)=\\operatorname{dim}Y-\\operatorname{dim}Z\r \\]\r and our assumptions on dimensions means \\(\\operatorname{dim}F^{-1}(Z)=1\\). Observe that\r \\[\r \\begin{aligned}\r \\partial F^{-1}(Z)&=F^{-1}(Z)\\cap\\partial(X\\times [0,1])\\\\\r &=F^{-1}(Z)\\cap(X\\times\\{0\\})\\cup F^{-1}(Z)\\cap(X\\times\\{1\\})\\\\\r &=f_0^{-1}(Z)\\cup f_1^{-1}(Z)\r \\end{aligned}\r \\]\r however, by theorem 1, this means \\(I_2(f_0,Z)=I_2(f_1,Z)\\), as desired. "}),Object(i.jsx)(_,{no:"5",name:"Boundary Theorem",statement:"\r If \\(W\\) is compact with \\(\\partial W=X\\), and \\(g\\colon X\\to Y\\) can be extended to \\(W\\), then \\(I_2(g,Z)=0\\) for all closed submanifolds \\(Z\\) in \\(Y\\) such that \\(\\operatorname{dim}X+\\operatorname{dim}Z=\\operatorname{dim}Y\\)."}),Object(i.jsx)(k,{proof:"\r Say \\(G\\) is the extension of \\(g\\). By transversality-homotopy, take \\(F\\sim G\\) so \\(F\\pitchfork G\\) and \\(\\partial F\\pitchfork G\\). Observe that \\(\\partial G=g\\) and \\(\\partial F=: f\\sim g\\). Therefore, \\(I_2(g,Z)=|f^{-1}(Z)|_2\\) by theorem 4, but as \\(F^{-1}(Z)\\) is a \\(1\\)-manifold with boundary, \\(I_2(g,Z)=0\\) by theorem 1."}),Object(i.jsx)("p",{children:"Then, for an arbitrary map \\(g\\) (with all the same conditions as before), we can define \\(I_2(g,Z)=I_2(f,Z)\\), where \\(f\\sim g\\) is an arbitrary homotopy transversal to \\(Z\\), which will exist by transversality-homotopy. Our next step in constructing this invariant is to exploit that our hypersurface will be connected."}),Object(i.jsx)(_,{no:"6",statement:"If \\(f\\colon X\\to Y\\) is smooth with equidimensional compact \\(X\\) and connected \\(Y\\), then \\(I_2(f,\\{y\\})\\) is invariant under choice of \\(y\\in Y\\)."}),Object(i.jsx)(k,{proof:"\r Without loss of generality, assume \\(f\\pitchfork \\{y\\}\\) (note this is identical to assuming \\(y\\) is a regular value). By the stack of records theorem (proved in an earlier post of mine), there is a neighbourhood \\(U\\) of \\(y\\) such that \\(f^{-1}(U)=\\dot{\\bigcup}_{k=1}^n V_k\\) where each \\(V_k\\) is open in \\(X\\) and \\(f\\) is locally diffeomorphic on each.\\[\\]\r Then, \\(I_2(f,\\{z\\})=n\\) for any \\(z\\in U\\), and so the map \\(y\\mapsto I_2(f,\\{y\\})\\) is locally constant on \\(U\\). As \\(Y\\) is connected, this extends to a globally constant map."}),Object(i.jsxs)("p",{children:["We call this value the modulo 2 ",Object(i.jsx)("strong",{children:"degree"})," of \\(f\\), written ","\\(\\operatorname{deg}_2 f\\)",". Now, we begin the construction. Let \\(X\\) be a compact, connected manifold (we will shortly examine hypersurfaces in particular) in"," ","\\(\\mathbb{R}^n\\)",", with ","\\(f\\colon X\\to\\mathbb{R}^n\\)"," ","smooth and for ","\\(z\\in\\mathbb{R}^n\\setminus f(X)\\)"," define the"," ",Object(i.jsx)("strong",{children:"unit vector"}),"\\[u_z\\colon X\\to S^{n-1}\\textrm{ by }u_z(x)=\\frac{f(x)-z}{|f(x)-z|}.\\]"]}),Object(i.jsxs)("p",{children:["Note that \\(u_z\\) satisfies the hypotheses of theorem 6, hence we can consider ","\\(\\operatorname{deg}_2 u_z\\)",". Observe that, geometrically, this is the number (modulo 2) of points \\(x\\in X\\) whose unit vector from \\(f(x)\\) to \\(z\\) will point in a particular direction (as we compute the degree by fixing some vector in"," ","\\(S^{n-1}\\)","). Thus, we call this the winding number modulo 2 of \\(f\\) around \\(z\\), written"," ","\\(W_2(f,z):=\\operatorname{deg}_2 u_z\\)",". A visual representation is seen below in figure 3."]}),Object(i.jsx)($,{no:"3",src:q,caption:"A particular unit vector \\(u_z\\) with points in its preimage (blue). Here, \\(W_2(f,z)=1\\)."}),Object(i.jsx)("p",{children:'This winding number is the key to the separation theorem. We will use it to compute what is "inside" and "outside", and we begin with a technical result.'}),Object(i.jsx)(_,{no:"7",statement:"\r Let \\(f\\colon X\\to\\mathbb{R}^n\\) be smooth with \\(D\\) a compact manifold with boundary \\(X\\) such that \\(F\\colon D\\to\\mathbb{R}^n\\) extends \\(f\\). If \\(z\\notin f(X)\\) is a regular value of \\(F\\), then \\(F^{-1}(Z)\\) is finite and \\(|F^{-1}(z)|\\equiv_2 W_2(f,z)\\). "}),Object(i.jsx)(k,{proof:"\r Suppose \\(F^{-1}(z)=\\varnothing\\). As \\(f\\) can be extended to \\(D\\), so can the unit vector \\(u_z\\) as \\(F(x)\\neq z\\) for all \\(x\\in D\\), so it is well-defined. Then, by the boundary theorem, we have that\r \\[\r \\operatorname{deg}_2 u_z=0=W_2(f,z)=|\\varnothing|\r \\]\r as the degree is defined as an intersection number. \\[\\]\r Suppose now \\(F^{-1}(z)=\\{x_1,\\dots ,x_\\ell\\}\\). For each \\(x_i\\), take a closed ball of radius \\(\\varepsilon_i\\) around \\(x_i\\), call it \\(\\mathcal{B}_i(x_i,\\varepsilon_i)\\), small enough such that the \\(\\mathcal{B}_i\\) are disjoint from each other and from \\(X\\). Define \\(g_i\\colon\\partial\\mathcal{B}_i\\to\\mathbb{R}^n\\) as a restriction of \\(F\\), and let \\(D_k:=D\\setminus\\dot{\\bigcup}_{i=1}^k\\operatorname{int}\\mathcal{B}_i\\), \\(X_k:=\\partial D_k\\), and \\(f_k:=F\\vert_{X_k}\\). \\[\\]\r Now, note that \\(W_2(f_0,z)=W_2(f,z)\\), and\r \\[\r W_2(f_k,z)=W_2(f_{k-1},z)+W_2(g_k,z).\r \\]\r Thus,\r \\[\r W_2(f_\\ell,z)=W_2(f_{\\ell-1},z)+W_2(g_\\ell,z)=W_2(g_1,z)+\\cdots +W_2(g_1,z)+W_2(f_0,z).\r \\]\r As \\(z\\notin D_\\ell\\), we can extend \\(f_\\ell\\) to \\(D_\\ell\\), hence by the boundary theorem \\(W_2(f_\\ell,z)=0\\), meaning\r \\[\r -W_2(f_0,z)=-W_2(f,z)=W_2(g_1,z)+\\cdots+W_2(g_\\ell,z).\r \\]\r By \\(z\\) being a regular value and the balls being disjoint, we know \\(F\\) is locally diffeomorphic in some neighbourhood of the closed balls. Restricting the unit vector map (induced by \\(g_k\\)) will have it be bijective, hence \\(W_2(g_k,z)=1\\), and taking everything modulo \\(2\\) we are done."}),Object(i.jsx)("p",{children:'One can apply theorem 7 to the case where \\(X\\) is a hypersurface and \\(f=\\imath\\) is the inclusion. If one can prove that the complement of \\(X\\) consists of two connected sets, each open with \\(X\\) being their boundary, with one bounded and one unbounded, then it will precisely state that \\(W_2(X,z):=W_2(\\imath,z)\\) (this is what we mean when we talk about winding numbers of manifolds) is equal to the number of points in the preimage of the extension of the inclusion map. That is, the winding number will be equal to \\(1\\) if it lies "inside" and \\(0\\) if it lies "outside". This is the invariant we seek to compute, which we will do using the following curve.'}),Object(i.jsxs)("p",{children:["Given ","\\(z\\in\\mathbb{R}^n\\setminus X\\)"," in the complement of our compact, connected hypersurface, we define a ",Object(i.jsx)("strong",{children:"ray"})," ","emanating from \\(z\\) in the direction of \\(v\\) to be"," ","\\[r:=\\{z+tv:0\\leq t\\in\\mathbb{R}\\}.\\]","."]}),Object(i.jsx)(_,{no:"8",statement:"\r A ray \\(r\\) from \\(z\\) in the direction of \\(v\\) is transversal to \\(X\\) if and only if \\(v\\) is a regular value of the unit vector \\(u_z\\)."}),Object(i.jsx)(k,{proof:"\r Suppose that \\(r\\pitchfork X\\). Then,\r \\[\r T_x(X)+\\operatorname{im}dr_t=T_x(\\mathbb{R}^n)=\\mathbb{R}^n\r \\]\r for any \\(x\\in X\\cap r\\), where \\(x=z+tv\\). With \\(v=(v_1,\\dots, v_n)\\), we know that\r \\[\r dr_t=\\begin{pmatrix}\r v_1 & \\cdots & v_n\r \\end{pmatrix}^T(t)\r \\]\r and so the image under \\(\\mathbb{R}\\) is just the ray extended to the line. Then, recall that \\(u_z(x)=(x-z)/|x-z|\\) (as our map \\(f\\) here is just the inclusion), and \\(v\\) is a regular value if and only if for all \\(x\\) such that \\(u_z(x)=v\\) we have \\(d(u_z)_x=\\mathbb{R}^{n-1}\\). This, however, happens if and only if \\(T_x(X)\\perp \\{tv:t\\in\\mathbb{R}\\}\\), precisely equivalent to our transversality condition."}),Object(i.jsx)(_,{no:"9",statement:"\r Let \\(r\\) be a ray emanating from \\(z_0\\) in the direction \\(v\\) so \\(r\\pitchfork X\\). Let \\(z\\neq z_0\\) be in the complement of \\(X\\) but on \\(r\\), with \\(\\ell\\) being the number of intersections of \\(r\\) and \\(X\\) between \\(z\\) and \\(z_0\\). Then, \\(W_2(X,z_0)=W_2(X,z)+\\ell\\) all modulo \\(2\\). "}),Object(i.jsx)(k,{proof:"\r Observe that, by theorem 8, we must have that \\(v\\) is a regular value of both \\(u_z\\) and \\(u_{z_0}\\) by theorem 8. Therefore, \\(W_2(X,z)=|u_z^{-1}(v)|_2\\) and \\(W_2(X,z_0)=|u_{z_0}^{-1}(v)|_2\\). Therefore, \\(W_2(X,z_0)=W_2(X,z)+\\ell\\), for if \\(x\\in u_z^{-1}(v)\\) lies after \\(z\\) but before \\(z_0\\), then \\(u_{z_0}(x)=-v\\), hence not contributing to the winding number. "}),Object(i.jsx)("p",{children:"At last, we have our central result. Recall that we are assuming we have already proven the complement of our hypersurface consists of the two components as posited in the Jordan-Brouwer theorem statement, and so theorem 7 tells points in the same component have the same winding number."}),Object(i.jsx)(_,{no:"10",statement:"\r Let \\(r\\) be a ray emanating from \\(z\\) in the direction of \\(v\\), such that \\(r\\pitchfork X\\). Then, \\(z\\) lies inside \\(X\\) if and only if \\(r\\) intersects \\(X\\) an odd number of times."}),Object(i.jsx)(k,{proof:"\r Observe that, as \\(X\\) is compact, we can find some \\(z_0\\) outside of \\(X\\) such that \\(W_2(X,z)=0\\). By theorem 9, then, \\(W_2(X,z)+\\ell=W_2(X,z_0)=0\\), meaning \\(W_2(X,z)=-\\ell\\) all modulo 2. However, as \\(z_0\\) was outside with winding number \\(0\\), this means \\(z\\) will be outside as well if and only if \\(-\\ell=0\\) modulo 2, equivalently if and only if \\(\\ell\\) is even. "}),Object(i.jsxs)("p",{children:["I find this is a beautiful argument. Recalling figure 3, we can take the dashed line extending \\(u_z\\) to be our ray, and we see there are \\(5\\) intersections. If \\(f(X)=\\imath(X)=X\\), then we see \\(W_2(X,z)=1\\) and indeed, \\(z\\) lies inside the curve (which is just a hypersurface in ","\\(\\mathbb{R}^2\\)","). In fact, due to Sard, almost all values of \\(u_z\\) will be regular, hence by theorem 8 almost all such rays will intersect transversally. So, taking a hypersurface, we can just draw random rays, and with probability 1 we will have one to which we can apply theorem 10. This immediately gives the following."]}),Object(i.jsx)(_,{no:"11",statement:"\r A point \\(z\\) lies inside a hypersurface \\(X\\) if and only if almost all rays emanating from \\(z\\) intersect \\(X\\) an odd number of times."}),Object(i.jsx)("p",{children:"This is astoundingly simple, so I can now rest easy, knowing if I ever find myself in a life-or-death situation where the only escape is by knowing whether a point lies inside or outside a picture, I just need a pencil and straightedge."}),Object(i.jsx)($,{no:"4",src:A,caption:"Figure 2-19 (89), Guillemin and Pollack"})]})}}]),a}(n.Component),B=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsxs)("div",{class:"postContent leftMargin",children:[Object(i.jsx)("p",{children:Object(i.jsx)("i",{children:"As a preface to everything I say below: I am no expert in Japanese. I am still learning, and still very early in my learning too. Below are just my personal experiences, and this post is not in any way an authoritative recommendation."})}),Object(i.jsxs)("p",{children:["In the Japanese language-learning community (which is surprisingly large for a language so localized), Heisig's"," ",Object(i.jsx)("i",{children:"Remembering the Kanji"})," ('RTK') is an incredibly divisive book. Even worse, it's a clean division: most people either blindly swear by it and insist it's the only way to begin learning Japanese, or denounce the book and aver it's a complete waste of time. For me, community sentiment was irrelevant when I began learning, simply because I wasn't aware of it. Rather, I asked a friend of mine who went from no Japanese to passing N1 in a little over a year, and simply planned to emulate his journey. However, I can imagine if someone is planning to learn the language and they're getting their advice strictly online, it would be very hard to consolidate all of these inconsistent views. Should they read it? Should they not? The situation is not so simple as to warrant a blanket \"Yes\" or \"No\", in my opinion, and I aim to elucidate my reasoning as to why in this post, as well as how I think it should be answered instead."]}),Object(i.jsxs)("p",{children:["I will assume you are familiar with what kanji are. If not, there are plenty of explanations online about the difference between the three Japanese scripts. To many, kanji are a fairly intimidating aspect of Japanese. I find this is related to that fact that language is, of course, solely an oral construction, and completely disjoint from orthography. Thus, even if you have a very strong vocabulary and solid understanding of grammar, you will remain functionally illiterate if you do not know kanji. In particular, this means that even if your knowledge of the ",Object(i.jsx)("i",{children:"language"})," surpasses a level, that does not necessarily mean you can also ",Object(i.jsx)("i",{children:"read"})," the next level, as more difficult texts begin to use both more kanji and less furigana. This gap in orthography exists for quite a while; depending on the end-material you wish to read it can require you to learn somewhere between 1500-3000 kanji until it goes away. Of course, Japanese people don't have (too many - character amnesia is an interesting phenomenon) issues with this, because the level of material they can understand will generally match their orthographic knowledge as they grow up. However, as an adult, it can be frustrating enough to read children's books when learning any language, but being limited to children's books even though you could read more complex material if it was written ",Object(i.jsx)("i",{children:"in a different script"})," is even more frustrating, and not an issue that is even possible in most languages. Most do not have an orthography that works like this - you can learn how to nearly fluently read Hangul over lunch, or even both kanas over the weekend. However, Japanese people don't care how difficult it is for foreigners to learn their orthography (and rightfully so) because, like I said, they don't usually encounter such a gap, and kanji have many benefits for Japanese (e.g. density:\u300c\u3053\u3053\u308d\u3088\u3044\u300dversus\u300c\u5feb\u3044\u300d; disambiguation: look up\u300c\u304b\u3051\u308b\u300din a dictionary). Thus, you will eventually have to learn kanji, and quite a few: at least 1000 at a bare minimum, but realistically far more."]}),Object(i.jsxs)("p",{children:["This is where Heisig's book comes in. He took a list of the 2136 J\u014dy\u014d kanji (plus a few extra), broke them down into their component sub-kanji, and then broke those sub-kanji down again, and continued until he arrived at atomic kanji - radicals. He then took a few basic radicals, and found all kanji which are combinations of those or combinations of the combinations (c.f. the sub-kanji). Once that list was exhausted, he introduced a new radical and repeated the process, continuing until he ordered all of the kanji. Afterward, Heisig"," ",Object(i.jsx)("u",{children:"assigned"})," (the phrasing here is important and I will recount it later) all of these kanji a unique keyword. Now, given his ordering process, each kanji has with it a minimal list of sub-kanji or radicals, which also have a unique keyword assigned. His technique then was to take a kanji, look at its keyword, look at the list of keywords that compose it, and then come up with some sort of visual imagery based on that list to remind him of the greater keyword. Repeat this for each kanji, and you end up with a process which, certainly at least mathematically, is the most efficient way to learn the kanji."]}),Object(i.jsxs)("p",{children:["So then, where is the criticism? Surely the most efficient way is the best way, right? Well, as in economics, theoretically efficiency here does not (necessarily) translate to pragmatism. The thing is, if your goal is literally to just learn the kanji, there is absolutely no question - Heisig's method is the only way to go. However, most (and in fact, I would wager all) people who are looking to learn kanji are doing it in the context of the greater goal of"," ",Object(i.jsx)("i",{children:"learning Japanese"}),". And the thing is, RTK does absolutely nothing to help in that regard, on the surface (as I mentioned before, this is just orthography). At around 5 minutes per character, going through the book will take 180 hours ",Object(i.jsx)("i",{children:"not including reviews"}),", and you will understand just as much Japanese content at hour 180 as you did at hour 0."]}),Object(i.jsxs)("p",{children:["If you have not gone through the book you might be confused as to how this is possible. Aren't the keywords teaching you the meaning of kanji? What does it even mean to learn kanji if that isn't it? Doesn't this mean RTK is useless? I certainly wondered this. Well, recall how I specified Heisig ",Object(i.jsx)("u",{children:"assigned"})," keywords to the kanji. The purpose of these keywords is primarily to distinguish the kanji from each other - a memory and bookkeeping tool. It doesn't actually matter exactly what they are; they're not super special or sacred words. Take any set of 2200 words, biject those to the kanji, and you have a new set of keywords that will work just as well as the keywords Heisig gave (in terms of completing the book). This is because many kanji have multiple meanings, or their meanings are very abstract. For example, Heisig assigns\u300c\u91cd\u300dthe keyword \"Heavy\". This appears in many words, from\u300c",Object(i.jsxs)("ruby",{children:["\u91cd",Object(i.jsx)("rt",{children:"\u304a\u3082"})]}),"\u3044\u300d, also meaning ",Object(i.jsx)("strong",{children:"Heavy"}),", to\u300c",Object(i.jsxs)("ruby",{children:["\u91cd",Object(i.jsx)("rt",{children:"\u3058\u3085\u3046"}),"\u8981",Object(i.jsx)("rt",{children:"\u3088\u3046"})]}),"\u300dmeaning ",Object(i.jsx)("strong",{children:"Important"}),", or\u300c",Object(i.jsxs)("ruby",{children:["\u91cd",Object(i.jsx)("rt",{children:"\u304b\u3055"})]}),"\u306a\u308b\u300dmeaning ",Object(i.jsx)("strong",{children:"To be piled up"}),'. In some sense these all come from the keyword, but as you can see it\'s a very vague idea; you can easily replace it with something like "Large", "Stacked", or "Multiple" and you don\'t lose nor gain any information. On the other hand, we can take\u300c\u672c\u300dwhich is assigned the word "Book" and see it appears in the word\u300c',Object(i.jsxs)("ruby",{children:["\u65e5",Object(i.jsx)("rt",{children:"\u306b"}),"\u672c",Object(i.jsx)("rt",{children:"\u307b\u3093"})]}),"\u300dmeaning ",Object(i.jsx)("strong",{children:"Japan"}),",\u300c",Object(i.jsxs)("ruby",{children:["\u672c",Object(i.jsx)("rt",{children:"\u307b\u3093"})]}),"\u300dmeaning ",Object(i.jsx)("strong",{children:"Book"}),",\u300c",Object(i.jsxs)("ruby",{children:["\u672c",Object(i.jsx)("rt",{children:"\u307b\u3093"}),"\u80fd",Object(i.jsx)("rt",{children:"\u306e\u3046"})]}),"\u300dmeaning ",Object(i.jsx)("strong",{children:"Instinct"}),", or\u300c",Object(i.jsxs)("ruby",{children:["\u672c",Object(i.jsx)("rt",{children:"\u307b\u3093"}),"\u6c17",Object(i.jsx)("rt",{children:"\u304d"})]}),"\u300dmeaning ",Object(i.jsx)("strong",{children:"Earnestness"}),". Here, it's quite obvious that not all of its uses are accounted for by the keyword."]}),Object(i.jsxs)("p",{children:["Of course though, some keywords are better than others, and Heisig's are overall pretty good. Although the keyword \"Heavy\" doesn't communicate all of the ideas \u300c\u91cd\u300d gives off, it ",Object(i.jsx)("i",{children:"did"}),' come pretty close in most of them, and sometimes exactly matched the meaning, as seen in\u300c\u91cd\u3044\u300d. This is something I think a lot of people neglect to bring up. Sure, a kanji like\u300c\u672c\u300ddoesn\'t solely mean "Book", but can also mean something like "Main", "Reality", or "Japan", but that doesn\'t change that it ',Object(i.jsx)("i",{children:"does"}),' does sometimes mean "Book". Overall, it does a really good job at helping you understand what basic words mean, and certainly what words using just the kanji alone mean.']}),Object(i.jsxs)("p",{children:["What this means is that going through RTK makes it easier to learn Japanese, but it alone doesn't teach you anything. The payoff in trudging through the mind-numbing memorization isn't when you finish the book. It isn't even when you first start learning grammar and words. For me, I only appreciated it after I memorized several hundred words and could begin to read basic texts by myself. This is where I began to realize that I wasn't burdened by kanji at all. One reason is that I had the ability to learn every word in its kanji-form from the get-go, meaning I do not have to worry about how frequently a word is written in kanji nor at what reading level the kanji is preferred over the kana. For example, I have seen both\u300c\u66ab\u304f\u300dand\u300c\u3057\u3070\u3089\u304f\u300d(",Object(i.jsx)("strong",{children:"For a while"}),"), as well as\u300c\u304d\u308c\u3044\u300dand\u300c\u7dba\u9e97\u300d(",Object(i.jsx)("strong",{children:"Pretty"})," or ",Object(i.jsx)("strong",{children:"Pure"}),'), while reading pretty basic texts despite both words being listed as "Usually kana" in dictionaries. Another is that knowing keywords gave huge a huge boost to my effective word-count. One of the first sentence cards I made exemplifies this:\u300c',Object(i.jsxs)("ruby",{children:["\u5c4b\u6839",Object(i.jsx)("rt",{children:"\u3084\u306d"})]}),"\u306e",Object(i.jsxs)("ruby",{children:["\u866b",Object(i.jsx)("rt",{children:"\u3080\u3057"})]}),"\u304c",Object(i.jsxs)("ruby",{children:["\u9cf4",Object(i.jsx)("rt",{children:"\u306a"})]}),"\u304f\u305e\u3088\u3002\u300d. This was my first time seeing the words\u300c\u5c4b\u6839\u300d(",Object(i.jsx)("strong",{children:"Roof"}),"), \u300c\u866b\u300d(",Object(i.jsx)("strong",{children:"Insect"}),"), or\u300c\u9cf4\u304f\u300d(",Object(i.jsx)("strong",{children:"To chirp"}),') (which is literally every single word in sentence), yet I knew exactly what the sentence meant because I could read the kanji as "Roof... roots", "Insect", and "Chirp". Of course, not every word is this straightforward. For example, good luck with\u300c',Object(i.jsxs)("ruby",{children:["\u7acb",Object(i.jsx)("rt",{children:"\u308a\u3063"}),"\u6d3e",Object(i.jsx)("rt",{children:"\u3071"})]}),"\u300d(",Object(i.jsx)("strong",{children:"Exquisite"}),') being parsed as "Stand up... faction", or\u300c',Object(i.jsxs)("ruby",{children:["\u6a5f",Object(i.jsx)("rt",{children:"\u304d"}),"\u95a2",Object(i.jsx)("rt",{children:"\u304b\u3093"})]}),"\u300d(",Object(i.jsx)("strong",{children:"Engine"})," or ",Object(i.jsx)("strong",{children:"Institution"}),') being parsed as "Mechanism... connection". However, I find that many words are, particularly in very short or very long compounds. Furthermore, I noticed that I never mistook certain kanji for others, even though they may look similar on the surface, due to the fact that rigorously going through them means they all look completely unique.']}),Object(i.jsxs)("p",{children:["However, RTK does not somehow eliminate the need to worry about kanji. It merely repositions it. And that is where its largest downfall comes in. Going through the book ",Object(i.jsx)("i",{children:"sucks"}),". A ",Object(i.jsx)("i",{children:"lot"}),". Recall that I said it takes around 180 hours total. This means that I read the book for, on average, 6 hours a day. My review time was usually around 2 hours a day (~250 cards at ~25 seconds per). I could only do this because I was an unemployed student during the summer. If I had a job? Then I could only keep this pace on the days I worked less than 4 hours - any more and I have to start swapping work for reading, meaning a full 8 hour day leaves only 2 hours of studying. If I was in school? I could maybe pull 2 hours a day during a slow part of the semester (but as I will show you, this would require it being exceptionally slow). Now, there's nothing inherently wrong with taking longer to get through RTK. After all, the kanji aren't going anywhere. However, it becomes so much harder when you do. I know this from personal experience. I originally started the book during the school year, and on an average (read: light) day I could read for maybe 30 minutes. At that pace, it would take a full ",Object(i.jsx)("i",{children:"year"}),' to finish the book (obviously this is false because the school year only lasts 8 months, but this is irrelevant given what I\'m about to say right now) and I ended up giving up 3 months in, having finished ~200 kanji, simply because I could not maintain any motivation in this journey to "learn Japanese" as I was seeing no progress -'," ",Object(i.jsx)("i",{children:"because that wasn't what I was doing."})," Getting it done in a month was doable, and 2 or 3 months might even be easier because it's less work every day, but going past 4 months seems like you would be pushing it dangerously close to the territory I was in."]}),Object(i.jsx)("p",{children:"When I started again, having forgotten basically everything more intricate than\u300c\u53e3\u300d, I realized that if I wanted to get this done, I need to get it done as fast as possible, so that this burnout cannot catch up to me again. I initially set a goal to do at least 40 kanji a day. As I ended up doing closer to 50, I upped my goal to do a minimum of 60. In the end, I was doing around 80 per day. The good thing is that despite being boring, RTK is not hard or stressful. Memorizing kanji becomes fairly easy after your first 100, and although diminishing returns set in pretty quickly afterward, it does become slightly easier with each extra one you learn. This means that whether I spent 4 hours or 8 hours reading the book and creating these stories, I was just as effective at the beginning as I was at the end, and I didn't feel mentally fatigued. A digression: I wish reading maths textbooks was this easy - I start becoming antsy and frustrated after around an hour of reading and struggle to comprehend anything after the second. Even with breaks, it is hard to do anything more than 2-4 hours in a day."}),Object(i.jsxs)("p",{children:["However, I would occasionally encounter kanji for which I could not come up with a compelling story. Interestingly, this had nothing to do with the number of strokes, position in the book, ambiguity in the keyword, or anything like that. It seemed to happen at random. Notable examples that I recorded were\u300c\u654f\u300d,\u300c\u6cb3\u300d,\u300c\u8cbc\u300d,\u300c\u8aad\u300d,\u300c\u5224\u300d,\u300c\u932f\u300d, and, rather embarrassingly,\u300c\u5f15\u300d. However, I obviously know all of these now, so what did I do to make the story compelling? Well, I slightly ignored Heisig. For some of these, I just brute-forced them in Anki until I got them. I really do not recommend doing this, because if you forget them later, you're screwed, as you have nothing to fall back on. There are a handful (literally, as in less than 10) of kanji for which I did this. For others, I used some cheap tricks such as verbal mnemonics. Heisig covers in detail why these shouldn't be the primary approach (basically it's because visual imagery is usually an intuitive response to the words, whereas verbal tricks have no basis), however if the words prompt nothing, it's better than brute-force. The most helpful backup, however, was"," ",Object(i.jsx)("a",{className:"linkPurple",href:"https://kanji.koohii.com/",children:"Kanji Koohii"})," (however I used it indirectly through"," ",Object(i.jsx)("a",{className:"linkPurple",href:"https://hochanh.github.io/rtk/",children:"rtk-search"}),"). Although those stories weren't my personal stories, they were stories nonetheless, and oftentimes I didn't need to rip a full one from a user, but just read some to get inspired."]}),Object(i.jsxs)("p",{children:['There is another reason to use these websites, and that is to correct some of Heisig\'s mistakes. There are a few suspicious keywords, such as using "Ghost" for\u300c\u9b3c\u300dinstead of just saying "Oni", giving\u300c\u6821\u300dthe keyword "Exam" despite it appearing in every single word involving schools ',Object(i.jsx)("i",{children:"and"}),' the word "School" never being used as a keyword elsewhere, or teaching only the simplified kanji for'," ",Object(i.jsx)("strong",{children:"Dragon"}),",\u300c",Object(i.jsxs)("ruby",{children:["\u7adc",Object(i.jsx)("rt",{children:"\u308a\u3085\u3046"})]}),'\u300d, despite\u300c\u9f8d\u300dalso being extremely common (enough to be a top-1800 kanji despite not being j\u014dy\u014d) and looking sick (it\'s the only kanji I\'ve memorized through stroke-order alone). There are also better meanings to give to kanji as radicals: assigning\u300c\u7cf8\u300dthe meaning of "Spiderman" on the left and "Venom" on the bottom, rather than the dull "Thread" wherever, makes all its derivatives fairly easy. There are also a few ingenious stories made by some users, such as user fiminor coming up with one story to encapsulate\u300c\u9678\u300d,\u300c\u7766\u300d,\u300c\u52e2\u300d,\u300c\u71b1\u300d,\u300c\u83f1\u300d, and\u300c\u9675\u300d. In general, I would check the user-submitted stories for each kanji before I moved on, even if I made a good story myself, to make sure I would be aware of these things.']}),Object(i.jsxs)("p",{children:['In order to come up with these good stories in the first place, there are a few things I found helpful to keep in mind. The biggest, by far, is to try to combine multiple kanji into one story. Heisig\'s book orders the kanji in a way that naturally lends itself to this, and there are around 100-200 kanji that I learned "for free", as I didn\'t have to come up with a separate story for them. For example, I did this for\u300c\u76e3\u300d,\u300c\u89a7\u300d,\u300c\u6feb\u300d, and\u300c\u9451\u300d, and I continue to do this today when I encounter new kanji (which I will discuss in detail soon) such as appending\u300c\u7dbe\u300dto fiminor\'s saga. I also found it important to give very specific images. For example, I struggled to distinguish\u300c\u5e1d\u300dand\u300c\u738b\u300dbecause both of their keywords ("Sovereign" and "King", respectively) are pretty similar and I pictured generic male royalty for both. I solved this by emphasizing a sceptre held in the latter (as I took it to be a pictograph of one), and picturing Julius Caesar in the former. When the primitive "Altar" came up, it appears to the left as in\u300c\u8996\u300dor underneath as in\u300c\u6b3e\u300d, and I always pictured the former as more of a statue and the latter as an offering table, in order to identify their physical position in the kanji. I also tried to include real-life components, such as friends or recounting events, to have a stronger and more grounded story. For example, for\u300c\u68a2\u300dthe keyword "Treetop" and components "Tree... extinguish" reminded me of the time I went to the Arashiyama grove with my friend, who insisted there would be lights on, only to get off the train at night and walk to a completely pitch-black set of treetops. Be aware though that sometimes you ',Object(i.jsx)("i",{children:"don't"}),' need intricate stories for kanji. Something like\u300c\u5206\u300dwith the keyword "Part" can be taken instantly as a pictograph of a dagger splitting a board (or something). In general, I felt that it was only around kanji 1000 or so that I got a feel for kanji and could feel that certain combinations or positions were unnatural, and began to play fast-and-loose with my stories; before that I kept everything very deliberate.']}),Object(i.jsx)("p",{children:'That is essentially all the advice I can give. Going through RTK is a fairly personal journey, and like I mentioned before, you will struggle at seemingly random points that others will not, and likely find kanji someone else finds exceedingly hard to be quite straightforward. Overall, I found the hardest part of the book to be the section of around 20 kanji beginning at number 595, where Heisig introduces the "Turkey" primitive (funnily enough, I use the memory of my struggle here to remember the later-learned\u300c\u96e3\u300d, given the keyword "Difficult"). The hardest kanji to come up with stories for were\u300c\u85cd\u300dand\u300c\u74bd\u300d, although I don\'t think either of these took longer than 15 minutes. Mentally, the hardest parts were around kanji 700 and 1400, where I really wanted to quit for no particular reason other than being sick of the book and doing flashcards.'}),Object(i.jsxs)("p",{children:["The kanji\u300c\u74bd\u300dbrings up an important critique of Heisig's RTK too. An analysis of around 800 million kanji uses,"," ",Object(i.jsx)("a",{className:"linkPurple",href:"http://scriptin.github.io/kanji-frequency/",children:"available here"}),", lists it as the 2938th most used character in the best case, Wikipedia, and in one week of Twitter analysis it never came up at all. For some context, 1500 kanji generally gives you 97-99% coverage, depending on the material. So why is it in Heisig's book? Because the j\u014dy\u014d list has nothing to do with frequency. Sure, some (actually, a supermajority of) parts conveniently overlap, but the list is just a set of characters approved for general-use (as is the literal name). Due to the nature of kanji and literacy that I discussed at the beginning, it should be clear that the government needs some official list to which they can adhere, and so they need to ensure political topics are covered, which is why that kanji (keyword \"Imperial Seal\") made the cut. Do you need to know it? I doubt it. Thankfully, it's near the end of the book, so you can skip it without a loss. However, there are many kanji like this that appear throughout Heisig's book, and in general, the order in which they are presented in RTK has nothing to do with how important they are. This poses to me a problem much more significant than learning a few scores of uncommon kanji - an absurdly large amount of the most common kanji appear near the end of the book. And unfortunately, you can't skip to them and do them first (generally speaking), because they are built upon kanji learned earlier, so the method won't work. Plus, the first 500 or so kanji in the book have exposition written by Heisig through which he slowly teaches you how to come up with stories on your own; immediately skipping to\u300c\u5e30\u300dand reading \"Spear... broom... apron\" will seem impossible to handle. This means Heisig's book loses a lot of its usefulness unless you're willing to push to at least the 1600 or 1800 mark."]}),Object(i.jsxs)("p",{children:["This also means a few fairly simple kanji that ",Object(i.jsx)("i",{children:"aren't"})," j\u014dy\u014d, such as the\u300c\u5b09\u300dof\u300c",Object(i.jsxs)("ruby",{children:["\u5b09",Object(i.jsx)("rt",{children:"\u3046\u308c"})]}),"\u3057\u3044\u300d(",Object(i.jsx)("strong",{children:"Pleased"}),") or both kanji in\u300c",Object(i.jsxs)("ruby",{children:["\u55a7",Object(i.jsx)("rt",{children:"\u3051\u3093"}),"\u5629",Object(i.jsx)("rt",{children:"\u304b"})]}),"\u300d(",Object(i.jsx)("strong",{children:"Argument"}),"), hence are not in RTK. However, this doesn't really matter, because there aren't too many of them, and once you've gotten that far learning new kanji is very easy. Whenever they come up, I don't need to sit down for 5 minutes again and try to look up stories online. The whole process (plus coming up with a keyword on my own!) - identifying components and making a story - rarely takes more than 45 seconds. And since you are learning at most 5 new ones in a day, you won't forgot them. This is another thing that I refer to when I say I don't have to worry about kanji anymore: that handling them now is second nature."]}),Object(i.jsxs)("p",{children:["Those are my thoughts on Heisig's ",Object(i.jsx)("i",{children:"Remembering the Kanji"}),". I found it incredibly helpful. I was free for a summer, grinded out the book in a very short amount of time, and began learning Japanese with a large effective-vocabulary, an easy time memorizing new words, never stressing when I encountered new kanji - which happened fairly rarely anyways - and never having to worry about not knowing enough kanji to read a piece of literature. At the same time, I tried it beforehand and (thankfully only temporarily) gave up on learning the language and wasted a few months of my time, but potentially could've turned a blind-eye to Japanese for the rest of my life. Is it worth it? That's for you to decide. I've experienced the good and the bad, and laid out to you why and when that happened. Hopefully that makes the decision simple for you. And if you choose to go through with it, hopefully my advice can help you through from learning\u300c\u4e00\u300dall the way to\u300c\u5df3\u300d."]})]})}}]),a}(n.Component),z=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsx)("table",{class:"figureContainer",children:Object(i.jsx)("tr",{children:Object(i.jsx)("td",{class:"figure",children:Object(i.jsx)("img",{src:this.props.src,alt:""})})})})}}]),a}(n.Component),W=a.p+"static/media/svg1.5c1a4c20.svg",R=a.p+"static/media/svg2.f20d0332.svg",F=a.p+"static/media/svg3.cecf0205.svg",H=a.p+"static/media/svg4.0e4d54c2.svg",C=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"componentDidMount",value:function(){window.KaTeXRender()}},{key:"render",value:function(){return Object(i.jsxs)("div",{class:"postContent leftMargin",children:[Object(i.jsxs)("p",{children:["While reading Aluffi's ",Object(i.jsx)("i",{children:"Algebra: Chapter 0"})," and finishing the proofs for the isomorphism theorems for modules, I began to grow slightly suspect that there was something going on behind the scenes, as the proofs were exactly the same as the ones for rings, which were the same as the ones for groups. Presented in his book, they all essentially stem from the fact that for a set-map \\(f:A\\longrightarrow B\\) and the equivalence relation \\(\\sim\\) defined by \\(a\\sim b\\) if and only if \\(f(a)=f(b)\\),"]}),Object(i.jsx)(z,{src:W}),Object(i.jsx)("p",{style:{textIndent:"0"},children:"where \\(\\pi_\\sim\\) is the projection to the equivalence class: \\(\\pi_\\sim(a)=[a]_\\sim\\)."}),Object(i.jsxs)("p",{children:["How do we know ","\\(\\tilde{f}\\)"," exists, let alone is unique? As the diagram must commute, given any"," ","\\(\\tilde{f}: A/\\!\\!\\sim\\longrightarrow B\\)"," we must have"," ","\\(\\tilde{f}\\circ\\pi_\\sim(a)=f(a)\\)"," for all \\(a\\in A\\), and so ","\\(\\tilde{f}\\)"," is forced to be \\([a]_\\sim\\mapsto f(a)\\). This is well-defined, recalling our definition of \\(\\sim\\). In recognition of the fact that this map is unique and can be deduced from any arbitrary set-map, we say that this quotient, \\(A/\\!\\!\\sim\\), satisfies a ",Object(i.jsx)("strong",{children:"universal property"})," in a particular category."]}),Object(i.jsxs)("p",{children:["What is a ",Object(i.jsx)("strong",{children:"category"}),"? It is just a collection of objects and ",Object(i.jsx)("strong",{children:"morphisms"})," between them, which are just ways to send one object to another. There are also a few checkmarks to glance over (such as existence of an identity and composition) to make sure your morphisms behave well, however they are not too important for us to formally cover. Above, for example, our objects are the ordered pair \\((B,f)\\) where \\(B\\) is a set and \\(f\\) is a map \\(A\\longrightarrow B\\); it is much cleaner to write them as a diagram"]}),Object(i.jsx)(z,{src:R}),Object(i.jsx)("p",{children:'A morphism between two objects \\((B,f)\\) and \\((C,g)\\) must then be some way to transform the map \\(f:A\\longrightarrow B\\) to \\(g:A\\longrightarrow C\\). This can be done by any map \\(j:B\\longrightarrow C\\) such that \\(j\\circ f = g\\); lucidity can be found by thinking of \\(j\\) as a morphism "between diagrams", meaning the following commutes:'}),Object(i.jsx)(z,{src:F}),Object(i.jsxs)("p",{children:["Note that we are not guaranteed to have such a \\(j\\) to exist. However, this diagram seems awfully suspicious to the one involving quotients at the very beginning, and that is because one does exist there. In fact we say \\(A/\\!\\!\\sim\\) (or rather, the diagram represented by \\((A/\\!\\!\\sim,\\pi_\\sim)\\)) is ",Object(i.jsx)("strong",{children:"initial"})," ","in this category, because there exists a unique morphism from it to any other object."]}),Object(i.jsx)("p",{children:"Now, with the concept of universal properties clarified, one can consider the canonical decomposition of our original map \\(f\\), which is the commutative diagram"}),Object(i.jsx)(z,{src:H}),Object(i.jsxs)("p",{children:["From here, much of the work in proving the isomorphism theorems is done. Indeed, this is because groups and rings all have underlying sets, and we can restrict ourselves by ensuring \\(f\\) is a homomorphism, as that is just a set-map which preserves the artificially-imposed structure. The formal way to do this is to work in a separate category, such as ","\\(\\mathbf{Grp}\\)",", whose objects are groups and morphisms are group homomorphisms - precisely these structure-preserving set-maps. Once in this domain, define the quotient and prove it is initial again, and we can see why the first isomorphism theorem holds instantly, as if \\(f\\) is a surjective homomorphism then ","\\(\\mathrm{im}\\,f = B\\)",". Note that I didn't even specify what type of homomorphism \\(f\\) was; the reasoning holds identically for groups, rings, and modules. The remaining theorems just aim to construct such a surjective \\(f\\)."]}),Object(i.jsxs)("p",{children:["Above, however, is a massive asterisk. It is not always straightforward to define \\(\\sim\\). For example, in"," ","\\(\\mathbf{Grp}\\)"," we cannot merely take a subgroup, but must also insist it is normal. Meanwhile in ","\\(\\mathbf{Ring}\\)",', we don\'t even bother with subrings, and instead provide the (rather obtuse, if you arrive directly from subgroups) definition of an ideal. This is where my suspicion mentioned at the beginning was inlaid - is there any relationship between these quotients? Although algebra is often tautological in this way, with definitions being nice to work with because the definitions were changed until they were (c.f. the word "normal" appearing everywhere), it seemed too coincidental that a quotient could always be found, regardless of what structure was imposed. My suspicion lasted merely a few minutes, however, because the simple query "isomorphism theorems" immediately led to the answer - universal algebra.']}),Object(i.jsxs)("p",{children:["Universal algebra begins by recognizing that all of these different structures boil down to two things - a set with operations. In particular, we call \\(f\\) an \\(n\\)-",Object(i.jsx)("strong",{children:"ary operation"})," on a set \\(A\\) if \\(f:A^n\\longrightarrow A\\). Then, we define a"," ",Object(i.jsx)("strong",{children:"type"})," to be a set"," ","\\(\\mathfrak{F}=\\left\\{(f_1,n_1),(f_2,n_2),\\dots\\right\\}\\)"," ","where each \\(f_i\\) is called an \\(n_i\\)-",Object(i.jsx)("strong",{children:"ary operation symbol"}),". Be aware that the subscript will be dropped if distinguishing it from another symbol is not of concern. An ",Object(i.jsx)("strong",{children:"algebra"})," ","\\(\\mathcal{A}\\)"," of type"," ","\\(\\mathfrak{F}\\)"," is just an ordered pair \\((A,F)\\) where \\(A\\) is a set and \\(F\\) is a set of \\(n\\)-ary operations so that for each \\(n_i\\)-ary operation symbol ","\\(f_i\\in\\mathfrak{F}\\)",", there is a corresponding \\(n_i\\)-ary operation ","\\(f_i^\\mathcal{A}\\in F\\)",". We call \\(A\\) the ",Object(i.jsx)("strong",{children:"universe"})," of"," ","\\(\\mathcal{A}\\)"," and \\(F\\) its"," ",Object(i.jsx)("strong",{children:"fundamental operations"}),"."]}),Object(i.jsxs)("p",{children:["For example, an algebra ","\\(\\mathcal{G}\\)"," of type"," ","\\(\\mathfrak{F}=\\left\\{(1,0),(^{-1},1),(\\cdot,2)\\right\\}\\)"," ","is an ordered pair \\((G,F)\\) with \\(G\\) any set and \\(F\\) a set containing a nullary (\u203d), unary, and binary operation on \\(G\\). What is a nullary operation? It must be an operation which returns something despite taking in no inputs - in other words, a constant function. We write ","\\(\\mathcal{G}=(G,1,^{-1},\\cdot)\\)"," to consolidate our operations in \\(F\\) with the symbols in"," ","\\(\\mathfrak{F}\\)",". We call ","\\(\\mathcal{G}\\)"," a"," ",Object(i.jsx)("strong",{children:"group"})," if","\n                    \\[\n                    \\begin{aligned}\n                    &\\cdot (1,x)=x=\\cdot\\,(x,1);\\\\\n                    &\\cdot(x,^{-1}\\!(x))=1=\\cdot\\,(^{-1}\\!(x),x);\\\\\n                    &\\cdot(x,y\\cdot z)=\\cdot\\,(x\\cdot y,z).\n                    \\end{aligned}\n                    \\]\n                    "]}),Object(i.jsxs)("p",{children:["This is all looks quite cumbersome when written strictly treating these operations as functions. Thankfully, by taking liberty with the operation symbols, and giving the element to which \\(1\\) maps a rather suggestive symbol like \\(e\\), we can intuitively rewrite this as","\n                    \\[\n                        \\begin{aligned}\n                        &e\\cdot x=x=x\\cdot e;\\\\\n                        &x\\cdot x^{-1}=e=x^{-1}\\cdot x;\\\\\n                        &x\\cdot(y\\cdot z)=(x\\cdot y)\\cdot z.\n                        \\end{aligned}\n                    \\]\n                    ","This is all very familiar - after all, it is just a group. However, note that we have fully described it without using any quantifying symbols. For example, the existence of an identity isn't denoted by \"For all ","\\(x\\in\\mathcal{G}\\)",'...", but rather a consequence of an operation and how it interacts with other operations.']}),Object(i.jsxs)("p",{children:["What might our subgroups look like? We know we need them to behave like a regular algebra on their own, but also be identified within its parent. So, for two algebras ","\\(\\mathcal{A}=(A,F_A)\\)"," and"," ","\\(\\mathcal{B}=(B,F_B)\\)"," of type ","\\(\\mathfrak{F}\\)",", we say that ","\\(\\mathcal{B}\\)"," is a ",Object(i.jsx)("strong",{children:"subalgebra"})," of"," ","\\(\\mathcal{A}\\)"," if its universe is a"," ",Object(i.jsx)("strong",{children:"subuniverse"})," of ","\\(\\mathcal{A}\\)",", meaning \\(B\\subseteq A\\) and \\(B\\) is closed under \\(F_A\\), and the operations on ","\\(\\mathcal{B}\\)"," can be recovered by restricting the ones on"," ","\\(\\mathcal{A}\\)",", meaning","\n                    \\[\n                        f^\\mathcal{B}_i(b_1,\\cdots,b_n)=f^\\mathcal{A}_i\\vert_\\mathcal{B}(b_1,\\dots,b_n)\n                    \\]\n                    ","for all ","\\(f^\\mathcal{B}_i\\in F_B\\)"," and"," ","\\(f^\\mathcal{A}_i\\in F_A\\)","."]}),Object(i.jsxs)("p",{children:["Now, take an algebra ","\\(\\mathcal{A}=(A,F)\\)"," of type"," ","\\(\\mathfrak{F}\\)",". Let \\(\\sim\\) be an equivalence relation on"," ","\\(\\mathcal{A}\\)",". It is important that we recall the set definition of an equivalence relation:","\n                    \\[\n                        \n\\sim\\,=\\left\\{(a,b)\\in A\\times A: \\mathrm{ (1), (2), (3)}\\right\\}\n\n                    \\]\n\n                    \\[\n                        \n a\\in A\\Rightarrow (a,a)\\in A;\n\n                    \\]\n\n                    \\[ \n                        \n(a,b),(b,c)\\in A\\Rightarrow (a,c)\\in A;\n\n                    \\]\n\n                    \\[\n                        \n(a,b)\\in A\\Rightarrow (b,a)\\in A.\n\n                    \\] \n                    ","We call \\(\\sim\\) a ",Object(i.jsx)("strong",{children:"congruence"})," on"," ","\\(\\mathcal{A}\\)"," if given any \\(n\\)-ary"," ","\\(f\\in\\mathfrak{F}\\)"," and for all \\(1\\leq i\\leq n\\), we have","\n                    \\[\na_i\\sim b_i\\Rightarrow f^\\mathcal{A}(a_1,\\dots,a_n)\\sim f^\\mathcal{A}(b_1,\\dots,b_n).\n\\]\n                    ","The definition of congruence is reminiscent of normal subgroups. The set of all congruences on ","\\(\\mathcal{A}\\)"," is denoted"," ","\\(\\mathrm{Con}\\,\\mathcal{A}\\)",". An element of this that we will need in the distant future is \\(\\nabla_A=A\\times A\\), called the"," ",Object(i.jsx)("strong",{children:"all relation"}),"."]}),Object(i.jsxs)("p",{children:["Naturally then, we go on to define quotients. For any \\(a\\in A\\) we call the equivalence class under \\(\\sim\\) the set","\\[\na/\\!\\!\\sim\\,=\\left\\{b\\in\\mathcal{A}:a\\sim b\\right\\}\n\\]","and then we denote quotient of \\(A\\) by \\(\\sim\\) to be","\\[\nA/\\!\\!\\sim\\,=\\left\\{a/\\!\\!\\sim:a\\in A\\right\\}.\n\\]"]}),Object(i.jsxs)("p",{children:["Note that for the above, congruencey isn't important at all. Any equivalence relation will do. However, to define an algebra with universe \\(A/\\!\\!\\sim\\) that carries over the operations from"," ","\\(\\mathcal{A}\\)",", we need the following to be well-defined:","\\[\nf^{\\mathcal{A}/\\sim}(a_1/\\!\\!\\sim,\\dots,a_n/\\!\\!\\sim)=f^\\mathcal{A}(a_1,\\dots,a_n)/\\!\\!\\sim.\n\\]","Indeed, congruences let us achieve that. We then say the quotient algebra of ","\\(\\mathcal{A}\\)"," by \\(\\sim\\),"," ","\\(\\mathcal{A}/\\!\\!\\sim\\)",", is the algebra \\((A/\\!\\!\\sim,F_\\sim)\\) where \\(F_\\sim\\) is simply the set operations gained after performing the above for all \\(f\\in F\\). Note that"," ","\\(\\mathcal{A}/\\!\\!\\sim\\)"," is clearly also an algebra of type"," ","\\(\\mathfrak{F}\\)",". Of note is that quotients, in a sense, preserve inclusions:"]}),Object(i.jsx)(_,{no:"1",statement:"\r Let \\(\\sim_1,\\sim_2\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\) so that \\(\\sim_2\\,\\subseteq\\,\\sim_1\\). Then, \\(\\sim_1\\! /\\!\\sim_2\\) is a congruence on \\(\\mathcal{A}/\\!\\!\\sim_2\\)."}),Object(i.jsx)(k,{proof:"\r Take some \\((\\alpha_i,\\beta_i)\\in\\sim_1\\!/\\!\\sim_2\\) for \\(1\\leq i\\leq n\\). Then, \\((\\alpha_i,\\beta_i)=(a_i/\\!\\!\\sim_2,b_i/\\!\\!\\sim_2)\\) where \\((a_i,b_i)\\in\\,\\sim_1\\). As \\(\\sim_1\\) is a congruence, we know for any \\(n\\)-ary \\(f\\), it holds that\r \\[\r (f^\\mathcal{A}(a_1,\\dots,a_n),f^\\mathcal{A}(b_1,\\dots,b_n))\\in\\,\\sim_1\r \\]\r and so\r \\[\r \\begin{aligned}\r (f^\\mathcal{A}&(a_1,\\dots,a_n)/\\!\\!\\sim_2,f^\\mathcal{A}(b_1,\\dots,b_n)/\\!\\!\\sim_2)= \\\\\r &(f^{\\mathcal{A}/\\sim_2}(a_1/\\!\\!\\sim_2,\\dots,a_n/\\!\\!\\sim_2),f^{\\mathcal{A}/\\sim_2}(b_1/\\!\\!\\sim_2,\\dots,b_n/\\!\\!\\sim_2)\\in\\sim_1\\! /\\!\\!\\sim_2\r \\end{aligned}\r \\]\r because \\(\\sim_2\\) is also a congruence. "}),Object(i.jsxs)("p",{children:["The last thing we need is a way to communicate between different algebras. This is done as one would expect. Given two algebras"," ","\\(\\mathcal{A}=(A,F_A)\\)"," and ","\\(\\mathcal{B}=(B,F_B)\\)"," of type ","\\(\\mathfrak{F}\\)",", a map \\(\\alpha:A\\longrightarrow B\\) is called an ",Object(i.jsx)("strong",{children:"algebra homomorphism"})," between"," ","\\(\\mathcal{A}\\)"," and ","\\(\\mathcal{B}\\)"," if","\\[\n\\alpha f_i^\\mathcal{A}(a_1,\\dots,a_n)=f_i^\\mathcal{B}(\\alpha a_1,\\dots,\\alpha a_n)\n\\]","for every ","\\(f_i\\in\\mathfrak{F}\\)",". We call a homomorphism an"," ",Object(i.jsx)("strong",{children:"isomorphism"})," if the underlying map is bijective."]}),Object(i.jsxs)("p",{children:["We immediately have a homomorphism at our disposal. First, we define the ",Object(i.jsx)("strong",{children:"natural map"})," \\(\\nu_\\sim:A\\longrightarrow A/\\!\\!\\sim\\) to be \\(a\\mapsto a/\\!\\!\\sim\\). We call the homomorphism it induces the ",Object(i.jsx)("strong",{children:"natural homomorphism"}),". But is it actually a homomorphism, or am I lying?"]}),Object(i.jsx)(_,{no:"1",statement:"\r The natural map is a homomorphism from \\(\\mathcal{A}\\) to \\(\\mathcal{A}/\\!\\!\\sim\\)."}),Object(i.jsx)(k,{proof:"\r Take some \\(n\\)-ary operation symbol \\(f\\) in type \\(\\mathfrak{F}\\) of \\(\\mathcal{A}\\) and \\(a_1,\\dots,a_n\\in A\\). Then,\r \\[\r \\begin{aligned}\r \\nu_\\sim f^\\mathcal{A}(a_1,\\dots,a_n)&=f^\\mathcal{A}(a_1,\\dots,a_n)/\\!\\!\\sim\\\\\r &=f^{\\mathcal{A}/\\sim}(a_1/\\!\\!\\sim,\\dots,a_n/\\!\\!\\sim)\\\\\r &=f^{\\mathcal{A}/\\sim}(\\nu_\\sim a_1,\\dots,\\nu_\\sim a_n)\r \\end{aligned}\r \\] \r so indeed, my conscience is clean. "}),Object(i.jsxs)("p",{children:["The ",Object(i.jsx)("strong",{children:"kernel"}),' of a homomorphism has a definition that seems slightly odd, however recall that we can\'t freely speak about "sending elements to zero" or anything of the sort, since that hinges on a specific choice of operations and identities. So, we instead define it as',"\\[\n\\mathrm{ker}(\\alpha)=\\left\\{(a,b)\\in A\\times A: \\alpha(a)=\\alpha(b)\\right\\}.\n\\]","Note that if we take this definition and return to our definition of a group, for example, we quickly recover the usual definition of kernel."]}),Object(i.jsx)("p",{children:"Now, we have all the background we need to dig into the theorems. First, we handle some grunt-work."}),Object(i.jsx)(_,{no:"3",statement:"\r The kernel of a homomorphism \\(\\alpha:\\mathcal{A}\\longrightarrow\\mathcal{B}\\) is a congruence on \\(\\mathcal{A}\\)."}),Object(i.jsx)(k,{proof:"\r Take some \\(n\\)-ary \\(f\\) and Let \\((a_i,b_i)\\in\\mathrm{ker}\\,\\alpha\\) for \\(1\\leq i\\leq n\\). Then,\r \\[\r \\begin{aligned}\r \\alpha f^\\mathcal{A}(a_1,\\dots,a_n)&=f^\\mathcal{B}(\\alpha a_1,\\dots,\\alpha a_n)\\\\\r &=f^\\mathcal{B}(\\alpha b_1,\\dots,\\alpha b_n)\\\\\r &=\\alpha f^\\mathcal{A}(b_1,\\dots,b_n)\r \\end{aligned}\r \\]\r meaning \\((f^\\mathcal{A}(a_1,\\dots,a_n),f^\\mathcal{A}(b_1,\\dots,b_n))\\in\\mathrm{ker}\\,\\alpha\\)."}),Object(i.jsx)(_,{no:"4",statement:"\r Given homomorphisms \\(\\alpha:\\mathcal{A}\\longrightarrow\\mathcal{B}\\) and \\(\\beta:\\mathcal{B}\\longrightarrow\\mathcal{C}\\), the composition of the set-maps \\(\\beta\\circ\\alpha:A\\longrightarrow C\\) is a homomorphism from \\(\\mathcal{B}\\) to \\(\\mathcal{C}\\)."}),Object(i.jsx)(k,{proof:"\r Take some \\(n\\)-ary \\(f\\), and let \\(a_1,\\dots,a_n\\in A\\). Then,\r \\[\r \\begin{aligned}\r \\beta\\circ\\alpha f^\\mathcal{A}(a_1,\\dots,a_n)&=\\beta(\\alpha   f^\\mathcal{A}(a_1,\\dots,a_n))\\\\\r &=\\beta f^\\mathcal{B}(\\alpha a_1,\\dots,\\alpha a_n)\\\\\r &=f^\\mathcal{C}(\\beta(\\alpha a_1),\\dots,\\beta(\\alpha a_n))\\\\\r &=f^\\mathcal{C}(\\beta\\circ\\alpha a_1,\\dots,\\beta\\circ\\alpha a_n)\r \\end{aligned}\r \\]\r as desired. "}),Object(i.jsx)("p",{children:"Now, we tackle the first big result."}),Object(i.jsx)(_,{no:"5",name:"First Isomorphism Theorem (FIT)",statement:"\r If \\(\\alpha:\\mathcal{A}\\longrightarrow\\mathcal{B}\\) is a surjective homomorphism, then there exists an isomorphism from \\(\\mathcal{A}/\\mathrm{ker}\\,\\alpha\\) to \\(\\mathcal{B}\\). In particular, this isomorphism is defined by \\(a_{\\mathrm{ker}\\,\\alpha}\\mapsto\\alpha a\\).\r "}),Object(i.jsx)(k,{proof:"\r Let \\(\\beta:A/\\mathrm{ker}\\,\\alpha\\longrightarrow B\\) be the above mapping. Given some \\(b\\in B\\), we know there exists some \\(a\\in A\\) so that \\(\\alpha a=b\\), by hypothesis. Then, \\(\\beta a_{\\mathrm{ker}\\,\\alpha}=b\\), so our map is surjective. Suppose now we have \\(\\beta a_{\\mathrm{ker}\\,\\alpha} =\\beta a'_{\\mathrm{ker}\\,\\alpha} \\). Thus, \\(\\alpha a=\\alpha a'\\), however this means \\((a,a')\\in\\mathrm{ker}\\,\\alpha\\), and thus \\( a_{\\mathrm{ker}\\alpha}=a'_{\\mathrm{ker}\\,\\alpha}\\), so our map is injective.\\[\\]\r We just need to verify \\(\\beta\\) plays nice with our operations. So, take some \\(n\\)-ary \\(f\\) and \\(a_1,\\dots,a_n\\in A\\), and we see\r \\[\r \\begin{aligned}\r \\beta(f^{\\mathcal{A}/\\mathrm{ker}\\,\\alpha}(a_1/\\mathrm{ker}\\,\\alpha,\\dots,a_n/\\mathrm{ker}\\,\\alpha))&=\\beta(f^\\mathcal{A}(a_1,\\dots,a_n)/\\mathrm{ker}\\,\\alpha)\\\\\r &=\\alpha f^\\mathcal{A}(a_1,\\dots,a_n)\\\\\r &=f^\\mathcal{B}(\\alpha a_1,\\dots,\\alpha a_n)\\\\\r &=f^\\mathcal{B}(\\beta(a_1/\\mathrm{ker}\\,\\alpha),\\dots,\\beta(a_n/\\mathrm{ker}\\,\\alpha))\r \\end{aligned}\r \\]\r so \\(\\beta\\) is indeed a homomorphism."}),Object(i.jsx)("p",{children:"Using (2) and (4), we opt to write \\(\\alpha=\\beta\\circ\\nu_\\sim\\) to encapsulate the definition of \\(\\beta\\). Next, we recall (1) from the very beginning, and out-of-order tackle the third theorem:"}),Object(i.jsx)(_,{no:"6",name:"Third Isomorphism Theorem",statement:"\r If \\(\\sim_1,\\sim_2\\,\\in\\mathrm{Con}\\,A\\) with \\(\\sim_2\\,\\subseteq\\,\\sim_1\\), then\r \\[\r \\alpha:\\frac{A/\\!\\!\\sim_2}{\\sim_1\\! /\\!\\!\\sim_2}\\longrightarrow A/\\!\\!\\sim_1\\quad\\mathrm{by}\\quad \\frac{a/\\!\\!\\sim_2}{\\sim_1\\! /\\!\\!\\sim_2}\\mapsto a/\\!\\!\\sim_1\r \\]\r is an isomorphism from \\(\\frac{\\mathcal{A}/\\sim_2}{\\sim_1 /\\sim_2}\\) to \\(\\mathcal{A}/\\!\\!\\sim_1\\)."}),Object(i.jsx)(k,{proof:"\r Consider the map \\(\\alpha':A/\\!\\!\\sim_2\\longrightarrow A/\\!\\!\\sim_1\\) defined by \\(a/\\!\\!\\sim_2\\,\\mapsto a/\\!\\!\\sim_1\\). We see that this is well-defined, for if \\(a/\\!\\!\\sim_2=b/\\!\\!\\sim_2\\), then \\((a,b)\\in\\sim_2\\), and by inclusion, \\((a,b)\\in\\,\\sim_1\\) so \\(a/\\!\\!\\sim_1=b/\\!\\!\\sim_1\\). Now, take any \\(a/\\!\\!\\sim_1\\,\\in A/\\!\\!\\sim_1\\), and it clear that \\(\\alpha'(a/\\!\\!\\sim_2)\\) reaches this element. Thus, \\(\\alpha'\\) is surjective.\\[\\]\r Take now any \\(n\\)-ary \\(f\\), and \\(a_1/\\!\\!\\sim_2,\\dots,a_n/\\!\\!\\sim_2\\,\\in A/\\!\\!\\sim_2\\). We see\r \\[\r \\begin{aligned}\r \\alpha'f^{\\mathcal{A}/\\sim_2}(a_1/\\!\\!\\sim_2,\\dots,a_n/\\!\\!\\sim_2)&=\\alpha'(f^\\mathcal{A}(a_1,\\dots,a_n)/\\!\\!\\sim_2)\\\\\r &=f^\\mathcal{A}(a_1,\\dots,a_n)/\\!\\!\\sim_1\\\\\r &=f^{\\mathcal{A}/\\sim_1}(a_1/\\!\\!\\sim_1,\\dots,a_n/\\!\\!\\sim_1)\\\\\r &=f^{\\mathcal{A}/\\sim_1}(\\alpha'(a_1/\\!\\!\\sim_2),\\dots,\\alpha'(a_n/\\!\\!\\sim_2))\r \\end{aligned}\r \\]\r so this is actually a homomorphism as well. Now, take note that\r \\[\r \\begin{aligned}\r \\mathrm{ker}\\,\\alpha'&=\\left\\{(a/\\!\\!\\sim_2,b/\\!\\!\\sim_2)\\in (A/\\!\\!\\sim_2)^2:\\alpha'(a/\\!\\!\\sim_2)=\\alpha'(b/\\!\\!\\sim_2)\\right\\}\\\\\r &=\\left\\{(a/\\!\\!\\sim_2,b/\\!\\!\\sim_2)\\in (A/\\!\\!\\sim_2)^2:a/\\!\\!\\sim_1=b/\\!\\!\\sim_1\\right\\}\\\\\r &=\\left\\{(a/\\!\\!\\sim_2,b/\\!\\!\\sim_2)\\in (A/\\!\\!\\sim_2)^2:(a,b)\\in\\sim_1\\right\\}\\\\\r &=\\,\\sim_1\\! /\\!\\!\\sim_2\r \\end{aligned}\r \\]\r so by (FIT),\r \\[\r \\frac{A/\\!\\!\\sim_2}{\\sim_1\\! /\\!\\!\\sim_2}\\cong A/\\!\\!\\sim_1 \r \\]\r and we see indeed taking \\(\\alpha'=\\alpha\\circ\\nu_{\\sim_1/\\sim_2}\\) gives the claimed mapping."}),Object(i.jsxs)("p",{children:["We now need one more definition. Take an algebra"," ","\\(\\mathcal{A}\\)"," and take any \\(B\\subseteq A\\). Then, we define","\\[\n\\bigcap\\left\\{X:B\\subseteq X\\mathrm{\\ and\\ }X\\mathrm{\\ is\\ a\\ subuniverse\\ of\\ }\\mathcal{A}\\right\\}\n\\]","to be the ",Object(i.jsx)("strong",{children:"subuniverse generated"})," by \\(B\\). It is clear this induces a subalgebra, notably the"," ",Object(i.jsx)("strong",{children:"subalgebra generated"})," by \\(B\\). We are interested in one particular instance of this. Let"," ","\\(\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\)",". Define for \\(B\\subseteq A\\) the set","\\[B^\\sim=\\left\\{a\\in A:B\\cap a/\\!\\!\\sim\\,\\neq\\varnothing\\right\\}.\\]","We denote ","\\(\\mathcal{B}^\\sim\\)"," to be the subalgebra generated by \\(B^\\sim\\). If we have a subalgebra ","\\(\\mathcal{B}=(B,F)\\)",", then we write ","\\(\\mathcal{B}^\\sim\\)"," to describe this process on \\(B\\). Of note is that in this case our generated subalgebra does not grow:"]}),Object(i.jsx)(_,{no:"7",statement:"\r If \\(\\mathcal{B}\\) is a subalgebra of \\(\\mathcal{A}\\) and \\(\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\), then the universe of \\(\\mathcal{B}^\\sim\\) is \\(B^\\sim\\).\r "}),Object(i.jsx)(k,{proof:"\r Take some \\(n\\)-ary \\(f\\). Take any \\(a_1,\\dots,a_n\\in B^\\sim\\). By definition of \\(B^\\sim\\), there is some \\(b_i\\in B\\) so that \\((a_i,b_i)\\in\\,\\sim\\) for \\(1\\leq i\\leq n\\). Thus,\r \\[\r (f^\\mathcal{A}(a_1,\\dots,a_n),f^\\mathcal{A}(b_1,\\dots,b_n))\\in\\,\\sim\r \\]\r but this means \\(f^\\mathcal{A}(a_1,\\dots,a_n)\\in B^\\sim\\). We know \\(B^\\sim\\) is a subset of our universe, however we have just showed that \\(B^\\sim\\) is a subuniverse of \\(A\\), and therefore will generate itself. Thus, our universe is indeed \\(\\mathcal{B}^\\sim\\)."}),Object(i.jsxs)("p",{children:["Denote for a congruence \\(\\sim\\) on ","\\(\\mathcal{A}\\)"," the"," ",Object(i.jsx)("strong",{children:"restriction"})," of \\(\\sim\\) to \\(B\\subseteq A\\) to be the set \\(\\sim\\!\\vert_B=\\,\\sim\\cap\\,(B\\times B)\\). If \\(B\\) is a subuniverse, then this is clearly a congruence \\((B,F_B)\\)."]}),Object(i.jsx)(_,{no:"8",name:"Second Isomorphism Theorem",statement:"\r If \\(\\mathcal{B}\\) is a subalgebra of \\(\\mathcal{A}\\) and \\(\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\), then \\(\\mathcal{B}/\\!\\!\\sim\\!\\vert_B\\cong\\mathcal{B}^\\sim\\! /\\!\\!\\sim\\!\\vert_{B^\\sim}\\)."}),Object(i.jsx)(k,{proof:"\r Consider the map \\(\\alpha:\\mathcal{B}\\longrightarrow\\mathcal{B}^\\sim\\! /\\!\\!\\sim\\!\\vert_{B^\\sim}\\) defined by \\(b\\mapsto b/\\!\\!\\sim\\!\\vert_{B^\\sim}\\). This map is clearly well-defined. Now take some \\(n\\)-ary \\(f\\) and \\(b_1,\\dots,b_n\\in B\\) and we see\r \\[\r \\begin{aligned}\r \\alpha f^\\mathcal{B}(b_1,\\dots,b_n)&=f^\\mathcal{B}(b_1,\\dots,b_n)/\\!\\!\\sim\\!\\vert_{B^\\sim}\\\\\r &=f^{\\mathcal{B}/\\sim\\vert_{B^\\sim}}(b_1/\\!\\!\\sim\\!\\vert_{B^\\sim},\\dots,b_n/\\!\\!\\sim\\!\\vert_{B^\\sim})\\\\\r &=f^{\\mathcal{B}/\\sim\\vert_{B^\\sim}}(\\alpha b_1,\\dots,\\alpha b_n)\r \\end{aligned}\r \\]\r and noting that because \\(\\mathcal{B}/\\!\\!\\sim\\!\\vert_{B^\\sim}\\) is clearly a subalgebra of \\(\\mathcal{B}^\\sim/\\!\\!\\sim\\!\\vert_{B^\\sim}\\), we can pull our operation up, thus showing \\(\\alpha\\) is a homomorphism. Now, take some \\(b/\\!\\!\\sim\\!\\vert_{B^\\sim}\\in B^\\sim\\! /\\!\\!\\sim\\!\\vert_{B^\\sim}\\). We know that there is some \\(b'\\in B\\) so that \\(b'\\sim b\\), by definition of \\(B^\\sim\\). Thus, \\(\\alpha b'=b/\\!\\!\\sim\\!\\vert_{B^\\sim}\\), meaning it is surjective.\\[\\]\r Naturally, we proceed inspect the kernel of \\(\\alpha\\). As \r \\[\r \\begin{aligned}\r \\mathrm{ker}\\,\\alpha&=\\left\\{(b,b')\\in B^2:\\alpha(b)=\\alpha(b')\\right\\}\\\\\r &=\\left\\{(b,b')\\in B^2 : b/\\!\\!\\sim\\!\\vert_{B^\\sim}=b'/\\!\\!\\sim\\!\\vert_{B^\\sim} \\right\\}\\\\\r &=\\left\\{(b,b')\\in B^2:(b,b')\\in\\,\\sim\\!\\vert_{B^\\sim}\\right\\}\r \\end{aligned}\r \\]\r and given \\(B\\subseteq B^\\sim\\), this means \\(\\mathrm{ker}\\,\\alpha=\\,\\sim\\!\\vert_B\\). Then, by (FIT), we are done."}),Object(i.jsxs)("p",{children:["That's the three covered! However, there is one more theorem which is often presented alongside the isomorphism theorems - the correspondence theorem - which I will include for completeness. This is where the language of universal algebra takes a slight detour away from the conventional language used in, say, group theory. We call a non-empty set \\(L\\) endowed with two binary operations - \\(\\wedge\\) (",Object(i.jsx)("strong",{children:"meet"}),") and \\(\\vee\\) (",Object(i.jsx)("strong",{children:"join"}),") - a lattice if both meet and join are commutative and associative, along with being ",Object(i.jsx)("strong",{children:"idempotent"}),", meaning \\[ x\\vee x = x\\qquad x\\wedge x = x \\] and ",Object(i.jsx)("strong",{children:"absorptive"}),", meaning \\[ x\\vee(x\\wedge y)=x\\qquad x\\wedge(x\\vee y)=x. \\] A"," ",Object(i.jsx)("strong",{children:"sublattice"})," is a non-empty subset of a lattice, closed under meet and join."]}),Object(i.jsxs)("p",{children:["A map \\(\\alpha:L\\longrightarrow S\\) where \\(L\\) and \\(S\\) are lattices is called a ",Object(i.jsx)("strong",{children:"lattice homomorphism"})," if for \\(a,b\\in L\\), \\[ \\alpha(a\\wedge_Lb)=\\alpha a\\wedge_S\\alpha b\\qquad \\alpha(a\\vee_Lb)=\\alpha a\\vee_S\\alpha b. \\]"]}),Object(i.jsxs)("p",{children:["Next, we call a set \\(A\\) a ",Object(i.jsx)("strong",{children:"partially-ordered set"})," (",Object(i.jsx)("strong",{children:"poset"}),") if there exists a relation \\(\\leq\\) which is reflexive and transitive, along with being"," ",Object(i.jsx)("strong",{children:"antisymmetric"}),", meaning","\\[a\\leq b\\mathrm{\\ and\\ } b\\leq a\\Rightarrow a=b.\\]","We write \\((A,\\leq)\\). The only thing separating this from a"," ",Object(i.jsx)("strong",{children:"total-order"})," (e.g. the usual definition of \\(\\leq\\) on"," ","\\(\\mathbb{N}\\)",") is that a partial-order does not guarantee \\(a\\leq b\\) or \\(b\\leq a\\), in general. On posets, an"," ",Object(i.jsx)("strong",{children:"interval"})," \\(\\left[a,b\\right]\\) or \\((a,b)\\),"," ",Object(i.jsx)("strong",{children:"supremum"}),", and ",Object(i.jsx)("strong",{children:"infimum"})," are defined exactly the same as they are for totally-ordered sets."]}),Object(i.jsx)("p",{children:"The reason posets are important is that every lattice has a natural partial-order, namely writing \\(a\\leq b\\) if \\(a=a\\wedge b\\). Verifying this is actually a partial-order is just symbol-pushing, so I will not include it here."}),Object(i.jsx)(_,{no:"9",statement:"\r Every interval of a lattice is a sublattice."}),Object(i.jsx)(k,{proof:"\r Take \\([a,b]\\) to be our interval. Let \\(p,q\\in [a,b]\\). Then,\r \\[\r a\\wedge (p\\wedge q)=(a\\wedge p)\\wedge q=a\\wedge q=a\r \\]\r so \\(a\\leq p\\wedge q\\). Similarly, \\(p\\wedge q\\leq b\\). Then,\r \\[\r a\\wedge(p\\vee q)=a\\wedge((p\\vee (p\\wedge a))\\vee q)=a\\wedge((p\\vee a)\\vee q)=a\\wedge(a\\vee(p\\vee q))=a\r \\]\r meaning \\(a\\leq p\\vee q\\), and similarly \\(p\\vee q\\leq b\\). Thus, our interval is closed under both meet and join."}),Object(i.jsx)("p",{style:{textIndent:"0"},children:"We write \\(\\llbracket a,b\\rrbracket\\) to describe this lattice."}),Object(i.jsxs)("p",{children:["Similar to how we take a lattice and impose an ordering, we can take a poset and end up with a lattice by defining meet and join. In particular, we take","\\[\na\\wedge b=\\inf\\left\\{a,b\\right\\}\\qquad a\\vee b=\\sup\\left\\{a,b\\right\\}\n\\]","and verifying these satisfy the conditions for meet and join is straightforward. This all culminates into our final theorem, discussing the lattice"," ","\\((\\mathrm{Con}\\,\\mathcal{A},\\subseteq)\\)","."]}),Object(i.jsx)(_,{no:"10",name:"Correspondence Theorem",statement:"\r Let \\(\\mathcal{A}\\) be an algebra and let \\(\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\). Then,\r \\[\r \\llbracket\\sim,\\nabla_A\\rrbracket\\cong\\mathrm{Con}\\,\\mathcal{A}/\\!\\!\\sim\r \\]\r as lattices under \\(\\subseteq\\) by \\(r\\mapsto r/\\!\\!\\sim\\)"}),Object(i.jsx)(k,{proof:"\r Let \\(\\alpha\\) denote this mapping. Take some \\(r,s\\in[\\sim,\\nabla_A]\\) so that \\(r\\neq s\\). Without loss of generality, take some \\(a,b\\in A\\) so that \\((a,b)\\in r\\setminus s\\). This means \\((a/\\!\\!\\sim,b/\\!\\!\\sim)\\in r/\\!\\!\\sim\\!\\setminus\\, s/\\!\\!\\sim\\) meaning \\(\\alpha r\\neq\\alpha s\\).\\[\\]\r Now, take some congruence \\(r/\\!\\!\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}/\\!\\!\\sim\\). Let \\(s=\\mathrm{ker}(\\nu_r\\circ\\nu_\\sim)\\). We see that \r \\[\r (a/\\!\\!\\sim,b/\\!\\!\\sim)\\in r/\\!\\!\\sim\\,\\Leftrightarrow (a,b)\\in s\\Leftrightarrow (a/\\!\\!\\sim,b/\\!\\!\\sim)\\in s/\\!\\!\\sim\r \\]\r meaning \\(\\alpha s=r\\). In total, our map is bijective.\\[\\]\r Now take \\(r,s\\in[\\sim,\\nabla_A]\\). Without loss of generality, take \\(s\\subseteq r\\). It is clear \\(s/\\!\\!\\sim\\,\\subseteq r/\\!\\!\\sim\\). Thus, \\(\\alpha\\) preserves inclusions, meaning it preserves our induced meet and join, and thus is a lattice homomorphism too."}),Object(i.jsx)("p",{children:"This took far longer than I thought it would. Going in, I assumed that everything would be fairly simple and clean, in the same way the proofs of the isomorphism theorems for specific structures are. However, given the variation between ideals and normal subgroups that I mentioned at the beginning, in hindsight I should have expected the overarching notion (i.e. congruences) to not necessarily be the friendliest or most familiar concept. Nonetheless, it is satisfying to have my curiosity quenched, even if it was slightly confusing at times."}),Object(i.jsx)("p",{children:"I have read that, apparently, universal algebra is pretty dead in terms of study today, supposedly having been subsumed into category theory. Although I find the hedonistic study of category theory to be quite sour, I will say that I find the category theory used in algebra to be more interesting and cleaner than universal algebra. It also far more powerful for identifying overarching ideas, whereas universal algebra limits itself to strictly algebra, by definition. However, I peeked into the end of Burris' and Sankappanavar's book and saw a large ampersand used as an operator over some set, so I am going to wager my freshman's opinion is quite ill-informed and there are deeper reasons the field is not very active today (if that's even true at all!)."})]})}}]),a}(n.Component),U=a.p+"static/media/svg1.68acb4a6.svg",N=a.p+"static/media/svg2.82d2c6f8.svg",S=a.p+"static/media/svg3.2f752a21.svg",G=a.p+"static/media/svg4.7f2d9061.svg",V=a.p+"static/media/svg5.c29c7486.svg",E=a.p+"static/media/svg6.90f4730c.svg",Z=a.p+"static/media/svg7.6093a484.svg",L=a.p+"static/media/svg8.8c5b64af.svg",Y=a.p+"static/media/fig1records.193c1ea7.png",P=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"componentDidMount",value:function(){window.KaTeXRender()}},{key:"render",value:function(){return Object(i.jsxs)("div",{class:"postContent leftMargin",children:[Object(i.jsx)("p",{children:"Although Eratosthenes calculated the Earth's circumference around 250 B.C.E with a very small margin of error, it is hard to see the Earth is round when simply standing outside. Even atop mountains and cliffs facing out to the sea, the Earth seems quite flat. It is only when we look at Earth as a whole that we see the curvature. In fact, this is true of any ball-shaped object."}),Object(i.jsxs)("p",{children:["In mathematics, we call objects like this ",Object(i.jsx)("strong",{children:"manifolds"}),", and say they are ",Object(i.jsx)("strong",{children:"locally Euclidean"}),". An important part of being locally Euclidean is that there are no sudden jumps or cusps or anything of the sort; the surface is smooth. Beginning with this notion, we study ",Object(i.jsx)("strong",{children:"smooth functions"}),". Take $U$ as an open subset of ","$\\mathbb{R}^n$",". We say the map"," ","$f:U\\rightarrow\\mathbb{R}^m$"," is smooth if it is"," ","$\\mathcal{C}^\\infty$",", or if it has continuous partial derivatives of all orders. An example of this is"," ","$f:\\mathbb{R}\\rightarrow\\mathbb{R}$"," by $x\\mapsto x^3$. However, suppose we had a function ","$f:[0,1]\\rightarrow\\mathbb{R}$",". Our $U$ in this case is not open. How do we talk about differentiation at the points $x=0$ or $x=1$? Of course, we cannot; $f$ is not continuous at these points and so is not differentiable. However, ",Object(i.jsx)("i",{children:"should"})," ","we be able to differentiate $f$? With \\(x\\mapsto x^3\\), the answer is clearly yes. So, in the same way we complete ","$\\mathbb{Q}$"," with Cauchy sequences which should converge, we say"," ","$f:U\\rightarrow\\mathbb{R}^m$"," is smooth on a closed"," ","$U\\subseteq\\mathbb{R}^n$"," if around every $u\\in U$ there exists an open ","$V\\subseteq\\mathbb{R}^n$"," and a smooth"," ","$F:V\\rightarrow\\mathbb{R}^m$"," such that"," ","$F\\vert_{V\\cap U}=f\\vert_{V\\cap U}$",". We call this $F$ a"," ",Object(i.jsx)("strong",{children:"smooth extension"})," of $f$ at $x$."]}),Object(i.jsxs)("p",{children:["With this idea of smoothness in mind we are almost ready to define manifolds. The only obstacle is the ability to go to and from our spaces. For example, $x\\mapsto x^3$ is smooth, however its inverse"," ","$y\\mapsto\\sqrt[3]{y}$"," is not, as it is not differentiable at $y=0$. We need to ensure we can take our manifold and straighten it out locally, but also be able to undo that process by folding things back up onto the manifold. This introduces"," ",Object(i.jsx)("strong",{children:"diffeomorphisms"}),". A smooth map $f:X\\rightarrow Y$, where $X$ and $Y$ are subsets of a Euclidean space, is called a diffeomorphism if ","$f^{-1}:Y\\rightarrow X$"," is also smooth. We say $X$ and $Y$ are diffeomorphic. A useful result follows."]}),Object(i.jsx)(_,{no:"1",statement:"\r The composition of diffeomorphisms is a diffeomorphism.\r "}),Object(i.jsx)(k,{proof:"\r Suppose we have diffeomorphisms $f:X\\rightarrow Y$ and $g:Y\\rightarrow Z$. Consider $g\\circ f:X\\rightarrow Z$. Let $x\\in X$. Given $f$ and $g$ are smooth we can find open neighborhoods $U$ of $x$ and $V$ of $f(x)$, as well as smooth extensions $F:U\\rightarrow Y$ and $G:V\\rightarrow Z$. Let $\\tilde{U}=U\\cap F^{-1}(V)$. Then note that\r \\[\r G\\circ F:\\tilde{U}\\rightarrow Z    \r \\]\r is smooth as it is defined on open sets. Furthermore, $(G\\circ F)\\vert_{X\\cap\\tilde{U}}=(g\\circ f)\\vert_{X\\cap\\tilde{U}}$ and is therefore our desired smooth extension. Applying the same technique to the inverses, we are done."}),Object(i.jsxs)("p",{children:["Now, we can define manifolds! Although there are ways to define manifolds on abstract topological spaces, it is not necessary for our discussion. So, we say ","$X\\subseteq\\mathbb{R}^n$"," is a $k$-",Object(i.jsx)("strong",{children:"dimensional"})," manifold (or $k$-manifold) if for each $x\\in X$ there exists a diffeomorphism $\\varphi:U\\rightarrow V$ where $V$ is an open set around $x$ in $X$ (as in, ","$V=X\\cap\\tilde{V}$"," ","for some open ","$\\tilde{V}\\subset\\mathbb{R}^n$",") and $U$ is an open subset of ","$\\mathbb{R}^k$",". We call a diffeomorphism going this way (from a Euclidean space) a ",Object(i.jsx)("strong",{children:"parametrization"})," ","of $X$ about $x$, and we call ","$\\varphi^{-1}:V\\rightarrow U$"," ",Object(i.jsx)("strong",{children:"local coordinates"})," on $X$ about $x$. We usually write"," ","$\\varphi^{-1}=(x_1,\\cdots,x_k)$",", where each $x_i$ takes in an element of $X$ and returns you a point in ","$\\mathbb{R}$",", making it clear how $X$ really is $k$-dimensional. In other words, $X$ is diffeomorphic to ","$\\mathbb{R}^k$","."]}),Object(i.jsx)(_,{no:"2",statement:"\r Every open ball in $\\mathbb{R}^n$ is diffeomorphic to $\\mathbb{R}^n$.\r "}),Object(i.jsx)(k,{proof:"\r Let our $n$-ball of radius $r$ be denoted $\\mathcal{B}_r$. Define $f:\\mathcal{B}_r\\rightarrow\\mathbb{R}^n$ by\r $$x\\mapsto\\frac{rx}{\\sqrt{r^2-\\|x\\|^2}}.$$\r It is clear this map is smooth, as it is just multiple applications of (1). We also note the map $f^{-1}:\\mathbb{R}^n\\rightarrow\\mathcal{B}_r$ defined by\r $$x\\mapsto\\frac{rx}{\\sqrt{r^2+\\|x\\|^2}}$$\r is smooth and is the inverse of $f$, justifying our clever choice of name."}),Object(i.jsxs)("p",{children:["Using the above fact, whenever we parametrize a $k$-manifold $X$ by"," ","$\\varphi:U\\subseteq\\mathbb{R}^k\\rightarrow V\\subseteq X$",", we will instead just take ","$\\varphi:\\mathbb{R}^k\\rightarrow V$",", by implicit composition. If the exact image of our parametrization is not important (for instance, if we do not need to invert it), we will write ","\\(\\varphi:\\mathbb{R}^k\\rightarrow X\\)","."]}),Object(i.jsxs)("p",{children:["One reason we impose all of these restrictions on manifolds is that they are the perfect conditions to study spaces on which we can borrow ideas from calculus. One of these is tangency. Just like how a differentiable function ","$f:\\mathbb{R}\\rightarrow\\mathbb{R}$"," can be locally approximated by its derivative, we can locally approximate the potentially very complicated global behaviour of a manifold by its derivative as well. Let ","$X\\subseteq\\mathbb{R}^n$"," be our $k$-manifold, and let $x_0\\in X$. Take"," ","$\\varphi:\\mathbb{R}^k\\rightarrow X$"," to be a parametrization about $x_0$, and without loss of generality take $\\varphi(0)=x_0$. Its derivative is","$$d\\varphi_{x_0}:\\mathbb{R}^k\\rightarrow\\mathbb{R}^n.$$","We call the image of ","$d\\varphi_{x_0}$"," our"," ",Object(i.jsx)("strong",{children:"tangent space"}),", $T_xX$. Just as the line locally approximating our function $f$ at $x_0$ is given by $f(x_0)+xf'(x)$, our tangent space can be put on $X$ by"," ","$\\varphi(0)+d\\varphi_{x_0}x$",". In fact, we do not need to use all of $X$; any open neighborhood around $x_0$ will do."]}),Object(i.jsx)("p",{children:"However, note we defined $T_xX$ with respect to a particular parametrization. Thankfully, the tangent space is the same for all parametrizations, as we will show."}),Object(i.jsx)(_,{no:"3",statement:"\r The tangent space of a manifold is invariant under choice of parametrization.\r "}),Object(i.jsx)(k,{proof:Object(i.jsxs)("span",{children:["Suppose we have ","$\\varphi:\\mathbb{R}^k\\rightarrow X$"," and"," ","$\\psi:\\mathbb{R}^k\\rightarrow X$"," both parametrizing $X$ about $x$, such that $\\varphi(x)=0=\\psi(x)$. Shrinking our domains to some $U$ and $V$ in ","\\(\\mathbb{R}^k\\)"," if necessary, we can make their images equal. Thus, ",Object(i.jsx)(z,{src:U})," where"," ","$h=\\psi^{-1}\\circ\\varphi:U\\rightarrow V$"," is a diffeomorphism by (1). Then, we see $d\\varphi_0=d\\psi_0\\circ dh_0$, so"," ","$d\\varphi_0(\\mathbb{R}^k)\\subseteq d\\psi_0(\\mathbb{R}^k)$",", and the reverse direction shows their images are actually equal, meaning the tangent space is identical regardless of parametrization chosen."," "]})}),Object(i.jsx)(_,{no:"4",statement:"\r If $X\\subseteq\\mathbb{R}^n$ is a $k$-manifold, then $\\mathrm{dim}\\,T_xX=k$ for all $x\\in X$.\r "}),Object(i.jsx)(k,{proof:"Let $x\\in X$ and parametrize about it by $\\varphi$. Then, $\\varphi^{-1}\\circ\\varphi=\\mathrm{Id}$. Given $\\mathrm{Id}$ is linear, $d\\mathrm{Id}_0=\\mathrm{Id}$, so ordinary chain rule requires that $d\\varphi^{-1}_x\\circ d\\varphi_0=\\mathrm{Id}$. Therefore, $d\\varphi_0$ is bijective, so it is an isomorphism, and the dimension follows."}),Object(i.jsx)("p",{children:"Now that we know tangent spaces are well-defined, we begin to unveil how powerful they are, by letting us learn a lot about manifolds from relatively simple linear algebra. First, we must show they play nicely with composition."}),Object(i.jsx)(_,{no:"5",name:"Chain Rule",statement:"\r With $j$-,$k$-, and $\\ell$-manifolds $X,Y,Z$ and smooth maps $f:X\\rightarrow Y$ and $g:Y\\rightarrow Z$,\r $$d(g\\circ f)_x=dg_{f(x)}\\circ df_x.$$\r "}),Object(i.jsx)(k,{proof:Object(i.jsxs)("span",{children:["Let $x\\in X$, and $y=f(x)$. Parametrize about $x$ and $y$ by $\\varphi$ and $\\psi$, respectively. We again shrink their domains as in (3) to $U$ and $V$, respectively, if need be. Taking derivatives, we arrive at ",Object(i.jsx)(z,{src:N})," suggesting"," ","$df_x=d\\psi_0\\circ dh_0\\circ d\\varphi^{-1}_0$",". Suppose however we had a different parametrization about $x$, say $\\varphi'$, whose domain is shrunk to $U'$. By (3), we have"," ",Object(i.jsx)(z,{src:S})," and so","$$d\\psi_0\\circ dh_0\\circ\\mathrm{Id}\\circ d(\\varphi')_0^{-1}= d\\psi_0\\circ dh_0\\circ d(\\varphi')_0^{-1}=d\\psi_0\\circ dh_0\\circ d\\varphi^{-1}_0=df_x$$","nonetheless, showing our choice does not matter. Applying the above to ",Object(i.jsx)(z,{src:G})," has the proof fall out immediately."]})}),Object(i.jsx)("p",{children:"There is one result that follows from this which will be particularly useful later."}),Object(i.jsx)(_,{no:"6",statement:"\r With $f:X\\rightarrow Y$ a diffeomorphism, $df_x$ is an isomorphism between their tangent spaces."}),Object(i.jsx)(k,{proof:"\r Let $x\\in X$, and $y=f(x)$. We know $f^{-1}\\circ f=\\mathrm{Id}$. By chain rule,\r $$d(f^{-1}\\circ f)_x=\\mathrm{Id}=df^{-1}_y\\circ df_x$$\r so in fact, $(df_x)^{-1}=df^{-1}_y$, and so it is an isomorphism."}),Object(i.jsxs)("p",{children:["Now that we know some basics about manifolds, as well as the basics about maps between them, we can ask the question about whether a transformation creates a manifold in the first place. Continuing with the theme of differentiability, we define a"," ",Object(i.jsx)("strong",{children:"local diffeomorphism"}),", which is exactly what it sounds like. We call $f:X\\rightarrow Y$ a local diffeomorphism if around each $x\\in X$ there exists an open neighborhood $U$ around $x$ which is diffeomorphic to some neighborhood $V$ around $f(x)$. This is not an empty definition, as a local diffeomorphism can very well not be an actual diffeomorphism, perhaps failing to be bijective. An incredibly powerful, and honestly shocking result applies to local diffeomorphisms."]}),Object(i.jsx)(_,{no:"7",name:"Inverse Function Theorem (IFT)",statement:"\r If $f:X\\rightarrow Y$ is smooth with $df_x$ an isomorphism, then $f$ is a local diffeomorphism at $x$."}),Object(i.jsx)("p",{children:"The proof is far too long and outside the scope for this post. I intend to soon (first learn about and then) write a separate post for this theorem using the Banach Fixed-Point approach. Also, note the relation to (6)."}),Object(i.jsx)(_,{no:"8",statement:"\r If $f:X\\rightarrow Y$ is smooth with $df_x$ an isomorphism,  then $f$ is locally equivalent to the identity at $x$."}),Object(i.jsx)(k,{proof:Object(i.jsxs)("span",{children:["Parametrize about $x$ by $\\varphi$ and $y=f(x)$ by $\\psi$. Then, we get ",Object(i.jsx)(z,{src:V})," and differentiating gives"," ",Object(i.jsx)(z,{src:E})," Given we know $df_x$ is also an isomorphism between $T_xX$ and $T_yY$, we know we can replace"," ","$d\\psi_0\\circ d\\varphi_x^{-1}$"," with it. Then, by (7), we can justify ","$f=\\psi\\circ\\varphi^{-1}$"," provided we sufficiently shrink neighborhoods."]})}),Object(i.jsxs)("p",{children:["This is generally more useful for us than (7) is. To be more explicit about what we have done here, we have actually given local coordinates $(x_1,\\cdots,x_k)$ from ","$\\varphi^{-1}$"," such that $f(x_1,\\cdots,x_k)=(x_1,\\cdots,x_k)$, and likewise for ","$f^{-1}$",". In a sense then, \\(X\\) and \\(Y\\) are the same manifold under a different guise, because we do not have enough structure to (meaningfully) differentiate between them. This is analogous two different bases representing the same vector space. However, sometimes our conditions are not this strong, but meaningful connections still exist. For example, a subspace of a vector space is obviously related to the vector space itself, even though we cannot biject their bases. In the case of manifolds, this brings up the idea of"," ",Object(i.jsx)("strong",{children:"submersions"}),"."]}),Object(i.jsxs)("p",{children:["When we have manifolds \\(X\\) and \\(Y\\) with \\(f:X\\rightarrow Y\\), but"," ","\\(k=\\mathrm{dim}\\,X\\geq\\mathrm{dim}\\,Y=\\ell\\)",", we cannot have \\(df_x\\) for any \\(x\\in X\\) be a bijection between tangent spaces unless the equality is actually met. However, we can have it be a surjection, and in this case we call \\(f\\) a submersion."," ",Object(i.jsx)("strong",{children:"The canonical submersion"})," is just a projection, the simplest of which being"," ","\\(\\pi:\\mathbb{R}^k\\rightarrow\\mathbb{R}^\\ell\\)"," defined by \\[ (x_1,\\dots,x_\\ell,\\dots,x_k)\\mapsto (x_1,\\dots,x_\\ell). \\] We will use \\(\\pi_c\\) to represent the appropriate projection for the context."]}),Object(i.jsx)(_,{no:"9",name:"Local Submersion Theorem",statement:"\r With \\(f:X\\rightarrow Y\\) a submersion at \\(x\\in X\\), \\(f\\) is locally equivalent to the canonical submersion."}),Object(i.jsx)(k,{proof:Object(i.jsxs)("span",{children:["Appropriately parametrize to achieve the diagram"," ",Object(i.jsx)(z,{src:Z})," We know"," ","\\(dg_0:\\mathbb{R}^k\\rightarrow\\mathbb{R}^\\ell\\)"," to be surjective, so for some basis it can be represented by the \\(\\ell\\)-by-\\(k\\) block matrix"," ","\\(\\begin{pmatrix} I_\\ell & 0\\end{pmatrix}\\)",", where \\(I_\\ell\\) is the \\(\\ell\\)-square identity. In order to apply (8), we need bijectivity, so we define"," ","\\(G:\\mathbb{R}^k\\rightarrow\\mathbb{R}^k\\)"," by","\\[\n                G(x)=(g(x)_1,\\dots,g(x)_\\ell,x_{\\ell+1},\\dots,x_k)\n                \\]","and by extending our basis chosen to represent \\(dg_0\\), we can represent \\(dG_0\\) by \\(I_k\\). Then by (8), after said shrinking, we get ",Object(i.jsx)(z,{src:L})," as desired."]})}),Object(i.jsxs)("p",{children:["This is quite a powerful result, because it lets us easily create manifolds when coupled with a few more useful tools. Say we have some arbitrary map \\(f:X\\rightarrow Y\\). With \\(y\\in Y\\), we call the"," ",Object(i.jsx)("strong",{children:"fibre"})," of \\(y\\) the set"," ","\\(\\left\\{x\\in X:f(x)=y\\right\\}=f^{-1}(y)\\)",". Note this is the special case of a preimage, namely of the singleton"," ","\\(\\left\\{y\\right\\}\\)",". Cases where fibres are manifolds themselves are of great interest, as we will soon see. However, how we can we figure out if they are one in the first place? Drawing inspiration from (9), suppose \\(f\\) is actually a smooth mapping of manifolds. We call \\(y\\) a ",Object(i.jsx)("strong",{children:"regular value"})," if \\(f\\) submerges its fibre (in the sense that it is a submersion at every element)."]}),Object(i.jsx)(_,{no:"10",name:"Fibre Theorem",statement:"\r If \\(y\\in Y\\) is a regular value of a smooth \\(f:X\\rightarrow Y\\) between manifolds, then the fibre of \\(y\\) is a submanifold of \\(X\\) with dimension \\(\\mathrm{dim}\\,X-\\mathrm{dim}\\,Y\\)."}),Object(i.jsx)(k,{proof:"\r Suppose we have some such \\(f\\), with \\(\\mathrm{dim}\\,X=k\\) and \\(\\mathrm{dim}\\,Y=\\ell\\). Let \\(x\\) be in our fibre. Choose local coordinates in a neighbourhood \\(U\\) of \\(x\\) by (9) such that \\(f(x_1,\\dots,x_k)=(x_1,\\dots,x_\\ell)\\). Then, note that\r \\[\r V=f^{-1}(y)\\cap U=\\left\\{x\\in U:x_1=\\cdots=x_\\ell=0\\right\\}.\r \\]\r However, this means \\(V\\) is an open subset of \\(f^{-1}(y)\\) diffeomorphic to \\(\\mathbb{R}^{k-\\ell}\\), as the local coordinate system \\((x_{\\ell+1},\\dots,x_k)\\) fully describes \\(V\\). In other words, \\(V\\) is a \\((k-\\ell)\\)-manifold."}),Object(i.jsxs)("p",{children:["This is remarkably powerful. For example, take the unit \\(n\\)-sphere"," ","\\(S^n\\subseteq\\mathbb{R}^{n+1}\\)",". To prove this is an \\(n\\)-manifold explicitly is not the easiest task. We would need to construct the stereographic projection, then show it is bijective and smooth both ways (or something similar). Instead, however, we note that","\\[\r\nS^n=\\left\\{x\\in\\mathbb{R}^{n+1}:N(x)=1\\right\\}\r\n\\]","where"," ","\\(N=\\|\\, \\|^2:\\mathbb{R}^{n+1}\\rightarrow\\mathbb{R}\\)"," is the square of the Euclidean norm. This means that \\(S^n\\) is the fibre of \\(1\\) (under \\(N\\)). However, note that at"," ","\\(z\\in\\mathbb{R}^{n+1}\\)"," ","\\[\r\ndN_z=\\begin{pmatrix} 2z_1 & \\cdots & 2z_{n+1}\\end{pmatrix}\r\n\\]"," ","is clearly surjective to ","\\(\\mathbb{R}\\)"," except when \\(z=0\\). In particular, it is surjective when \\(z=1\\), meaning \\(S^n\\) is an \\(n\\)-manifold."]}),Object(i.jsxs)("p",{children:["One interesting remark is that ","\\(dN_{-1}\\)"," is also surjective. In fact, this holds true for any \\(z \\lt 0\\), despite the fact that we cannot have a negative radius. Although strange, it is merely platitudinous, as ","\\(N^{-1}(-1)=\\varnothing\\)"," and the empty set is vacuously a \\(0\\)-manifold (and also a basis for every kernel, and has an infimum of infinity, and...)."]}),Object(i.jsxs)("p",{children:["There is an interesting consequence of working with these fibres under certain conditions. We can use it to create a neighbourhood around a point, by stacking various records induced by the fibre. The geometric intuition here is nicely demonstrated in figure 1 taken from Guillemin and Pollack's ",Object(i.jsx)("i",{children:"Differential Topology"}),"."]}),Object(i.jsx)($,{no:"1",src:Y,caption:" Stack of Records visualization, Fig 1-13 (26) G and P"}),Object(i.jsx)(_,{no:"11",name:"Stack of Records",statement:"\r Suppose \\(y\\in Y\\) is a regular value of a smooth \\(f:X\\rightarrow Y\\) where \\(X\\) and \\(Y\\) are equidimensional manifolds, and \\(X\\) is compact. Then, the fibre of \\(y\\) is finite, and there exists an open neighbourhood of \\(y\\) whose preimage is the disjoint union of open neighbourhoods around each element in the fibre."}),Object(i.jsx)(k,{proof:"\r Suppose we have some such \\(y\\). Let \\(x\\in f^{-1}(y)\\). We know \\(df_x\\) is surjective from (10), and given \\(\\mathrm{dim}\\,X=\\mathrm{dim}\\,Y\\) it is in fact bijective. From (7), it is therefore locally diffeomorphic on the fibre. Suppose now the fibre is infinite. As \\(X\\) is compact, we know it contains a limit point of \\(f^{-1}(y)\\), say \\(x_0\\). As \\(f\\) is continuous, we know our fibre is compact as well, hence \\(x_0\\in f^{-1}(y)\\). Take consecutively smaller neighbourhoods of \\(x_0\\) to form a sequence of \\(x_i\\in f^{-1}(y)\\) which converge to \\(x_0\\). As \\(f\\) is a local diffeomorphism a neighbourhood of \\(x_0\\) diffeomorphic to some neighbourhood in \\(Y\\) must exist, but each neighbourhood will contain some \\(x_i\\neq x_0\\), hence failing to be injective. Thus, the fibre is finite, say \r \\[\r f^{-1}(y)=\\left\\{x_1,\\dots,x_n\\right\\}.\r \\] \r Choose open neighbourhoods \\(U_i\\) around each \\(x_i\\) diffeomorphic to some neighbourhood around \\(y\\), which we shrink until they are disjoint. Then, let \\(V=\\bigcap f(U_i)\\). Then, let \\(U_i^\\ast=U_i\\cap f^{-1}(V)\\). As \\(X\\setminus\\dot{\\bigcup}\\,U_i^\\ast\\) is closed, its image is compact, and therefore \\(V\\) is open. By construction \\(f^{-1}(V)=\\dot{\\bigcup}\\, U_i^\\ast\\), giving our desired records and stacking. "}),Object(i.jsx)("p",{children:"This is the reason I love differential topology. You get to go from a very simple picture and idea, like stacking records on one another, to the abstract and rigorous framework behind the proof itself, building on top of other abstract and rigorous tools with the same intuitive framing. Moreover, the tools themselves are quite simple - linear maps and metric space topology - but they fuse perfectly with the requirement that your space be locally Euclidean, letting you describe complicated and otherwise obtuse structures with straightforward and basic concepts."})]})}}]),a}(n.Component),D=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"componentDidMount",value:function(){window.KaTeXRender()}},{key:"render",value:function(){return Object(i.jsxs)("div",{class:"postContent leftMargin",children:[Object(i.jsxs)("p",{children:["A few weeks ago I was working through some exercises out of Rudin's"," ",Object(i.jsx)("i",{children:"Principles of Mathematical Analysis"})," and exercise 4.22 brought up normality. This piqued an interest in what a space which is"," ",Object(i.jsx)("i",{children:"not"})," normal would look like. Searching for non-trivial examples brought up the Moore plane, and my understanding of what it is and why it is not normal laid in a hazy propinquity. So, I spent some time looking through some threads on MSE, Reddit, and other websites, as well as some texts like Munkres' ",Object(i.jsx)("i",{children:"Topology"})," to prove it starting from the bottom up."]}),Object(i.jsxs)("p",{children:["First, we must define what a topology is. Given some $X$, we define a",Object(i.jsx)("strong",{children:" topology"})," ","$\\mathcal{T}$"," to be a set of subsets of $X$ such that"]}),Object(i.jsxs)("ol",{children:[Object(i.jsxs)("li",{children:["both $X$ and $\\varnothing$ are in ","$\\mathcal{T}$",";"]}),Object(i.jsxs)("li",{children:["the union of any elements of ","$\\mathcal{T}$"," is too an element of"," ","$\\mathcal{T}$","; and"]}),Object(i.jsxs)("li",{children:["the finite intersection of any elements of ","$\\mathcal{T}$"," is too an element of ","$\\mathcal{T}$","."]})]}),Object(i.jsxs)("p",{style:{textIndent:"0"},children:["We then call $X$ a ",Object(i.jsx)("strong",{children:"topological space"})," once a topology is specified. We then say a subset of $X$ is ",Object(i.jsx)("strong",{children:"open"})," if it is an element of ","$\\mathcal{T}$",". Then, a subset is"," ",Object(i.jsx)("strong",{children:"closed"})," if its complement is open."]}),Object(i.jsxs)("p",{children:["Describing topologies can be particularly difficult as listing an infinite amount of sets takes a non-trivial amount of time. Instead, to describe a particular topology on $X$ a ",Object(i.jsx)("strong",{children:"basis"})," ","$\\mathcal{B}$"," is usually provided, which takes as elements subsets of $X$ such that"]}),Object(i.jsxs)("ol",{children:[Object(i.jsxs)("li",{children:["for any $x\\in X$ there exists some ","$B\\in\\mathcal{B}$"," such that $x\\in B$; and"]}),Object(i.jsxs)("li",{children:["for any $x\\in X$ such that $x$ lies in the intersection two distinct"," ","$B_1,B_2\\in\\mathcal{B}$",", there exists some $B_3\\subset B_1\\cap B_2$ such that $x\\in B_3$."]})]}),Object(i.jsxs)("p",{children:["Then, we define the topology ","$\\mathcal{T}$"," on $X$"," ",Object(i.jsx)("strong",{children:"generated"})," by ","$\\mathcal{B}$"," by having $U$ be open in $X$ if for all $x\\in U$ there exists some ","$B\\in\\mathcal{B}$"," ","such that $x\\in B$ and $B\\subset U$. Showing that ","$\\mathcal{T}$"," ","is indeed a topology involves showing that it adheres to the first 3 conditions listed; the first two are trivial and the third can be shown by induction."]}),Object(i.jsxs)("p",{children:["To more constructively show ",Object(i.jsx)("i",{children:"what"})," is exactly in ","$\\mathcal{T}$",", rather than just saying ",Object(i.jsx)("i",{children:"if"})," something is, let ","$\\mathcal{B}$"," ","generate some topology. Then, given some ","$U\\in\\mathcal{T}$"," note that for any $x\\in U$ we can choose some ","$B_x\\in\\mathcal{B}$"," ","such that $x\\in B_x\\subset U$ by our definition of open. Then,","$$U=\\bigcup_{x\\in U}B_x.$$","Additionally, given that this implies every ","$B\\in\\mathcal{B}$"," is in the topology, $B$ is then open and so any union of elements of the basis gives another element of the topology. Thus, both sides are subsets of each other and so ","$\\mathcal{T}$"," is just every possible union of every element of $B$. The notion of open and closed sets related to interior and limit points in ","$\\mathbb{R}^n$"," can be recovered by taking as a basis every open $n$-ball."]}),Object(i.jsxs)("p",{children:["This is important because now we can define the object of interest: the ",Object(i.jsx)("strong",{children:"Moore plane"}),". First, consider the upper half of the ","$\\mathbb{R}^2$","-plane,","$$\\Gamma=\\left\\{\\left(x,y\\right)\\in\\mathbb{R}^2:y\\geq 0\\right\\}.$$","Then, given some $(p,q)\\in\\Gamma$, we define a local basis at that point by various open discs. Namely, if $q\\neq0$, then we considered every open disc in $\\Gamma$ centred at $(p,q)$. If $q=0$, then we consider every open disc in $\\Gamma$ tangent to the $x$-axis at $(p,0)$, but also including the point of tangency. More formally,","$$\\mathcal{B}(p,q)=\\begin{cases}\n        \\bigcup\\limits_{0\\,\\lt\\,\\varepsilon\\,\\leq\\, q}\\left\\{(x,y)\\in\\mathbb{R}^2:(x-p)^2+(y-q)^2\\lt\\,\\varepsilon^2\\right\\} & \n        q\\,\\ge\\, 0\\\\ \\bigcup\\limits_{\\varepsilon\\,\\gt\\, 0}\\left\\{p,0\\right\\}\\cup\\left\\{(x,y)\\in\\mathbb{R}^2:(x-p)^2+(y-\\varepsilon)^2\\lt\\,\\varepsilon^2\\right\\} \n        & q=0.\\end{cases}$$"]}),Object(i.jsxs)("p",{children:["One can do this for every $(p,q)\\in\\Gamma$ to find the complete basis. Now, we define the entire reason this post exists. We call a space $X$"," ",Object(i.jsx)("strong",{children:"normal"})," if for any disjoint closed subsets $A$ and $B$, there exist disjoint open $U$ and $V$ such that $A\\subset U$ and $B\\subset V$. In other words, you can separate $A$ and $B$ by neighborhoods."]}),Object(i.jsxs)("p",{children:["To me this was confusing, because it seems very difficult to imagine in a (non-trivial) space. After all, taking ","$\\mathbb{R}^n$"," for intuition, it seems absurd that a space could not be normal. However, the Moore plane is just so. Now, we will set abound to prove it via contradiction (or rather a more tidy contrapositive) beginning with a small result on normal spaces, and following with another for a particular subset of the rationals."]}),Object(i.jsx)(_,{no:"1",statement:"\r If $X$ is a normal space, then for any closed $C\\subset X$ with an open $U$ such that $C\\subset U$, there exists an open $V$ such that\r $$C\\subset V\\subset\\overline{V}\\subset U$$\r where $\\overline{V}$ is the closure of $V$."}),Object(i.jsx)(k,{proof:"\r Consider some such $C$ and $U$. We know then $C\\cap X\\setminus U=\\varnothing$, and as $U$ is open $X\\setminus U$ is closed. Then, given that $X$ is normal we can find some disjoint open $V\\supset C$ and open $W\\supset X\\setminus U$. Given they are disjoint, we know $V\\subset X\\setminus W$, and so\r $$C\\subset V\\subset\\overline{V}\\subseteq X\\setminus W\\subset U$$\r as $X\\setminus W$ is closed."}),Object(i.jsx)(_,{no:"2",statement:Object(i.jsxs)("span",{children:["The ",Object(i.jsx)("strong",{children:"dyadic rationals"}),", ","$\\mathbb{Q}_d$",", defined by"," ","$$\\mathbb{Q}_d=\\left\\{\\frac{p}{2^q}\\in\\mathbb{Q}:p\\in\\mathbb{Z},q\\in\\mathbb{N}\\right\\}$$"," ","where the naturals include 0, are dense in ","$\\mathbb{R}$","."]})}),Object(i.jsx)(k,{proof:"\r We merely need to show every $x\\in\\mathbb{R}\\setminus\\mathbb{Q}_d$ is a limit point of $\\mathbb{Q}_d$. Let $\\varepsilon \\gt 0$. Then, there exists some $q\\in\\mathbb{N}$ such that $2^q\\varepsilon\\gt 1.$ We know there exists some $p$ such that\r $$p-1\\lt 2^qx\\lt p$$\r and then we get\r $$2^qx\\lt p\\lt 2^qx+1\\lt 2^q(x+\\varepsilon)$$\r meaning $\\left|x-\\frac{p}{2^q}\\right|\\lt\\varepsilon$. "}),Object(i.jsx)("p",{children:"Now, we set out to prove a famous result connecting normal spaces and continuous functions, using the above subclosure property in its construction."}),Object(i.jsx)(_,{no:"3",name:"Urysohn",statement:"\r For any two disjoint closed sets $A$ and $B$ in normal $X$, there exists a continuous mapping $f:X\\rightarrow [0,1]$ such that for all $x\\in A, f(x)=0$ and for all $x\\in B, f(x)=1$."}),Object(i.jsx)(k,{proof:"\r Let $C_0=A$, and then $U_1=X\\setminus B$. We know $C_0\\subset U_1$, and so by (1) we can find some subclosure, say $C_{\\frac12}$, and then from this some open $U_{\\frac12}$ such that\r $$C_0\\subset U_{\\frac12}\\subset C_{\\frac12}\\subset U_1.$$\r However, we can then repeat this process with $C_0$ and $U_{\\frac12}$, and $C_{\\frac12}$ and $U_1$, and then again after that, eventually getting the construction\r $$C_0\\subset\\cdots\\subset C_{\\frac14}\\subset U_{\\frac14}\\subset\\cdots\\subset U_{\\frac12}\\subset C_{\\frac12}\\subset\\cdots\\subset U_{\\frac34}\\subset C_{\\frac34}\\subset\\cdots\\subset U_1$$\r where we choose to index by $\\mathbb{Q}_d$.\\[\\]\r Let $(0,1]_d=\\mathbb{Q}_d\\cap (0,1]$. Then, we define $f:X\\rightarrow [0,1]$ by\r $$f(x)=\r \\begin{cases}\r 1 & x\\in B\\\\\r \\inf\\left\\{r\\in (0,1]_d: \\left\\{x\\right\\}\\subset U_r\\right\\} & x\\notin B. \r \\end{cases}\r $$\r We must define $f$ on $B$ as no element of $B$ will be in any $U_r$. We also see this infimum will return $0$ for any $x\\in A$. It stands to show that $f$ is continuous on $X$.\\[\\]\r First, notice that if $x\\in\\overline{U_r}$ then $f(x)\\leq r$. This is because $\\mathbb{Q}_d$ is dense in $\\mathbb{R}$ as per (2), so for any $\\varepsilon\\gt 0$ we know there is some $r'$ such that $r\\lt r'\\lt r+\\varepsilon$. Then, $\\overline{U_r}\\subset U_{r'}$, so $f(x)\\lt r'$.\\[\\]\r Consider now some arbitrary $(a,b)\\subset [0,1]$. Choose some $x\\in f^{-1}(a,b)$. We know we can find some $p,q\\in (0,1]_d$ such that\r $$a\\lt p\\lt f(x)\\lt q\\lt b$$ \r and then $x\\notin\\overline{U_p}$ and $x\\in U_q$.\\[\\]\r Then, we let $V_x=U_q\\setminus\\overline{U_p}$. Consider some $v\\in V_x$. We know $v\\in U_q$ but $v\\notin\\overline{U_p}$, meaning $p\\lt v\\lt q$. Thus, $f(V_x)=(p,q)\\subset (a,b)$. As $V_x$ is open, we know every point in $f^{-1}(a,b)$ is interior, and hence the entire preimage is open. As these open intervals are arbitrary, we know $f$ is continuous on all of $X$. "}),Object(i.jsxs)("p",{children:["Note that although the above proof uses ","$\\mathbb{Q}_d$",", it is not necessary. In fact, any countable and dense set will do; one just needs to ensure it is easily enumerable for the argument to be straightforward and readable, and the dyadic rationals are one such choice. Additionally, every set similar to this will be dense in"," ","$\\mathbb{R}$","; the proof I demonstrated is just a trivial adaptation of the standard proof that ","$\\mathbb{Q}$"," in its entirety is dense."]}),Object(i.jsxs)("p",{children:["We now quickly provide one more definition. We say a space $X$ is"," ",Object(i.jsx)("strong",{children:"Hausdorff"})," if any two distinct points in $X$ also have disjoint neighborhoods. This important as the Moore plane is Hausdorff, but is not normal, and that will come into play in both the next theorem and our eventual conclusion."]}),Object(i.jsx)(_,{no:"4",statement:"\r If $X$ is Hausdorff with dense $E\\subset X$, and $f$ and $g$ are continuous functions on $X$ with $f(e)=g(e)$ for all $e\\in E$, then $f=g$.\r "}),Object(i.jsx)(k,{proof:"\r Suppose this is not the case. Then, there exists $x_0\\in X\\setminus E$ such that $f(x_0)\\neq g(x_0)$. Given $X$ is Hausdorff, there exist open neighborhoods of $f(x_0)$ and $g(x_0)$, $U_f$ and $U_g$ respectively, such that\r $$U_f\\cap U_g=\\varnothing .$$\r We know\r $$x_0\\in f^{-1}(U_f)\\cap g^{-1}(U_g)=V$$\r and $V$ is known to be open as both $f$ and $g$ are continuous. As $V$ is open and $E$ is dense, however, there is some $e\\in E$ also in $V$, and $f(e)=g(e)=\\lambda$, meaning\r $$\\lambda\\in  U_f\\cap U_g$$\r giving a contradiction."}),Object(i.jsxs)("p",{children:["A few more definitions are useful in the next proof. We say a topology $X$ is ",Object(i.jsx)("strong",{children:"discrete"})," if every single possible subset is included in the topology. Note that this contrasts with the"," ",Object(i.jsx)("strong",{children:"indiscrete"})," topology which would only include $X$ and $\\varnothing$. They are called so as in the discrete topology every element is distinguishable (in the sense that if $x\\in X$, then"," ","$\\left\\{ x\\right\\}\\in\\mathcal{T}$","), whereas in the indiscrete topology every single point is grouped together into one big open set (as we would have"," ","$\\mathcal{T}=\\left\\{\\varnothing, X\\right\\}$"," ). The reason why the discrete topology is useful in the upcoming proof is because"," ","$\\left\\{x\\right\\}$"," is both open and closed in it (given that its complement is too an open set)."]}),Object(i.jsxs)("p",{children:["The specific type of discreteness we will use is the one induced by the ",Object(i.jsx)("strong",{children:"subspace topology"}),". Given some $X$ with topology"," ","$\\mathcal{T}$",", the subspace topology on a subset $S\\subset X$ is defined as"," ","$$\\mathcal{T}_S =\\left\\{ S\\cap U:U\\in\\mathcal{T}\\right\\} .$$"]}),Object(i.jsx)(_,{no:"5",name:"Jones",statement:"\r If $X$ is normal and infinite, with dense $D\\subset X$, and  $C\\subset X$  closed and discrete by the subspace topology, then $2^{\\left| C\\right|}\\leq 2^{\\left| D\\right|}$, where $\\left| X\\right|$ is the cardinality of $X$."}),Object(i.jsx)(k,{proof:"\r Consider a non-empty $A\\subsetneq C$. We know $A$ and $C\\setminus A$ are closed and disjoint, so by Urysohn we can find a continuous function\r $$f_A :X\\rightarrow \\left[ 0,1\\right]$$\r such that $f\\left( A\\right) =\\left\\{ 0\\right\\}$ and  $f\\left( C\\setminus A\\right) =\\left\\{ 1\\right\\}$.\\[\\]\r Consider any continuous function $f :X\\rightarrow \\left[ 0,1\\right]$. As it is uniquely determined by the values it takes on $D$, as per (4), we could could give a full description by matching every element of $D$ with the functions output in $\\left[ 0,1\\right]$. Thus, the set of all such functions has cardinality\r $$\\left|\\left[ 0,1\\right]^D\\right| =\\left(2^{\\aleph_0}\\right)^{\\left| D\\right|}=2^{\\aleph_0} .$$\r We know that the set of functions of the form $f_A$ is a subset of all possible continuous functions. Thus, as $A$ is just any element of the powerset of $C$,\r $2^{\\left| C\\right|}\\leq  2^{\\aleph_0}$."}),Object(i.jsx)("p",{children:"Now, we return to the Moore plane. Our goal, as one would expect, is to find sets corresponding to $C$ and $D$ above whose cardinalities do not follow."}),Object(i.jsx)(_,{no:"6",statement:"\r With respect to the subspace topology, the $x$-axis, $\\mathbb{R}\\times\\left\\{ 0\\right\\}$, is discrete and closed in $\\Gamma$.\r "}),Object(i.jsx)(k,{proof:"\r Let $\\mathcal{X}$ be the $x$-axis. We know the only open sets in $\\Gamma$ which intersect $\\mathcal{X}$ are those generated by the local basis at any point $(p,0)$, $p\\in\\mathbb{R}$, as they include $(p,0)$. Thus, the subspace topology is on $\\mathcal{X}$ is\r $$T_\\mathcal{X}=\\left\\{\\left\\{\\left(p,0\\right)\\right\\}\\in\\mathcal{X}:p\\in\\mathbb{R}\\right\\}$$\r which means $\\mathcal{X}$ is discrete. As its complement is $\\varnothing$, we also know $\\mathcal{X}$ is closed. \r "}),Object(i.jsx)(_,{no:"7",statement:"\r The set $\\mathbb{Q}\\times\\mathbb{Q}_+$ is dense in $\\Gamma$.\r "}),Object(i.jsx)(k,{proof:"\r Let $\\mathcal{Q}=\\mathbb{Q}\\times\\mathbb{Q}_+$. Trivially, any $x\\in\\mathcal{Q}$ is also in $\\Gamma$. Consider some $x\\in\\Gamma \\setminus\\mathcal{Q}$. We know $x=(a,b)$ for some $(a,b)\\in\\mathbb{R}\\times\\mathbb{R}_+$. Let $N$ be an arbitrary neighborhood of $x$. Let $U$ be an open set such that $x\\in U\\subseteq N$.\\[\\]\r If $b\\neq 0$, then $U$ is an open disc around $x$ and so some $\\varepsilon\\gt 0$ is its radius. As $\\mathbb{Q}$ is dense in $\\mathbb{R}$, and likewise for $\\mathbb{Q}_+$ and $\\mathbb{R}_+$, we know we can find some point $p\\in\\mathbb{Q}$ and $q\\in\\mathbb{Q}_+$ such that\r $$\\left| p-a\\right|\\lt\\frac{\\varepsilon}{\\sqrt2}\\qquad \\left| q-b\\right|\\lt\\frac{\\varepsilon}{\\sqrt2}$$\r meaning\r $$\r \\left(p-a\\right)^2+\\left(q-b\\right)^2\\lt\\left(\\frac{\\varepsilon}{\\sqrt2}\\right)^2+\\left(\\frac{\\varepsilon}{\\sqrt2}\\right)^2=\\varepsilon^2\r $$\r hence $(p,q)\\in U$.\r Suppose now that $b=0$. We know then that some  $\\varepsilon\\gt 0$ defines the open disc centred around $(a,\\varepsilon )$ tangent to $x$. Again by density, we find some $p\\in\\mathbb{Q}$ and $q\\in\\mathbb{Q}_+$ such that\r $$\\left| p-a\\right|\\lt\\frac{\\varepsilon}{\\sqrt2}\\qquad\\frac{\\sqrt2-1}{\\sqrt2}\\varepsilon\\lt q\\lt\\frac{\\sqrt2+1}{\\sqrt2}\\varepsilon$$\r noting that our choice of $q$ implies too that $\\left| q-\\varepsilon\\right|\\lt\\frac{\\varepsilon}{\\sqrt2}$. Similarly then,\r $$\r \\left(p-a\\right)^2+\\left(q-\\varepsilon\\right)^2\\lt\\left(\\frac{\\varepsilon}{\\sqrt2}\\right)^2+\\left(\\frac{\\varepsilon}{\\sqrt2}\\right)^2=\\varepsilon^2\r $$\r thus $(p,q)\\in U$.\\[\\]\r Given the arbitrary neighborhood, any $x\\in\\Gamma$ that is not also in $\\mathcal{Q}$ is a limit point thereof. "}),Object(i.jsx)("p",{children:"At last, we can finally prove what was intended."}),Object(i.jsx)(_,{no:"8",statement:"\r The Moore plane is not normal.\r "}),Object(i.jsx)(k,{proof:"\r By (6) we know $\\mathcal{X}=\\mathbb{R}\\times\\left\\{ 0\\right\\}$ is closed and discrete in $\\Gamma$ with respect to the subspace topology. By (7), we know $\\mathcal{Q}=\\mathbb{Q}\\times\\mathbb{Q}_+$ is dense (and therefore infinite) in $\\Gamma$.\\[\\]\r We know $\\left|\\mathcal{X}\\right| =\\left|\\mathbb{R}\\right|$ and $\\left|\\mathcal{Q}\\right| =\\aleph_0$. Since $2^{\\left|\\mathbb{R}\\right|}\\gt 2^{\\aleph_0}$ we know $\\Gamma$ is not normal by Jones."}),Object(i.jsx)("p",{children:"This was really fun to make! I had little experience with topology outside of metric spaces prior to this, and going in I had no idea how to visualize topological spaces at all, nor why something like this could even be possible."}),Object(i.jsx)("p",{children:"The way I intuitively understand this begins with Urysohn, whose construction involved taking advantage of the space around closed sets (if the space is normal) to make a function based on shrinking a neighborhood covering it, until by limiting behaviour you end up back at the closed set itself."}),Object(i.jsx)("p",{children:"Then given that a dense set fully characterizes a continuous function, if you are able to do this Urysohn process on a closed and discrete subset of the space then it can only be so big (limited by the size of the dense set), as you are taking advantage of space between closures. If it turns out the set is actually larger than that, then it must be because the everything is so tightly packed together that you cannot separate closed sets - the space is non-normal."})]})}}]),a}(n.Component),M=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"componentDidMount",value:function(){window.KaTeXRender()}},{key:"render",value:function(){return Object(i.jsxs)("div",{className:"postContent leftMargin",children:[Object(i.jsx)("p",{children:'Logarithms are pretty simple functions first introduced in early high school as the answer to the question "What is the opposite of exponentiation?". However, there is actually a deeper history behind them, and that lies with their connection in group theory, which my friend mentioned to me and I presented today when I ran the problem solving session at my university.'}),Object(i.jsxs)("p",{children:["It is obvious that adding and subtracting numbers is easier than multiplying or dividing. After all, kids in elementary school become experts in the former, however even adults can have difficulty with fractions. Computationally, multiplication and division require far more resources as well, with the most optimal multiplication algorithm running in ","$\\mathcal{O}(n\\cdot \\log(n))$",", while addition is simply ","$\\mathcal{O}(n)$",'. Thus, there is a lot of motivation to transform multiplication tasks into addition tasks, and from this came the concept of logarithms. However, it is worth examining what the idea of "transforming" an operations actually means. Hence, we examine groups.'," "]}),Object(i.jsxs)("p",{children:["Consider some set $G$ with an operation $\\ast$ defined on it, both of which are often written together as $(G,\\ast)$. In order for this to become a ",Object(i.jsx)("strong",{children:"group"}),", we must have four requirements:"]}),Object(i.jsxs)("ol",{children:[Object(i.jsx)("li",{children:"For all $a,b\\in G$, $a\\ast b\\in G$;"}),Object(i.jsx)("li",{children:"For all $a,b,c\\in G$, $(a\\ast b)\\ast c = a\\ast(b\\ast c)$;"}),Object(i.jsx)("li",{children:"There exists some $e\\in G$ (often called the identity) such that $e\\ast a=a\\ast e=e$ for all $a\\in G$;"}),Object(i.jsxs)("li",{children:["Every $a\\in G$ has associated with it some unique element"," ","$a^{-1}\\in G$"," such that ","$a\\ast a^{-1}=e$","."]})]}),Object(i.jsxs)("p",{children:["Now, consider two groups, say $(G,\\ast)$ and $(H,\\cdot)$. Suppose we have some function $\\varphi : G \\longrightarrow H$ which satisfies $$\\varphi(a\\ast b)=\\varphi(a)\\cdot\\varphi(b)$$ for all $a,b\\in G$. We call this a group ",Object(i.jsx)("strong",{children:"homomorphism"}),". Note that nothing is specified about bijectivity or anything of the sort."]}),Object(i.jsxs)("p",{children:["This specific property is nice because it preserves group structure as we will see. For example, consider the identity of $G$, say $e$. Then, let $a\\in G$. We see","$$\\varphi(a)=\\varphi(e\\ast a)=\\varphi(e)\\cdot\\varphi(a).$$","This necessitates $\\varphi(e)$ to be the identity of $H$. So, group homomorphisms preserve identities."]}),Object(i.jsxs)("p",{children:["Now let us consider inverses, using $a$ again. We have","$$\\varphi(e)=\\varphi(a\\ast a^{-1})=\\varphi(a)\\cdot\\varphi(a^{-1}).$$","However as we know that $\\varphi(e)$ is the identity of $H$, this means that ","$\\varphi(a^{-1})$"," is the inverse of $\\varphi(a)$. In other words, ","$\\varphi(a^{-1})=(\\varphi(a))^{-1}$","; inverses are preserved too."]}),Object(i.jsxs)("p",{children:["Lastly, we will consider powers. We use the intuitive notation $a\\ast\\cdots\\ast a=a^n$ if we perform the operation $n$ times. Of course, $\\varphi(a^1)=(\\varphi(a))^1$. Now suppose this holds for all"," ","$k\\in\\mathbb{N}$"," where $k\\gt 1$. Then, consider $k+1$. We have","$$\\begin{aligned}\r\n\\varphi(a^{k+1})&=\\varphi(a^k\\ast a)\\\\\r\n&=\\varphi(a^k)\\cdot\\varphi(a)\\\\\r\n&=(\\varphi(a))^k\\cdot\\varphi(a)\\\\\r\n&=(\\varphi(a))^{k+1}\r\n\\end{aligned}$$","and so this holds for any natural number, by induction. Thus, $\\varphi$ preserves exponentiation."]}),Object(i.jsxs)("p",{children:["We know for all positive real numbers $x,y$ we have $$\\log(xy)=\\log(x)+\\log(y).$$ The domain of the logarithm lets us interpret this as a group homomorphism between"," ","$(\\mathbb{R}^{+},\\cdot)$"," (where $\\cdot$ is just multiplication) and ","$(\\mathbb{R},+)$","; the identity elements are 1 and 0 respectively; and inverses are given by inverting the number (since we do not have to worry about 0) and by subtraction, again respectively. We can then prove all commonly used log laws immediately from this fact. Even more significantly, as the logarithm is bijective with respect to these groups, this is actually a group"," ",Object(i.jsx)("strong",{children:"isomorphism"}),", and thus ","$(\\mathbb{R}^{+},\\cdot)$"," ","and ","$(\\mathbb{R},+)$"," are isomorphic. This is actually the heart of why the logarithm is so good at transforming these operations."]}),Object(i.jsx)("p",{children:"I think this is a great example of deep mathematical structure behind something which can be very easily understood, and shows that \"higher level\" maths isn't necessarily inaccessible or super abstract to the point that no tangible examples exist. I also don't want to study for my microeconomics exam, so writing this post lets me procrastinate while still feeling productive."})]})}}]),a}(n.Component),J=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"componentDidMount",value:function(){window.KaTeXRender()}},{key:"render",value:function(){return Object(i.jsx)("div",{id:"KaTeXSec",className:"coDiv posts",children:Object(i.jsxs)("ul",{children:[Object(i.jsx)(x,{date:"2021-08-03",dummyID:"7",name:"But What Is Entanglement Really?",summary:"Quantum entanglement, morally, has an intuitive definition: that some system cannot be understood as a combination of individual components, only holistically as an inseparable whole. Unsurprisingly, the precise mathematical definition herein is slightly more involved, introduced through the tensor product of Hilbert spaces. Some ways of measuring entanglement, specifically those related to entanglement entropy, are also surveyed.",full:Object(i.jsx)(O,{})}),Object(i.jsx)(x,{date:"2020-12-05",dummyID:"6",name:"Colouring Inside the Lines: the Jordan-Brouwer Separation Theorem",summary:"Children learn in elementary school how to colour inside the lines. In the late 1800s, mathematicians argued for over a decade whether this is always possible or not. This is a brief discussion of the Jordan curve theorem and what it tells us about the inside and outside of curves, and how manifolds with boundaries are used to state its generalization: the separation theorem. Transversal intersections and homotopy are introduced in order to discuss some techniques used in the proof of theorem.",full:Object(i.jsx)(X,{})}),Object(i.jsx)(x,{date:"2020-08-09",dummyID:"5",name:"Learning All J\u014dy\u014d Kanji in a Month: A Reflection on and Criticism of Heisig's RTK",summary:"I share my experience with arguably the most controversial book related to learning Japanese, pointing out the flaws I personally noticed as well as the strengths, and summarize my experience at different stages as well as overall. I try to describe what I believe its best use-case is, so that you may decide for yourself whether it will be a suitable technique.",full:Object(i.jsx)(B,{})}),Object(i.jsx)(x,{date:"2020-08-01",dummyID:"4",name:"Universal Isomorphism Theorems",summary:'Many algebraic structures and theorems have a similar feeling, ostensibly seen by the isomorphism theorems common to many of them. This is the motivation for universal algebra, and this post shows how it can be used to formulate the most general form of these isomorphism theorems. Lattices are also covered and used to more generally state and prove the "fourth" isomorphism theorem: the correspondence theorem. ',full:Object(i.jsx)(C,{})}),Object(i.jsx)(x,{date:"2020-03-05",dummyID:"3",name:"Stacking (Mathematical) Records on a (Locally) Flat Earth",summary:'Manifolds have a nice geometric intuition, with many examples seen when looking out any window. This is an introduction which formalizes (Euclidean) manifolds and smooth maps, culiminating to proving a cute theorem with nice visual intution: showing how you can pull apart a disk on one manifold to the union of multiple smaller disks on another manifold, "stacking" them on top of each other.',full:Object(i.jsx)(P,{})}),Object(i.jsx)(x,{date:"2019-12-22",dummyID:"2",name:"Non-normal Spaces: the Moore Plane and Continuous Functions",summary:'Topological normality, the ability to find space between distinct closed sets, seems like it should always be present (hence the name). However, this is not the case; the Moore plane is an easy-to-visualize counter-example. A theorem due to Jones which relies on different sizes of infinity is used to show that the Moore plane is, informally speaking, simply too "tightly packed" to be normal.',full:Object(i.jsx)(D,{})}),Object(i.jsx)(x,{date:"2019-10-19",dummyID:"1",name:"Viewing Logarithms as Group Isomorphisms",summary:"Logarithms are often used to make certain computations faster or easier to visualize. This is the result of a connection to group theory, with the logarithm being a special case of homomorphism, explicitly demonstrating why these types of maps are so useful.",full:Object(i.jsx)(M,{})})]})})}}]),a}(n.Component),Q=a(0),K=a(13),ee=a.p+"static/media/tottori.f5f93e62.jpg",te=window.innerHeight/100;var ae=function(){var e="Me riding a camel in the Tottori sanddunes",t=g();return Object(i.jsxs)("div",{className:"coDiv contact",children:[Object(i.jsx)("table",{className:"contactHead",children:t?Object(i.jsxs)("span",{children:[Object(i.jsx)("tr",{children:Object(i.jsx)("td",{className:"contactPhoto",children:Object(i.jsx)("img",{src:ee,alt:e})})}),Object(i.jsx)("tr",{children:Object(i.jsx)("td",{className:"contactMessage",children:Object(i.jsx)("h1",{children:"Thank you for reaching out!"})})})]}):Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"contactMessage",children:Object(i.jsx)("h1",{children:"Thank you for reaching out!"})}),Object(i.jsx)("td",{className:"contactPhoto",children:Object(i.jsx)("img",{src:ee,alt:e})})]})}),Object(i.jsx)(Q.b.Provider,{value:{color:"#4c2a6e",size:8*te},children:Object(i.jsx)("table",{className:"contactInfo",children:t?Object(i.jsxs)("span",{children:[Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"https://www.instagram.com/kazachekalex/",children:Object(i.jsx)(K.b,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsxs)("a",{href:"https://www.instagram.com/kazachekalex/",children:[" ","@kazachekalex"," "]})})]}),Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"mailto: alexdkazachek@gmail.com",children:Object(i.jsx)(K.d,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsxs)("a",{href:"mailto: alexdkazachek@gmail.com",children:[" ","alexdkazachek@gmail.com"," "]})})]}),Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"https://github.com/akazachek",children:Object(i.jsx)(K.a,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsx)("a",{href:"https://github.com/akazachek",children:" akazachek "})})]}),Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"https://linkedin.com/in/kazachek",children:Object(i.jsx)(K.c,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsx)("a",{href:"https://linkedin.com/in/kazachek",children:" kazachek "})})]})]}):Object(i.jsxs)(n.Fragment,{children:[Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"https://www.instagram.com/kazachekalex/",children:Object(i.jsx)(K.b,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsxs)("a",{href:"https://www.instagram.com/kazachekalex/",children:[" ","@kazachekalex"," "]})}),Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"mailto: alexdkazachek@gmail.com",children:Object(i.jsx)(K.d,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsxs)("a",{href:"mailto: alexdkazachek@gmail.com",children:[" ","alexdkazachek@gmail.com"," "]})})]}),Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"https://github.com/akazachek",children:Object(i.jsx)(K.a,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsx)("a",{href:"https://github.com/akazachek",children:" akazachek "})}),Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"https://linkedin.com/in/kazachek",children:Object(i.jsx)(K.c,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsx)("a",{href:"https://linkedin.com/in/kazachek",children:" kazachek "})})]})]})})})]})};var ie=function(){return Object(i.jsx)(h.a,{children:Object(i.jsxs)("div",{className:"App",children:[Object(i.jsx)(f,{}),Object(i.jsx)(l.a,{exact:!0,path:"/",children:Object(i.jsx)(w,{})}),Object(i.jsx)(l.a,{path:"/Posts",children:Object(i.jsx)(J,{})}),Object(i.jsx)(l.a,{path:"/Contact",children:Object(i.jsx)(ae,{})})]})})},ne=function(e){e&&e instanceof Function&&a.e(3).then(a.bind(null,43)).then((function(t){var a=t.getCLS,i=t.getFID,n=t.getFCP,s=t.getLCP,o=t.getTTFB;a(e),i(e),n(e),s(e),o(e)}))};r.a.render(Object(i.jsx)(s.a.StrictMode,{children:Object(i.jsx)(ie,{})}),document.getElementById("root")),ne()}},[[42,1,2]]]);
//# sourceMappingURL=main.415d9905.chunk.js.map