{"version":3,"sources":["components/NavItem.js","components/NavBar.js","components/MobileDetector.js","media/me.jpg","media/shortcv.pdf","contents/About.js","components/PostPreview.js","components/Figure.js","components/Theorem.js","components/Proof.js","contents/writing/2021-08-21/Entanglement.js","contents/writing/2021-08-16/SOME1.js","contents/writing/2020-12-05/fig1(koch).png","contents/writing/2020-12-05/fig2(transv).png","contents/writing/2020-12-05/fig3(wind).png","contents/writing/2020-12-05/fig4(gp).jpg","contents/writing/2020-12-05/JordanBrouwer.js","contents/writing/2020-08-09/HeisigKanji.js","components/Diagram.js","contents/writing/2020-08-01/svg1.svg","contents/writing/2020-08-01/svg2.svg","contents/writing/2020-08-01/svg3.svg","contents/writing/2020-08-01/svg4.svg","contents/writing/2020-08-01/UniversalIsomorphism.js","contents/writing/2020-03-05/svg1.svg","contents/writing/2020-03-05/svg2.svg","contents/writing/2020-03-05/svg3.svg","contents/writing/2020-03-05/svg4.svg","contents/writing/2020-03-05/svg5.svg","contents/writing/2020-03-05/svg6.svg","contents/writing/2020-03-05/svg7.svg","contents/writing/2020-03-05/svg8.svg","contents/writing/2020-03-05/fig1records.png","contents/writing/2020-03-05/StackOfRecords.js","contents/writing/2019-12-22/Normal.js","contents/writing/2019-10-19/LogIso.js","contents/Posts.js","media/tottori.jpg","contents/Contact.js","App.js","reportWebVitals.js","index.js"],"names":["NavItem","props","state","classes","this","item","setState","id","class","to","tolink","onClick","click","bind","Component","NavBar","handleClick","x","NavActiveItem","length","document","getElementById","classList","remove","add","MobileDetector","useState","window","innerWidth","width","setWidth","handleWindowSizeChange","useEffect","addEventListener","removeEventListener","About","str","className","src","pfp","alt","style","paddingTop","href","shortcv","PostPreview","props_","postOpen","postToggle","postTransition","useTransition","from","zIndex","opacity","transform","enter","leave","html","summary","dummyID","dangerouslySetInnerHTML","__html","date","name","map","key","div","full","Figure","caption","no","Theorem","theoremTitle","statement","Proof","proof","float","Entanglement","KaTeXRender","textAlign","title","frameborder","allow","allowfullscreen","height","SOME1","JordanBrouwer","Fig1Koch","Fig2Transv","Fig3Wind","Fig4GP","HeisigKanji","Diagram","UniversalIsomorphism","svg1","textIndent","svg2","svg3","svg4","StackOfRecords","svg5","svg6","svg7","svg8","Fig1GP","Normal","LogIso","Posts","vh","innerHeight","Contact","pfpAlt","isMobile","Provider","value","color","size","App","exact","path","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode"],"mappings":"uRA+BeA,E,kDA3Bb,WAAYC,GAAQ,IAAD,8BACjB,cAAMA,IACDC,MAAQ,CACXC,QAAS,sBAHM,E,gEAQO,cAApBC,KAAKH,MAAMI,MACbD,KAAKE,SAAS,CAAEH,QAAS,mC,+BAK3B,OACE,oBAAII,GAAIH,KAAKH,MAAMI,KAAMG,MAAOJ,KAAKF,MAAMC,QAA3C,SACE,cAAC,IAAD,CACEM,GAAIL,KAAKH,MAAMS,OACfC,QAASP,KAAKH,MAAMW,MAAMC,KAAKT,KAAMA,KAAKH,MAAMI,MAFlD,SAIGD,KAAKH,MAAMI,a,GArBAS,aCmDPC,E,kDAjDb,WAAYd,GAAQ,IAAD,8BACjB,cAAMA,IAMRe,YAAc,SAACC,GACT,EAAKf,MAAMgB,cAAcC,OAAS,GACpCC,SACGC,eAAe,EAAKnB,MAAMgB,eAC1BI,UAAUC,OAAO,aAEtB,EAAKjB,SAAS,CAAEY,cAAeD,IAAK,WAClCG,SACGC,eAAe,EAAKnB,MAAMgB,eAC1BI,UAAUE,IAAI,iBAdnB,EAAKtB,MAAQ,CACXgB,cAAe,aAHA,E,qDAqBjB,OACE,qBAAKV,MAAM,0BAAX,SACE,8BACE,+BACE,cAAC,EAAD,CACEH,KAAK,YACLK,OAAO,IACPE,MAAOR,KAAKY,cAEd,cAAC,EAAD,CACEX,KAAK,QACLK,OAAO,SACPE,MAAOR,KAAKY,cAEd,cAAC,EAAD,CACEX,KAAK,UACLK,OAAO,WACPE,MAAOR,KAAKY,yB,GAxCLF,a,QCgBNW,EAjBQ,WAAO,IAAD,EACDC,mBAASC,OAAOC,YADf,mBACpBC,EADoB,KACbC,EADa,KAGrBC,EAAyB,WAC7BD,EAASH,OAAOC,aAUlB,OAPAI,qBAAU,WAER,OADAL,OAAOM,iBAAiB,SAAUF,GAC3B,WACLJ,OAAOO,oBAAoB,SAAUH,MAEtC,IAEIF,GAAS,KChBH,MAA0B,+BCA1B,MAA0B,oCCyF1BM,MApFf,WACE,IAEMC,EAAMX,IAAmB,QAAU,cAEzC,OACE,qBAAKY,UAAU,QAAf,SACE,sBAAKA,UAAU,kCAAkC9B,GAAG,WAApD,UACE,qBAAK+B,IAAKC,EAAKC,IAPN,WAOmBH,UAAU,QACtC,uBACA,kDACA,qBAAII,MAAO,CAAEC,WAAY,OAAzB,UACG,IADH,oCAEoC,IAClC,mBAAGL,UAAU,aAAaM,KAAK,sBAA/B,iBAEK,IALP,sCAQA,uBACA,sEACwC,IACtC,mBACEN,UAAU,aACVM,KAAK,qDAFP,gCAKK,IAPP,0IASmE,IACjE,mBAAGN,UAAU,aAAaM,KAAK,6BAA/B,gEAVF,uKAeoC,IAClC,mBACEN,UAAU,aACVM,KAAK,8CAFP,kBAhBF,kDAsBkD,IAChD,mBACEN,UAAU,aACVM,KAAK,0EAFP,mBAvBF,uGAgCA,8WAK2D,IACzD,mBACEN,UAAU,aACVM,KAAK,6CAFP,yBAKK,IAXP,eAcA,0HAEqBP,EAFrB,mEAKA,oBAAGC,UAAU,KAAb,UACG,IADH,+BAEyB,IACvB,mBAAGA,UAAU,aAAaM,KAAMC,EAAhC,kBAHF,kBArES,aAqET,a,QCLOC,EApEK,SAACC,GAAY,IAAD,EACCpB,oBAAS,GADV,mBACvBqB,EADuB,KACbC,EADa,KAExBC,EAAiBC,YAAcH,EAAU,KAAM,CACnDI,KAAM,CAAEC,QAAS,EAAGC,QAAS,EAAGC,UAAW,qBAC3CC,MAAO,CAAEH,QAAS,EAAGC,QAAS,EAAGC,UAAW,mBAC5CE,MAAO,CAAEJ,QAAS,EAAGC,QAAS,EAAGC,UAAW,uBAG9C,SAAStC,IACPgC,GAAW,SAACD,GAAD,OAAeA,KAG5B,IAAoB,IAAhBD,EAAOW,KACT,IAAIC,EACF,mBACEnD,GAAIuC,EAAOa,QACXtB,UAAU,cACVuB,wBAAyB,CAAEC,OAAQf,EAAOY,gBAI1CA,EACF,mBAAGnD,GAAIuC,EAAOa,QAAStB,UAAU,cAAjC,SACGS,EAAOY,UAKd,OACE,gCACE,qBACErB,UAAWU,EAAW,uBAAyB,cAC/CxC,GAAIuC,EAAOgB,KACXnD,QAASK,EAHX,UAKE,uBAAOqB,UAAU,WAAjB,SACE,+BACE,oBAAIA,UAAU,YAAd,SACE,6BAAKS,EAAOiB,SAEd,oBAAI1B,UAAU,WAAd,SACE,6BAAKS,EAAOgB,cAIlB,8BAAMJ,OAINT,EAAee,KACb,gBAAG3D,EAAH,EAAGA,KAAM4D,EAAT,EAASA,IAAKhE,EAAd,EAAcA,MAAd,OACEI,GACE,eAAC,IAAS6D,IAAV,CAAc7B,UAAU,OAAiBI,MAAOxC,EAAhD,UACG6C,EAAOqB,KACR,wBACE9B,UAAU,mDACV1B,QAASK,EAFX,yBAFkCiD,UC9BnCG,E,uKApBX,OACE,wBAAO/B,UAAU,kBAAjB,UACE,6BACE,oBAAIA,UAAU,mCAAd,SACE,qBAAKC,IAAKlC,KAAKH,MAAMqC,IAAKE,IAAKpC,KAAKH,MAAMoE,cAG9C,6BACE,oBAAIhC,UAAU,UAAd,SACE,yCACUjC,KAAKH,MAAMqE,GADrB,KAC2BlE,KAAKH,MAAMoE,sB,GAb7BvD,aC6BNyD,E,kDA3Bb,WAAYtE,GAAQ,IAAD,8BACjB,cAAMA,IACDC,MAAQ,CACXsE,aACqB,MAAnB,EAAKvE,MAAM8D,KACU,MAAjB,EAAK9D,MAAMqE,GACT,YACA,WAAarE,EAAMqE,GAAK,KACT,MAAjB,EAAKrE,MAAMqE,GACX,YAAcrE,EAAM8D,KAAO,MAC3B,WAAa9D,EAAMqE,GAAK,KAAOrE,EAAM8D,KAAO,OAVnC,E,qDAejB,OACE,qBAAKvD,MAAM,UAAX,SACE,8BACE,iCAASJ,KAAKF,MAAMsE,eACpB,4BAAIpE,KAAKH,MAAMwE,qB,GArBH3D,aCgBP4D,E,uKAbX,OACE,qBAAKlE,MAAM,QAAX,SACE,8BACE,wCACCJ,KAAKH,MAAM0E,MACZ,sBAAMlC,MAAO,CAAEmC,MAAO,SAAtB,SAAkC,4B,GARxB9D,aC2gBL+D,E,kLArgBXlD,OAAOmD,gB,+BAIP,OACE,sBAAKtE,MAAM,yBAAX,UACE,8BACE,0DADF,6EAE4C,IAC1C,mBAAG6B,UAAU,aAAaM,KAAK,sBAA/B,gEAHF,0CAQA,mBAAGF,MAAO,CAAEsC,UAAW,UAAvB,SACE,wBACEzC,IAAI,4CACJ0C,MAAM,uBACNC,YAAY,IACZC,MAAM,2FACNC,iBAAe,EACf1C,MAAO,CAAE2C,OAAQ,OAAQvD,MAAO,WAGpC,o/BAiBA,uRAIwC,oDAJxC,+CAK4C,iDAA6B,IALzE,gDAMgD,YANhD,QAMkE,IAC/D,UAPH,6CAOwD,UAPxD,kCAQ4B,kCAR5B,sBASW,mDATX,WAWI,iFAGA,mHAdJ,YAgBY,UAhBZ,+CAgBmE,IAChE,4BAjBH,OAiBoC,YAjBpC,6CAkByB,iCAlBzB,+CAmBgC,UAnBhC,UAqBI,2GArBJ,2DAuB2D,IACxD,6CAxBH,UAwBwD,UAAW,IAxBnE,uFA0BgB,gCA1BhB,4JA4BwE,IACrE,mBA7BH,iDA6BqE,IAClE,oBA9BH,OAgCA,0EAC4C,oBAD5C,2YASA,mFACqD,IAClD,0BAFH,gCAE2D,IACxD,sBAHH,aAGoC,wBAHpC,mDAIwC,kDAJxC,4CAK0C,YAL1C,eAKmE,IAChE,4BANH,8BAM2D,YAN3D,UAOQ,8BAPR,oCAOwE,IACrE,oBARH,wFAWI,qIAXJ,oCAeA,iIAEmC,gCAFnC,OAEwE,IACrE,8BAHH,iCAGgE,IAC7D,kEAJH,MAIyE,IAJzE,wMAWS,uDAXT,kCAYS,uCAZT,OAYqD,YAZrD,qBAagB,sBAbhB,0UAqBuB,6BArBvB,uBAqByE,IACvE,+DAtBF,8JA2BA,0HAEyB,UAFzB,kCAEmE,IAChE,sCAHH,kBAGyD,IACtD,qBAJH,MAI4B,IACzB,6CALH,oDAMgC,sBANhC,MAM0D,IACvD,sBAPH,iDAOwE,IACrE,oBARH,WAQgC,UARhC,QAQgD,IAC9C,mDATF,sNAYkC,sBAZlC,gDAeA,+NAGyD,IACtD,qBAJH,yBAI+C,oBAJ/C,QAIyE,IACvE,gDALF,IAK+B,2BAL/B,iBAKyE,IACvE,wDANF,gBAMmD,IAChD,oCAPH,OASA,cAAC,EAAD,CACEyC,GAAG,IACHP,KAAK,wBACLU,UAAU,yNAGZ,cAAC,EAAD,CACEE,MAAM,68BAeR,gIAEkC,qBAFlC,kHAIuD,IACpD,iBALH,gQAQuE,IACpE,yBATH,iBAS2C,uBAT3C,OAWA,iEACkC,6CADlC,2BAEY,UAFZ,OAE2B,qBAF3B,mBAEiE,IAC9D,0BAHH,YAGuC,IACpC,wCAJH,8DAKgC,4BALhC,aAKuE,IACpE,0CANH,kDAOyB,gBAPzB,MAO6C,IAC1C,gCARH,mBAQoD,gBARpD,2CASuC,IACpC,2DAVH,WAUuE,IACpE,4BAXH,UAWuC,UAXvC,gBAW+D,IAC5D,gBAZH,2CAY4D,IACzD,kBAbH,YAa+B,UAb/B,MAa6C,IAC3C,kDAdF,QAcoC,+CAdpC,QAgBA,yFAC2D,IACzD,8CAFF,WAEmC,8CAFnC,kHAI4C,IAC1C,2DALF,iDAMe,uDANf,2CAOoB,sDAPpB,aAOgE,IAC9D,4CARF,oEAWA,8GAEY,IACT,iEAHH,+UAUA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,8LAGZ,iEACmC,cADnC,kCAEgB,kBAFhB,mBAEmD,IAChD,yBAHH,kBAG4C,IAC1C,wDAJF,wEAQS,cART,8EASuC,UATvC,0CAUkB,0BAVlB,OAUiD,IAC9C,6BAXH,+CAYgB,mBAZhB,QAYyC,qBAZzC,aAYyE,IACtE,4BAbH,8BAa2D,IACxD,8BAdH,0EAkBK,8CAlBL,2HAsBA,cAAC,EAAD,CACEH,GAAG,IACHP,KAAK,iBACLU,UAAU,8VAKZ,yDAC2B,UAD3B,OACyC,6CADzC,MACqE,IAClE,uBAFH,qEAGkC,cAHlC,oCAIa,kBAJb,yBAIsD,UAJtD,2EAKmE,IAChE,cANH,eAM6B,0CAN7B,mCAOW,2CAPX,OASA,qKAEyE,IACtE,0DAHH,SAGoE,IACjE,uBAJH,oCAI4D,UAJ5D,QAKM,qBALN,iJAOiC,qBAPjC,0BAQa,uBARb,QAQ0C,uBAR1C,gBASQ,cATR,SAS6B,qBAT7B,2GAaS,mBAbT,QAakC,sBAblC,YAakE,IAC/D,0BAdH,wEAeqC,cAAe,IAClD,+CAhBF,QAgBiC,kDAhBjC,yCAiBgC,+CAjBhC,kCAkBsB,0BAlBtB,sPAwBA,wYAMgC,IAC7B,6CAPH,QAOsD,IACnD,kBARH,yIAYA,oIAEsC,qBAFtC,YAEqE,IAClE,UAHH,iDAG4D,IACzD,mBAJH,mBAIuC,cAJvC,4BAKa,UALb,2BAKgD,IAC9C,gEANF,mCAOW,4BAPX,OAO4C,IACzC,4BARH,SAQsC,IACnC,iEATH,oBAUe,+CAVf,oBAU2D,IACxD,0BAXH,WAaI,yFAbJ,mWAoBsB,2DApBtB,gPA0BA,iKAEiE,IAC9D,YAHH,SAGsB,sCAHtB,QAGkE,IAChE,mDAJF,OAIqC,oBAJrC,MAI6D,IAC1D,kEALH,gCAM+B,0DAN/B,qBAOiB,0BAPjB,MASI,6GATJ,uBAWuB,wBAXvB,wIAa+C,IAC5C,6BAdH,WAcyC,6BAdzC,QAgBA,cAAC,EAAD,CACEH,GAAG,IACHP,KAAK,UACLU,UAAU,gUAIZ,uJAEkD,kBAFlD,mBAGa,0DAHb,OAGuD,UAHvD,OAKA,cAAC,EAAD,CACEH,GAAG,IACHG,UAAU,8LAGZ,cAAC,EAAD,CACEE,MAAM,y+CAmBR,qEACuC,sBADvC,2BAEsB,sBAFtB,iCAGU,8DAHV,8BAI8B,IAJ9B,4LAM2D,IACxD,yDAPH,WAOqE,IAClE,6BARH,8vCA8B6B,UA9B7B,uEA+BuC,IACpC,2CAhCH,QAkCA,mEACqC,UADrC,6nBAYgB,+DAZhB,0HAc0C,IACxC,8DAfF,OAiBA,gNAG0C,IACvC,2CAJH,QAIoD,IAClD,mBACEtC,UAAU,aACVM,KAAK,oEAFP,kBALF,0GAYsC,YAZtC,0EAaoD,IAClD,mBACEN,UAAU,aACVM,KAAK,2CAFP,kBAdF,iBAoBiB,qBApBjB,SAoB6C,cApB7C,qFAsBW,iBAtBX,aAsBuC,UAtBvC,mEAyBA,iMAG+B,yDAH/B,iIAK2D,IACxD,kBANH,mQASsE,IATtE,QAUQ,wBAVR,8BAU4D,IACzD,kBAXH,yLAce,yCAdf,QAgBA,kEACmC,sDADnC,MACwE,IACrE,cAFH,oBAEmC,gBAFnC,MAEuD,IAFvD,6SAQS,2DART,wDASuC,gBATvC,QAS6D,IAC1D,cAVH,gGAaA,4LAGyB,YAHzB,QAG2C,YAH3C,uCAIwB,UAJxB,sGAK+D,IAC7D,mBACEN,UAAU,aACVM,KAAK,iEAFP,kBANF,QAcA,q7B,GAlfmB7B,aCuBZuE,E,kLArBX1D,OAAOmD,gB,+BAIP,OACE,qBAAKtE,MAAM,yBAAX,SACE,mBAAGiC,MAAO,CAAEsC,UAAW,UAAvB,SACE,wBACEzC,IAAI,4CACJ0C,MAAM,uBACNC,YAAY,IACZC,MAAM,2FACNC,iBAAe,EACf1C,MAAO,CAAE2C,OAAQ,OAAQvD,MAAO,iB,GAfxBf,aCNL,MAA0B,uCCA1B,MAA0B,yCCA1B,MAA0B,uCCA1B,MAA0B,qCCyb1BwE,E,kLA3aX3D,OAAOmD,gB,+BAIP,OACE,sBAAKtE,MAAM,yBAAX,UACE,g8BAgBA,cAAC,EAAD,CAAQ8D,GAAG,IAAIhC,IAAKiD,EAAUlB,QAAQ,mBACtC,iLAGQ,mDAHR,uFAIsD,IACnD,sBALH,kGAQA,cAAC,EAAD,CACEN,KAAK,SACLU,UAAU,sKAGZ,4aAQA,2VAK2C,IACzC,6DANF,kDAOoB,sBAPpB,0EAQmD,IACjD,uDAEE,iFAGJ,2JAEwD,IACrD,gCAHH,qPAMsE,IACnE,uBAPH,0EAQ0B,gCAR1B,+OAYqB,0BAZrB,wFAeA,weASA,cAAC,EAAD,CACEH,GAAG,IACHG,UAAU,kGAGZ,cAAC,EAAD,CACEE,MAAM,+IAGR,uHAEmB,iCAFnB,KAEuD,IACrD,kDAHF,uIAOA,cAAC,EAAD,CACEZ,KAAK,iBACLU,UAAU,iTAGZ,6YAQA,0LAGc,kBAHd,0HAKc,wBALd,oEAMiC,IAC/B,+DAPF,kHASW,uDATX,cAUS,wBAVT,OAYA,cAAC,EAAD,CACEH,GAAG,IACHG,UAAU,0JAGZ,cAAC,EAAD,CAAOE,MAAM,grBACb,2UAOA,cAAC,EAAD,CACEL,GAAG,IACHhC,IAAKkD,EACLnB,QAAQ,6EAEV,6cAOY,mCAPZ,0dAgBA,2EACwC,+CADxC,iMAIyD,IACvD,4CALF,ikBAeA,gqBAYA,cAAC,EAAD,CACEC,GAAG,IACHP,KAAK,0BACLU,UAAU,gUAGZ,+HAEe,gDAFf,wEAKA,cAAC,EAAD,CACEH,GAAG,IACHP,KAAK,oBACLU,UAAU,scAGZ,qSAIyD,IACvD,yDALF,mGAM6D,IAEzD,uEARJ,iHAWqC,IAClC,mCAZH,oGAakE,IAC/D,kBAdH,0UAqBA,cAAC,EAAD,CACEH,GAAG,IACHG,UAAU,uQAGZ,cAAC,EAAD,CACEE,MAAM,8zCAiBR,cAAC,EAAD,CACEL,GAAG,IACHP,KAAK,mBACLU,UAAU,mQAGZ,cAAC,EAAD,CACEE,MAAM,gXAGR,2WAOA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,0KAEZ,cAAC,EAAD,CACEE,MAAM,+kBAIR,iEACkC,4CADlC,wBAEW,gCAFX,0IAIkD,IAC/C,sBALH,UAKiC,oCAAqC,IALtE,kBAMkB,0CANlB,cAMwE,IACtE,iDAEE,kFAGJ,kHAEY,kCAFZ,4NAK+D,IAC5D,gBANH,uFAO8B,IAC3B,4CARH,0DAWA,cAAC,EAAD,CACEL,GAAG,IACHhC,IAAKmD,EACLpB,QAAQ,mGAEV,0LAKA,cAAC,EAAD,CACEC,GAAG,IACHG,UAAU,ySAGZ,cAAC,EAAD,CACEE,MAAM,klDAqBR,4sBAYA,uCACS,uCADT,0EAEmD,yCAAqB,IAFxE,2DAGuD,IACpD,+CAJH,OAMA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,gKAGZ,cAAC,EAAD,CACEE,MAAM,suBAaR,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,gVAGZ,cAAC,EAAD,CACEE,MAAM,mZAGR,gUAOA,cAAC,EAAD,CACEL,GAAG,KACHG,UAAU,oNAGZ,cAAC,EAAD,CACEE,MAAM,6ZAGR,yUAKqB,sBALrB,6TAYA,cAAC,EAAD,CACEL,GAAG,KACHG,UAAU,0JAGZ,6QAMA,cAAC,EAAD,CACEH,GAAG,IACHhC,IAAKoD,EACLrB,QAAQ,mD,GAtaUvD,aC2ab6E,E,uKAjbX,OACE,sBAAKnF,MAAM,yBAAX,UACE,4BACE,6QAOF,gJAE+C,IAC7C,sDAHF,+4BAkBA,slBASmB,yCATnB,mEAUgC,qCAVhC,ysBAqBU,sDArBV,8uBAiCA,qkBAQkE,IAChE,yCATF,4lBAoBA,8eAOiD,IAC/C,kDARF,2NAWuC,sDAXvC,+FAeA,yUAKqB,yCALrB,omBAeE,0CACG,iDAhBL,8BAkBmB,2CAlBnB,aAmBE,0CACG,oDADH,SACgB,iDApBlB,iBAsBW,+CAtBX,aAuBE,0CACG,iDAxBL,6BA0Ba,oDA1Bb,oVAgCE,0CACG,wCADH,SACc,iDAjChB,iBAmCW,2CAnCX,UAoCE,0CACG,iDArCL,iBAuCW,0CAvCX,UAwCE,0CACG,8CADH,SACe,iDAzCjB,iBA2CW,8CA3CX,aA4CE,0CACG,8CADH,SACe,2CA7CjB,iBA+CW,iDA/CX,2FAkDA,oOAGiD,oCAHjD,uVAQ2C,qCAR3C,gLAaA,yzBAYE,iDAZF,0EAaE,4CAbF,OAa6B,0CAb7B,4PAkBE,gDACI,iDAnBN,SAsBE,0CACG,iDAvBL,SA0BE,0CACG,2CA3BL,mGA8BE,0CA9BF,yBA8B8B,4CA9B9B,iCA+BE,8CA/BF,kQAmCE,0CACG,8CADH,SACe,2CApCjB,UAsCI,+CAtCJ,oDAwCE,0CACG,wCADH,SACc,iDAzChB,UA2CI,4CA3CJ,OA2C+B,iDA3C/B,4VAkDA,0MAG6B,sCAH7B,OAG6C,oCAH7C,o/BAkB8C,qCAlB9C,kVAuBiD,IAC/C,sEAxBF,8NA6BA,ooCAmBA,8uCAkB+B,IAC7B,mBAAG6B,UAAU,aAAaM,KAAK,4BAA/B,0BAnBF,yCAoBwB,IACtB,mBAAGN,UAAU,aAAaM,KAAK,iCAA/B,wBArBF,2LA0BA,wVAKyB,oCALzB,wGAMoE,IAClE,4CAPF,UAQE,0CACG,uDATL,w1BAwBA,+xDAyB+C,sCAzB/C,obAkCA,m6BAeA,8JAE6C,IAC3C,mBAAGN,UAAU,aAAaM,KAAK,6CAA/B,4BAHF,8wDAkCA,gFACiD,uCADjD,yDAGE,0CACG,iDAJL,sBAMM,6CANN,2BAOE,0CACG,8CADH,SACe,2CARjB,UAUI,8CAVJ,onBAqBA,mEACoC,sDADpC,i7B,GA9ZkB7B,aCgBX8E,E,uKAbX,OACE,uBAAOpF,MAAM,kBAAb,SACE,6BACE,oBAAIA,MAAM,SAAV,SACE,qBAAK8B,IAAKlC,KAAKH,MAAMqC,IAAKE,IAAI,e,GAPpB1B,aCFP,MAA0B,iCCA1B,MAA0B,iCCA1B,MAA0B,iCCA1B,MAA0B,iCCwmB1B+E,E,kLAzlBXlE,OAAOmD,gB,+BAIP,OACE,sBAAKtE,MAAM,yBAAX,UACE,wDACyB,mDADzB,udAUA,cAAC,EAAD,CAAS8B,IAAKwD,IACd,mBAAGrD,MAAO,CAAEsD,WAAY,KAAxB,+GAIA,gDACkB,mBADlB,uEAEsC,IACnC,oDAHH,gBAGqE,IAClE,2CAJH,kCAKM,mBALN,+QASc,wDATd,gCAYA,2CACY,8CADZ,4CAEc,+CAFd,qcAUA,cAAC,EAAD,CAASzD,IAAK0D,IACd,wYAQA,cAAC,EAAD,CAAS1D,IAAK2D,IACd,gWAK+C,6CAAyB,IALxE,2FASA,oMAKA,cAAC,EAAD,CAAS3D,IAAK4D,IACd,qYAMmC,sBANnC,+SAWqB,6BAXrB,sNAgBA,+IAEsD,IACnD,sBAHH,sFAI0C,uBAJ1C,4sBAiBA,2MAGqC,mDAHrC,wEAI6D,IAC3D,0CALF,eAKoC,IACjC,oEAAqE,IANxE,+CAQE,0DARF,gHAUc,6CAVd,IAUwC,qBAVxC,WAUsE,IACnE,sBAXH,8JAagC,6BAbhC,sDAcyC,+BAdzC,yBAesB,8CAftB,MAemD,IAChD,qBAhBH,mBAgBuC,IACrC,4DAjBF,OAmBA,yDAC2B,qBAD3B,WACyD,IACtD,oEAAqE,IAFxE,ySAOsB,wCAPtB,gEAQ0D,IACvD,sBATH,aASoC,qBATpC,KAS4D,IAC1D,2CAVF,qWAqBA,+1BAiBY,0BAjBZ,gGAoBA,wMAGgC,6BAHhC,OAGkE,IAC/D,6BAJH,YAI0C,sBAJ1C,iBAKQ,qBALR,SAKmC,gDALnC,MAKkE,IAC/D,qBANH,wBAM8C,IAC5C,iDAPF,OAOmC,qBAPnC,8FASM,qBATN,+CASwE,IACrE,qBAVH,iNAgBW,iCAhBX,OAgBiD,IAC9C,iCAjBH,OAmBA,sDACwB,2BADxB,WAC4D,IACzD,sBAFH,kDAEsE,IACnE,qBAHH,qoBAmBqB,gDAnBrB,MAmBoD,IACjD,qBApBH,4BAoBgD,IAC7C,2BArBH,qSA0B6B,qBA1B7B,cA0B8D,IAC3D,qCA3BH,yGA4BwE,IACtE,kDA7BF,OA+BA,qSAMI,0EAGJ,qOAGgE,IAC7D,qBAJH,8CAMI,uHANJ,gFASc,qBATd,mBASiD,IAC9C,iCAVH,qKAYkE,IAC/D,iCAbH,sCAawE,IACrE,sBAdH,mEAiBA,cAAC,EAAD,CACE5B,GAAG,IACHG,UAAU,0MAGZ,cAAC,EAAD,CACEE,MAAM,qvBAcR,gKAEiE,IAC9D,6BAHH,QAGsC,6BAHtC,YAIQ,sBAJR,0DAKY,0DALZ,WAK0D,IACvD,qBANH,QAM8B,qBAN9B,MAQI,sGARJ,aAUa,6BAVb,8BAUsE,IACpE,iDAXF,0CAaA,0GAEM,iDAFN,kIAIiB,0DAJjB,yDAOA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,oGAGZ,cAAC,EAAD,CACEE,MAAM,ycAWR,qCACM,4CADN,qQAOI,mGAPJ,mJAYA,oIAIA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,kIAGZ,cAAC,EAAD,CACEE,MAAM,odAWR,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,4RAGZ,cAAC,EAAD,CACEE,MAAM,0cAYR,qEACA,cAAC,EAAD,CACEL,GAAG,IACHP,KAAK,kCACLU,UAAU,4SAIZ,cAAC,EAAD,CACEE,MAAM,yqCAaR,+OAKA,cAAC,EAAD,CACEL,GAAG,IACHP,KAAK,4BACLU,UAAU,uaAOZ,cAAC,EAAD,CACEE,MAAM,svDA0BR,iFACmD,IAChD,qBAFH,qDAII,gIAJJ,aAMY,2DANZ,kEAOyC,IACvC,0DARF,yEASuC,IACpC,iDAVH,2CAaI,qFAbJ,aAea,2BAfb,6EAgB0C,2BAhB1C,mBAiBiB,2BAjBjB,gHAqBA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,0LAIZ,cAAC,EAAD,CACEE,MAAM,2kBAOR,wEACuC,qBADvC,OACiE,IAC/D,iDAFF,6LAMA,cAAC,EAAD,CACEL,GAAG,IACHP,KAAK,6BACLU,UAAU,kOAGZ,cAAC,EAAD,CACEE,MAAM,4pDAoBR,0bAOE,0CAPF,sBAOuC,0CAPvC,yFASa,gDATb,4DAUuB,gDAVvB,wEAWoD,IAClD,gDAZF,sEAeA,4HAEc,0DAFd,4IAMA,+DAC8B,2DAD9B,KAEE,2CAFF,+FAG6C,IAC3C,mDAJF,YAKG,8DALH,kEAM+D,IAC7D,iDAPF,gDAOyE,IACtE,oBARH,2GASwD,IACtD,8CAVF,4CAU+D,IAC7D,8CAXF,SAWiC,6CAXjC,yEAcA,0QAMA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,oDAGZ,cAAC,EAAD,CACEE,MAAM,wdAWR,mBAAGlC,MAAO,CAAEsD,WAAY,KAAxB,iFAGA,yLAKI,+FALJ,sJASyB,IACtB,kDAVH,OAYA,cAAC,EAAD,CACEzB,GAAG,KACHP,KAAK,yBACLU,UAAU,kRAOZ,cAAC,EAAD,CACEE,MAAM,u/BASR,mkBAWA,gyB,GAxkB2B7D,aCZpB,MAA0B,iCCA1B,MAA0B,iCCA1B,MAA0B,iCCA1B,MAA0B,iCCA1B,MAA0B,iCCA1B,MAA0B,iCCA1B,MAA0B,iCCA1B,MAA0B,iCCA1B,MAA0B,wCC8a1BqF,E,kLAzZXxE,OAAOmD,gB,+BAIP,OACE,sBAAKtE,MAAM,yBAAX,UACE,4ZAQA,2EAC4C,+CAD5C,sBAEmB,uDAFnB,kLAKmB,sDALnB,mCAMkB,kBANlB,mBAMqD,IAClD,iCAPH,sBAOwD,IACrD,yBARH,qFASmD,IAChD,yCAVH,2DAW6B,mCAX7B,6MAcyD,uCAAc,IAdvE,yHAgBgD,gBAhBhD,uDAiBiD,IAC9C,iCAlBH,yBAkB2D,IACxD,6BAnBH,mDAoBW,6BApBX,gBAoBsD,IACnD,iCArBH,aAqB+C,IAC5C,0CAtBH,uBAsBkE,IAChE,sDAvBF,qBAyBA,yOAGqE,IAClE,0BAJH,8NAO6C,IAC3C,qDARF,yHAUqB,2BAVrB,qFAaA,cAAC,EAAD,CACE8D,GAAG,IACHG,UAAU,kEAIZ,cAAC,EAAD,CACEE,MAAM,ioBAOR,8LAG0B,6BAH1B,aAIE,iDAJF,iKAMgD,uBAAwB,IANxE,iBAOiB,oCAPjB,kCAQkB,kBARlB,wEASsC,qDAAiC,IATvE,iCAUiC,kCAAmC,IAClE,uDAXF,sCAWwE,IACrE,oCAZH,4EAa6C,gBAb7C,gGAeoB,kBAfpB,OAiBA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,kFAIZ,cAAC,EAAD,CACEE,MAAM,wcAOR,oGACsE,IACnE,gEAFH,+BAG0B,yCAH1B,uJAMS,6CANT,OAQA,mQAI2B,yCAJ3B,6KAO2B,6BAP3B,kDAQyC,IACtC,yCATH,iHAYG,8DAZH,wBAawB,oBAbxB,OAaiD,IAC/C,mDAdF,iJAgByC,IACtC,iCAjBH,8FAoBA,mMAKA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,wFAKZ,cAAC,EAAD,CACEE,MACE,oDACmB,yCADnB,OACiE,IAC9D,sCAFH,uHAI0B,sBAJ1B,wDAKqC,cAAC,EAAD,CAASrC,IAAKwD,IALnD,SAKkE,IAC/D,+CANH,kFAQY,IACT,iEATH,kJAY0B,SAI9B,cAAC,EAAD,CACExB,GAAG,IACHG,UAAU,4GAIZ,cAAC,EAAD,CAAOE,MAAM,+VACb,oQAMA,cAAC,EAAD,CACEL,GAAG,IACHP,KAAK,aACLU,UAAU,gKAKZ,cAAC,EAAD,CACEE,MACE,2PAI4B,cAAC,EAAD,CAASrC,IAAK0D,IAJ1C,cAI8D,IAC3D,oDALH,mIAO8D,IAC5D,cAAC,EAAD,CAAS1D,IAAK2D,IARhB,UAUI,qKAVJ,0EAaW,cAAC,EAAD,CAAS3D,IAAK4D,IAbzB,4CAkBJ,oHAIA,cAAC,EAAD,CACE5B,GAAG,IACHG,UAAU,yGAGZ,cAAC,EAAD,CACEE,MAAM,0NAKR,uRAI8C,IAC5C,0DALF,2cAcA,cAAC,EAAD,CACEL,GAAG,IACHP,KAAK,iCACLU,UAAU,+GAGZ,2PAMA,cAAC,EAAD,CACEH,GAAG,IACHG,UAAU,4HAGZ,cAAC,EAAD,CACEE,MACE,8GAES,cAAC,EAAD,CAASrC,IAAK8D,IAFvB,6BAE0D,IACxD,cAAC,EAAD,CAAS9D,IAAK+D,IAHhB,iGAIoD,IACjD,oCALH,0CAMe,+BANf,uDAWJ,uMAG2B,kBAH3B,uEAI0D,WAJ1D,ihBAYuD,IACrD,iDAbF,OAeA,6GACwE,IACrE,wDAFH,uNAK2D,IACzD,8DANF,qDAO0B,IACvB,wDARH,yKAYA,cAAC,EAAD,CACE/B,GAAG,IACHP,KAAK,2BACLU,UAAU,8HAGZ,cAAC,EAAD,CACEE,MACE,oFACmD,IACjD,cAAC,EAAD,CAASrC,IAAKgE,IAFhB,WAEiC,IAC9B,wDAHH,wGAKiC,IAC9B,mDANH,qHAQoC,IACjC,iDATH,2PAeS,cAAC,EAAD,CAAShE,IAAKiE,IAfvB,oBAmBJ,+OAGmE,IACjE,2CAJF,sBAI0C,IACvC,oDALH,yEAM0D,IACvD,6BAPH,8QAW6B,mDAX7B,8FAeA,cAAC,EAAD,CACEjC,GAAG,KACHP,KAAK,gBACLU,UAAU,kNAGZ,cAAC,EAAD,CACEE,MAAM,ymBAOR,uGACuE,IACpE,uCAFH,4OAOG,qEAPH,QAQQ,IACL,gEATH,iIAWgD,IAC7C,+BAAgC,IAE/B,8EACA,IAfJ,4BAgB4B,oBAhB5B,uHAoBA,gEACkC,gBADlC,kLAIqB,gCAJrB,qIAQA,yUAKgB,sDALhB,OAOA,cAAC,EAAD,CACEL,GAAG,IACHhC,IAAKkE,EACLnC,QAAQ,2DAEV,cAAC,EAAD,CACEC,GAAG,KACHP,KAAK,mBACLU,UAAU,2VAGZ,cAAC,EAAD,CACEE,MAAM,o1CAOR,8lB,GA3YqB7D,aCuUd2F,E,kLAjVX9E,OAAOmD,gB,+BAIP,OACE,sBAAKtE,MAAM,yBAAX,UACE,oGACsE,IACpE,oEAFF,4FAGiE,IAC/D,oCAJF,8SAQmC,yCARnC,+CAWA,sGAEE,+CAFF,IAE8B,iBAF9B,8CAKA,+BACE,qEAAuC,iBAAvC,OACA,+DACgC,iBADhC,wBACuE,IACpE,iBAFH,WAIA,6EAC8C,iBAD9C,yBAEiB,iBAFjB,UAKF,oBAAGiC,MAAO,CAAEsD,WAAY,KAAxB,gCACqB,uDADrB,iEAE+C,0CAF/C,2BAGuB,iBAHvB,sBAG4D,IAC1D,4CAJF,iCAMA,mNAG6C,2CAAuB,IACjE,iBAJH,4EAOA,+BACE,sEACsC,sBADtC,+BAIA,uGACuE,IACpE,4BAFH,8EAMF,8DACgC,iBADhC,UACyD,IACvD,+CAFF,OAEiC,iBAFjC,wEAGgD,sBAAuB,IAHvE,uDAIqD,iBAAkB,IAJvE,gKASA,6DAC8B,qCAD9B,kBACyD,iBADzD,6BAE0B,mCAF1B,sBAEuD,iBAAkB,IAFzE,4CAG4C,sBAH5C,mDAI4C,wBAAyB,IAJrE,mEAMG,+BANH,+CAO+C,sBAP/C,4KAUgC,iBAVhC,qIAY2C,kBAZ3C,iEAeA,yGAEM,iDAFN,2CAGO,kBAHP,UAKI,+EALJ,uuBAiBA,gLAEyE,IACvE,4CAHF,sMAQA,kJAE+C,kBAF/C,8TASA,cAAC,EAAD,CACEzB,GAAG,IACHG,UAAU,gPAKZ,cAAC,EAAD,CACEE,MAAM,maAKR,cAAC,EAAD,CACEL,GAAG,IACHG,UACE,wCACM,sDADN,KAC0C,kBAD1C,eAEa,IAET,uGACA,IALJ,8CAM8C,gBAN9C,SAUJ,cAAC,EAAD,CACEE,MAAM,iaAOR,qLAKA,cAAC,EAAD,CACEL,GAAG,IACHP,KAAK,UACLU,UAAU,gMAGZ,cAAC,EAAD,CACEE,MAAM,0+DAoBR,yEAC2C,kBAD3C,oRAKmE,IAChE,gBANH,sFAOyC,gBAPzC,gCAUA,kGACoE,IAClE,+CAFF,gOAOA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,wJAIZ,cAAC,EAAD,CACEE,MAAM,gjBASR,+GAES,8CAFT,kGAG8D,IAC5D,gDAJF,mLAMkE,IAC/D,0CAPH,uHASiC,IAC9B,oDAVH,sFAWuE,IACpE,yBAZH,oFAeA,yGAEM,uDAFN,iCAEuE,IACpE,iBAHH,kEAIa,IAET,0EAGJ,cAAC,EAAD,CACEL,GAAG,IACHP,KAAK,QACLU,UAAU,gPAGZ,cAAC,EAAD,CACEE,MAAM,g8BASR,wLAKA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,+IAIZ,cAAC,EAAD,CACEE,MAAM,yfAMR,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,2EAIZ,cAAC,EAAD,CACEE,MAAM,wvDAkBR,iFACA,cAAC,EAAD,CACEL,GAAG,IACHG,UAAU,yCAIZ,cAAC,EAAD,CACEE,MAAM,keAIR,sQAMA,yUAOA,2f,GArUa7D,aC8GN4F,E,kLA5GX/E,OAAOmD,gB,+BAIP,OACE,sBAAKzC,UAAU,yBAAf,UACE,mZAQA,iYAMc,mCANd,8BAOU,oBAPV,mQAWU,OAEV,uLAGW,2CAHX,uCAKA,+BACE,wEACA,gGACA,4IAIA,4FAC4D,IACzD,iBAFH,cAEgC,oBAFhC,UAKF,2QAIoB,kDAJpB,iFAOA,oMAIG,mEAJH,6GAQA,uFAGI,6EAHJ,iFAMc,qBANd,qDAOgB,wCAPhB,mCAUA,4OAGwE,IACrE,qBAJH,kDAMI,mMANJ,wGAWA,wMAGiD,IAC9C,6BAJH,gDAKO,oBALP,0WAUoD,IAClD,iDAXF,cAW0C,6BAA8B,IAXxE,OAYO,oBAZP,mHAeA,ma,GAjGavB,aCsFN6F,E,kLA5EXhF,OAAOmD,gB,+BAIP,OACE,qBAAKvE,GAAG,WAAW8B,UAAU,cAA7B,SACE,+BACE,cAAC,EAAD,CACEyB,KAAK,aACLH,QAAQ,IACRI,KAAK,mCACLL,QAAQ,wqBAERS,KAAM,cAAC,EAAD,IACNV,MAAM,IAER,cAAC,EAAD,CACEK,KAAK,aACLH,QAAQ,IACRI,KAAK,+BACLL,QAAQ,mrBAKRS,KAAM,cAAC,EAAD,IACNV,MAAM,IAER,cAAC,EAAD,CACEK,KAAK,aACLH,QAAQ,IACRI,KAAK,oEACLL,QAAQ,qfACRS,KAAM,cAAC,EAAD,MAER,cAAC,EAAD,CACEL,KAAK,aACLH,QAAQ,IACRI,KAAK,8FACLL,QAAQ,8WACRS,KAAM,cAAC,EAAD,MAER,cAAC,EAAD,CACEL,KAAK,aACLH,QAAQ,IACRI,KAAK,iCACLL,QAAQ,gaACRS,KAAM,cAAC,EAAD,MAER,cAAC,EAAD,CACEL,KAAK,aACLH,QAAQ,IACRI,KAAK,4DACLL,QAAQ,4YACRS,KAAM,cAAC,EAAD,MAER,cAAC,EAAD,CACEL,KAAK,aACLH,QAAQ,IACRI,KAAK,8DACLL,QAAQ,6YACRS,KAAM,cAAC,EAAD,MAER,cAAC,EAAD,CACEL,KAAK,aACLH,QAAQ,IACRI,KAAK,2CACLL,QAAQ,qQACRS,KAAM,cAAC,EAAD,e,GAtEErD,a,gBCbL,OAA0B,oCCcrC8F,GAAKjF,OAAOkF,YAAc,IAuIfC,OArIf,WACE,IAAMC,EAAS,6CACTC,EAAWvF,IACjB,OACE,sBAAKY,UAAU,gBAAf,UACE,uBAAOA,UAAU,cAAjB,SACG2E,EACC,iCACE,6BACE,oBAAI3E,UAAU,eAAd,SACE,qBAAKC,IAAKC,GAAKC,IAAKuE,QAGxB,6BACE,oBAAI1E,UAAU,iBAAd,SACE,oEAKN,+BACE,oBAAIA,UAAU,iBAAd,SACE,+DAEF,oBAAIA,UAAU,eAAd,SACE,qBAAKC,IAAKC,GAAKC,IAAKuE,WAK5B,cAAC,IAAYE,SAAb,CAAsBC,MAAO,CAAEC,MAjClB,UAiCuCC,KAAM,EAAIR,IAA9D,SACE,uBAAOvE,UAAU,cAAjB,SACG2E,EACC,iCACE,+BACE,oBAAI3E,UAAU,aAAd,SACE,mBAAGM,KAAK,0CAAR,SACE,cAAC,KAAD,QAGJ,oBAAIN,UAAU,SAAd,SACE,oBAAGM,KAAK,0CAAR,UACG,IADH,gBAEgB,YAIpB,+BACE,oBAAIN,UAAU,aAAd,SACE,mBAAGM,KAAK,kCAAR,SACE,cAAC,KAAD,QAGJ,oBAAIN,UAAU,SAAd,SACE,oBAAGM,KAAK,kCAAR,UACG,IADH,0BAE0B,YAI9B,+BACE,oBAAIN,UAAU,aAAd,SACE,mBAAGM,KAAK,+BAAR,SACE,cAAC,KAAD,QAGJ,oBAAIN,UAAU,SAAd,SACE,mBAAGM,KAAK,+BAAR,8BAGJ,+BACE,oBAAIN,UAAU,aAAd,SACE,mBAAGM,KAAK,mCAAR,SACE,cAAC,KAAD,QAGJ,oBAAIN,UAAU,SAAd,SACE,mBAAGM,KAAK,mCAAR,gCAKN,eAAC,WAAD,WACE,+BACE,oBAAIN,UAAU,aAAd,SACE,mBAAGM,KAAK,0CAAR,SACE,cAAC,KAAD,QAGJ,oBAAIN,UAAU,SAAd,SACE,oBAAGM,KAAK,0CAAR,UACG,IADH,gBAEgB,SAGlB,oBAAIN,UAAU,aAAd,SACE,mBAAGM,KAAK,kCAAR,SACE,cAAC,KAAD,QAGJ,oBAAIN,UAAU,SAAd,SACE,oBAAGM,KAAK,kCAAR,UACG,IADH,0BAE0B,YAI9B,+BACE,oBAAIN,UAAU,aAAd,SACE,mBAAGM,KAAK,+BAAR,SACE,cAAC,KAAD,QAGJ,oBAAIN,UAAU,SAAd,SACE,mBAAGM,KAAK,+BAAR,2BAEF,oBAAIN,UAAU,aAAd,SACE,mBAAGM,KAAK,mCAAR,SACE,cAAC,KAAD,QAGJ,oBAAIN,UAAU,SAAd,SACE,mBAAGM,KAAK,mCAAR,wCC1GH0E,OAtBf,WAEE,OACE,cAAC,IAAD,UACE,sBAAKhF,UAAU,MAAf,UACE,cAAC,EAAD,IAEA,cAAC,IAAD,CAAOiF,OAAK,EAACC,KAAK,IAAlB,SACE,cAAC,EAAD,MAEF,cAAC,IAAD,CAAOA,KAAK,SAAZ,SACE,cAAC,EAAD,MAEF,cAAC,IAAD,CAAOA,KAAK,WAAZ,SACE,cAAC,GAAD,YCZKC,GAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,6BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,GAAD,MAEF/G,SAASC,eAAe,SAM1BmG,O","file":"static/js/main.26c0dc83.chunk.js","sourcesContent":["import React, { Component } from \"react\";\r\nimport { Link } from \"react-router-dom\";\r\n\r\nclass NavItem extends Component {\r\n  constructor(props) {\r\n    super(props);\r\n    this.state = {\r\n      classes: \"hvr-sweep-to-right\"\r\n    };\r\n  }\r\n\r\n  componentDidMount() {\r\n    if (this.props.item === \"Who Am I?\") {\r\n      this.setState({ classes: \"hvr-sweep-to-right navActive\" });\r\n    }\r\n  }\r\n\r\n  render() {\r\n    return (\r\n      <li id={this.props.item} class={this.state.classes}>\r\n        <Link\r\n          to={this.props.tolink}\r\n          onClick={this.props.click.bind(this, this.props.item)}\r\n        >\r\n          {this.props.item}\r\n        </Link>\r\n      </li>\r\n    );\r\n  }\r\n}\r\n\r\nexport default NavItem;\r\n","import React, { Component } from \"react\";\r\nimport NavItem from \"./NavItem\";\r\n\r\nclass NavBar extends Component {\r\n\r\n  constructor(props) {\r\n    super(props);\r\n    this.state = {\r\n      NavActiveItem: \"Who Am I?\"\r\n    };\r\n  }\r\n\r\n  handleClick = (x) => {\r\n    if (this.state.NavActiveItem.length > 0) {\r\n      document\r\n        .getElementById(this.state.NavActiveItem)\r\n        .classList.remove(\"navActive\");\r\n    }\r\n    this.setState({ NavActiveItem: x }, () => {\r\n      document\r\n        .getElementById(this.state.NavActiveItem)\r\n        .classList.add(\"navActive\");\r\n    });\r\n  };\r\n\r\n  render() {\r\n    return (\r\n      <div class=\"navContainer centredBox\">\r\n        <nav>\r\n          <ul>\r\n            <NavItem\r\n              item=\"Who Am I?\"\r\n              tolink=\"/\"\r\n              click={this.handleClick}\r\n            ></NavItem>\r\n            <NavItem\r\n              item=\"Posts\"\r\n              tolink=\"/Posts\"\r\n              click={this.handleClick}\r\n            ></NavItem>\r\n            <NavItem\r\n              item=\"Contact\"\r\n              tolink=\"/Contact\"\r\n              click={this.handleClick}\r\n            ></NavItem>\r\n          </ul>\r\n        </nav>\r\n      </div>\r\n    );\r\n  }\r\n\r\n  \r\n}\r\n\r\nexport default NavBar;","import { useState, useEffect } from \"react\";\r\n\r\nconst MobileDetector = () => {\r\n  const [width, setWidth] = useState(window.innerWidth);\r\n\r\n  const handleWindowSizeChange = () => {\r\n    setWidth(window.innerWidth);\r\n  };\r\n\r\n  useEffect(() => {\r\n    window.addEventListener(\"resize\", handleWindowSizeChange);\r\n    return () => {\r\n      window.removeEventListener(\"resize\", handleWindowSizeChange);\r\n    };\r\n  }, {});\r\n\r\n  return width <= 768;\r\n};\r\n\r\nexport default MobileDetector;\r\n","export default __webpack_public_path__ + \"static/media/me.5a56aa7d.jpg\";","export default __webpack_public_path__ + \"static/media/shortcv.833e982e.pdf\";","import React from \"react\";\r\nimport MobileDetector from \"../components/MobileDetector\";\r\nimport pfp from \"../media/me.jpg\";\r\nimport shortcv from \"../media/shortcv.pdf\";\r\n\r\nfunction About() {\r\n  const pfpAlt = \"Headshot\";\r\n  const cvDate = \"2021-09-06\";\r\n  const str = MobileDetector() ? \"above\" : \"to the left\";\r\n\r\n  return (\r\n    <div className=\"coDiv\">\r\n      <div className=\"about centredBox leftMarginWide\" id=\"aboutSec\">\r\n        <img src={pfp} alt={pfpAlt} className=\"pfp\"></img>\r\n        <br></br>\r\n        <h1> Hey, I'm Alex! </h1>\r\n        <h3 style={{ paddingTop: \"1vh\" }}>\r\n          {\" \"}\r\n          I'm a third year undergraduate at{\" \"}\r\n          <a className=\"linkPurple\" href=\"https://www.uwo.ca/\">\r\n            UWO\r\n          </a>{\" \"}\r\n          in mathematics and data science.\r\n        </h3>\r\n        <br></br>\r\n        <p>\r\n          This past summer I did research under{\" \"}\r\n          <a\r\n            className=\"linkPurple\"\r\n            href=\"https://www.math.uwo.ca/faculty/barron/barron.html\"\r\n          >\r\n            Dr. Tatyana Barron\r\n          </a>{\" \"}\r\n          through an NSERC USRA, covering some aspects of quantum state geometry\r\n          and information theory. I was also one of the organizers for the{\" \"}\r\n          <a className=\"linkPurple\" href=\"https://cumc.math.ca/2021/\">\r\n            2021 Canadian Undergraduate Mathematics Conference\r\n          </a>\r\n          . My role was in creating the website, as well as organizing the\r\n          panels and workshops. I also presented an introduction to quantum\r\n          entanglement, which you can watch{\" \"}\r\n          <a\r\n            className=\"linkPurple\"\r\n            href=\"https://www.youtube.com/watch?v=K2HlbbaDlyE\"\r\n          >\r\n            here\r\n          </a>\r\n          . Right now, I'm in charge of the academics for{\" \"}\r\n          <a\r\n            className=\"linkPurple\"\r\n            href=\"https://www.uwo.ca/math/undergraduate/current_students/macaw/index.html\"\r\n          >\r\n            MaCAW\r\n          </a>\r\n          , the official club of Western's mathematics department, putting on\r\n          events like student seminars.\r\n        </p>\r\n        <p>\r\n          Outside of academics, I like to go rock climbing and do calisthenics.\r\n          I'm also interested in fashion, with my Instagram being mostly outfit\r\n          shots. Being interested in linguistics in general, I like learning\r\n          languages, and know some Russian and Japanese. Convincing myself that\r\n          it's cardio, I also play a lot of Beat Saber (here is my{\" \"}\r\n          <a\r\n            className=\"linkPurple\"\r\n            href=\"https://scoresaber.com/u/76561198089263800\"\r\n          >\r\n            Score Saber\r\n          </a>{\" \"}\r\n          profile).\r\n        </p>\r\n        <p>\r\n          Feel free to read my blog posts or get in touch with me on my socials,\r\n          both of which are {str}. I hope you enjoy your stay. Food and drink is\r\n          not provided.\r\n        </p>\r\n        <p className=\"cv\">\r\n          {\" \"}\r\n          My résumé is available{\" \"}\r\n          <a className=\"linkPurple\" href={shortcv}>\r\n            here\r\n          </a>\r\n          . Last updated {cvDate}.\r\n        </p>\r\n      </div>\r\n    </div>\r\n  );\r\n}\r\n\r\nexport default About;\r\n","import React, { useState } from \"react\";\r\nimport { useTransition, animated } from \"react-spring\";\r\n\r\nconst PostPreview = (props_) => {\r\n  const [postOpen, postToggle] = useState(false);\r\n  const postTransition = useTransition(postOpen, null, {\r\n    from: { zIndex: -1, opacity: 0, transform: \"translateX(-30vw)\" },\r\n    enter: { zIndex: -1, opacity: 1, transform: \"translateX(0vw)\" },\r\n    leave: { zIndex: -1, opacity: 0, transform: \"translateX(-30vw)\" }\r\n  });\r\n\r\n  function handleClick() {\r\n    postToggle((postOpen) => !postOpen);\r\n  }\r\n\r\n  if (props_.html === true) {\r\n    var summary = (\r\n      <p\r\n        id={props_.dummyID}\r\n        className=\"postSummary\"\r\n        dangerouslySetInnerHTML={{ __html: props_.summary }}\r\n      ></p>\r\n    );\r\n  } else {\r\n    var summary = (\r\n      <p id={props_.dummyID} className=\"postSummary\">\r\n        {props_.summary}\r\n      </p>\r\n    );\r\n  }\r\n\r\n  return (\r\n    <div>\r\n      <li\r\n        className={postOpen ? \"postPreview postOpen\" : \"postPreview\"}\r\n        id={props_.date}\r\n        onClick={handleClick}\r\n      >\r\n        <table className=\"postHead\">\r\n          <tr>\r\n            <td className=\"postTitle\">\r\n              <h2>{props_.name}</h2>\r\n            </td>\r\n            <td className=\"postDate\">\r\n              <h4>{props_.date}</h4>\r\n            </td>\r\n          </tr>\r\n        </table>\r\n        <div>{summary}</div>\r\n      </li>\r\n      {\r\n        /* this will not work if i map anything --other-- than literally the word 'props' so i had to rename the PostPreview props */\r\n        postTransition.map(\r\n          ({ item, key, props }) =>\r\n            item && (\r\n              <animated.div className=\"post\" key={key} style={props}>\r\n                {props_.full}\r\n                <button\r\n                  className=\"postEndButton hvr-overline-from-right leftMargin\"\r\n                  onClick={handleClick}\r\n                >\r\n                  Hide Post\r\n                </button>\r\n              </animated.div>\r\n            )\r\n        )\r\n      }\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default PostPreview;\r\n","import React, { Component } from \"react\";\r\n\r\nclass Figure extends Component {\r\n\r\n  render() {\r\n    return (\r\n      <table className=\"figureContainer\">\r\n        <tr>\r\n          <td className=\"figure centredBox leftMarginWide\">\r\n            <img src={this.props.src} alt={this.props.caption}></img>\r\n          </td>\r\n        </tr>\r\n        <tr>\r\n          <td className=\"caption\">\r\n            <h4>\r\n              Figure {this.props.no}: {this.props.caption}\r\n            </h4>\r\n          </td>\r\n        </tr>\r\n      </table>\r\n    );\r\n  }\r\n\r\n}\r\n\r\nexport default Figure;","import React, { Component } from \"react\";\r\n\r\nclass Theorem extends Component {\r\n\r\n  constructor(props) {\r\n    super(props);\r\n    this.state = {\r\n      theoremTitle:\r\n        this.props.name == null\r\n          ? this.props.no == null\r\n            ? \"Theorem. \"\r\n            : \"Theorem \" + props.no + \". \"\r\n          : this.props.no == null\r\n          ? \"Theorem (\" + props.name + \"). \"\r\n          : \"Theorem \" + props.no + \" (\" + props.name + \"). \"\r\n    };\r\n  }\r\n\r\n  render() {\r\n    return (\r\n      <div class=\"theorem\">\r\n        <p>\r\n          <strong>{this.state.theoremTitle}</strong>\r\n          <i>{this.props.statement}</i>\r\n        </p>\r\n      </div>\r\n    );\r\n  }\r\n\r\n}\r\n\r\nexport default Theorem;","import React, { Component } from \"react\";\r\n\r\nclass Proof extends Component {\r\n\r\n  render() {\r\n    return (\r\n      <div class=\"proof\">\r\n        <p>\r\n          <i>Proof. </i>\r\n          {this.props.proof}\r\n          <span style={{ float: \"right\" }}>{\"\\\\(\\\\square\\\\)\"}</span>\r\n        </p>\r\n      </div>\r\n    );\r\n  }\r\n\r\n}\r\n\r\nexport default Proof;","import React, { Component } from \"react\";\r\n/* environments */\r\nimport Figure from \"../../../components/Figure\";\r\nimport Theorem from \"../../../components/Theorem\";\r\nimport Proof from \"../../../components/Proof\";\r\n\r\nclass Entanglement extends Component {\r\n  componentDidMount() {\r\n    window.KaTeXRender();\r\n  }\r\n\r\n  render() {\r\n    return (\r\n      <div class=\"postContent leftMargin\">\r\n        <p>\r\n          <strong>Update (2021-08-21):</strong> I presented an abridged version\r\n          of this write-up as a student talk at the{\" \"}\r\n          <a className=\"linkPurple\" href=\"https://cumc2021.ca\">\r\n            2021 Canadian Undergraduate Mathematics Conference\r\n          </a>\r\n          . Below is a recording of this talk.\r\n        </p>\r\n        <p style={{ textAlign: \"center\" }}>\r\n          <iframe\r\n            src=\"https://www.youtube.com/embed/K2HlbbaDlyE\"\r\n            title=\"YouTube video player\"\r\n            frameborder=\"0\"\r\n            allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\r\n            allowfullscreen\r\n            style={{ height: \"50vh\", width: \"80%\" }}\r\n          ></iframe>\r\n        </p>\r\n        <p>\r\n          In middle school I wanted to be a physicist. The motivating factor was\r\n          quantum mechanics, or at least my pop science understanding of it.\r\n          Entangled particles! Quantum tunneling! Superpositions! Of course, I\r\n          didn't actually understand anything, being many years away from\r\n          learning the mathematical prerequisites, but it still marked a general\r\n          cardinal direction on my academic map. As the years went on, my\r\n          interests slowly veered from the physics to the mathematics,\r\n          abstracting all the way to mathematical logic and the various set\r\n          theories. I later grew to find these subjects too callous and\r\n          symbolic, returning to where I am now with more geometric interests.\r\n          My work this summer, however, brought me back in some sense to where\r\n          it all started: quantum physics. This time my perspective was purely\r\n          mathematical, with no care for the pop science which originally set me\r\n          on my journey. This mathematics is what I'm going to write about\r\n          today, specifically that of entanglement.\r\n        </p>\r\n        <p>\r\n          The concept of entanglement, morally, seeks to formalize the situation\r\n          in which the combination of parts may only be understood as just that\r\n          - a combination; one cannot infer, fully, what the component parts\r\n          are. The setting for our story is the <strong>tensor product</strong>.\r\n          Its construction begins with a desire for <strong>bilinearity</strong>{\" \"}\r\n          over vector spaces. Given two vectors spaces {\"\\\\(U,V\\\\)\"} over{\" \"}\r\n          {\"\\\\(F\\\\)\"}, we would like a third vector space, say {\"\\\\(W\\\\)\"}, for\r\n          which there exists a map {\"\\\\(T\\\\colon U\\\\times V\\\\to W\\\\)\"} such that\r\n          for any {\"\\\\(\\\\lambda\\\\in F,u_1,u_2\\\\in U,v_1,v_2\\\\in V\\\\)\"} we have\r\n          {\r\n            \"\\\\[T\\\\left(\\\\lambda u_1,v_1\\\\right)=\\\\lambda T(u_1,v_1)=T(u_1,\\\\lambda v_1)\\\\]\"\r\n          }\r\n          {\r\n            \"\\\\[T\\\\left(u_1+u_2,v_1+v_2\\\\right)=T(u_1,v_1+v_2)+T(u_2,v_1+v_2)=T(u_1,v_1)+T(u_1,v_2)+T(u_2,v_1)+T(u_2,v_2).\\\\]\"\r\n          }\r\n          That is, {\"\\\\(T\\\\)\"} is linear in both components. So, fix bases{\" \"}\r\n          {\"\\\\(\\\\{e_i\\\\},\\\\{f_i\\\\}\\\\)\"} of {\"\\\\(U,V\\\\)\"}, respectively, and\r\n          consider some scalars {\"\\\\(\\\\alpha_i,\\\\beta_i\\\\in F\\\\)\"}. What we then\r\n          need from our tensor product {\"\\\\(W\\\\)\"} is for\r\n          {\r\n            \"\\\\[T\\\\left(\\\\sum_i \\\\alpha_i e_i,\\\\sum_i\\\\beta_i f_i\\\\right)=\\\\sum_{i,j}\\\\alpha_i\\\\beta_j T(e_i,f_j).\\\\]\"\r\n          }\r\n          In order to accomplish this, we define the formal symbol{\" \"}\r\n          {\"\\\\(e_i\\\\otimes f_j\\\\eqqcolon T(e_i,f_j)\\\\)\"} (with {\"\\\\(T\\\\)\"}{\" \"}\r\n          extended to non-basis vectors bilinearly); this is our tensor, and the\r\n          vector space {\"\\\\(W\\\\eqqcolon U\\\\otimes V\\\\)\"} is composed of linear\r\n          combinations of these symbols. This construction is actually\r\n          universal, in the sense that given any other bilinear construction on{\" \"}\r\n          {\"\\\\(U\\\\times V\\\\)\"}, we can uniquely describe it in terms of this{\" \"}\r\n          {\"\\\\(U\\\\otimes V\\\\)\"}.\r\n        </p>\r\n        <p>\r\n          There may be apprehension to us defining {\"\\\\(U\\\\otimes V\\\\)\"} in\r\n          terms of some explicit bases. There is indeed an equivalent definition\r\n          of the tensor product as a quotient space with respect to a\r\n          bilinearity relation, however this basis-free construction is less\r\n          useful in our current context, hence it will not be shown. As an\r\n          aside, there is something I find quite comedic in defining tensors as\r\n          the symbols themselves, but I'm not quite sure what.\r\n        </p>\r\n        <p>\r\n          Something important to note is that given a vector{\" \"}\r\n          {\"\\\\(t\\\\in U\\\\otimes V\\\\)\"}, we cannot necessarily write{\" \"}\r\n          {\"\\\\(t=u\\\\otimes v\\\\)\"} for some {\"\\\\(u\\\\in U,v\\\\in V\\\\)\"}. Vectors\r\n          for which this is possible are called <strong>decomposable</strong>.\r\n          Two other facts for finite-dimensional {\"\\\\(U,V\\\\)\"} are that if{\" \"}\r\n          {\"\\\\(\\\\{e_i\\\\},\\\\{f_i\\\\}\\\\)\"} are orthonormal bases for {\"\\\\(U,V\\\\)\"},\r\n          then {\"\\\\(\\\\{e_i\\\\otimes f_j\\\\}\\\\)\"} will be an orthonormal basis for{\" \"}\r\n          {\"\\\\(U\\\\otimes V\\\\)\"}. Of course, orthonormality implies an inner\r\n          product, and indeed one exists, given by\r\n          {\r\n            \"\\\\[\\\\langle e_i\\\\otimes f_j,e_k\\\\otimes f_\\\\ell\\\\rangle_{U\\\\otimes V}= \\\\langle e_i,e_k\\\\rangle_U\\\\langle f_j,f_\\\\ell\\\\rangle_V\\\\]\"\r\n          }\r\n          extended to non-basis vectors.\r\n        </p>\r\n        <p>\r\n          We can also bring linear transforms over to the tensor product.\r\n          Specifically, given linear maps {\"\\\\(\\\\sigma\\\\colon U\\\\to U'\\\\)\"} and{\" \"}\r\n          {\"\\\\(\\\\tau\\\\colon V\\\\to V'\\\\)\"}, we may define the linear map{\" \"}\r\n          {\"\\\\(\\\\sigma\\\\otimes\\\\tau\\\\colon U\\\\otimes V\\\\to U'\\\\otimes V'\\\\)\"} by{\" \"}\r\n          {`\r\n          \\\\[\r\n            (\\\\sigma\\\\otimes\\\\tau)(u\\\\otimes v)=\\\\sigma u\\\\otimes\\\\tau v.\r\n          \\\\]\r\n          `}\r\n          There is a simple matrix representation of this new linear map, given\r\n          by the <strong>Kronecker product</strong> of matrices. Fixing two\r\n          bases {\"\\\\(\\\\{e_1,\\\\dots,e_n\\\\},\\\\{f_i\\\\}\\\\)\"} of {\"\\\\(U,V\\\\)\"} and\r\n          representing {\"\\\\(\\\\sigma,\\\\tau\\\\)\"} with respect to them, the block\r\n          matrix\r\n          {`\\\\[\r\n              \\\\sigma\\\\otimes\\\\tau=\\\\begin\\{pmatrix\\}\\\\sigma_\\{11\\}\\\\tau & \\\\cdots & \\\\sigma_\\{1n\\}\\\\tau\\\\\\\\\r\n              \\\\vdots & \\\\ddots &\\\\vdots \\\\\\\\\r\n              \\\\sigma_\\{n1\\}\\\\tau & \\\\cdots & \\\\sigma_\\{nn\\}\\\\tau\r\n              \\\\end\\{pmatrix\\}\r\n          \\\\]`}\r\n          gives the matrix of {\"\\\\(\\\\sigma\\\\otimes\\\\tau\\\\)\"} with respect to the{\" \"}\r\n          <strong>lexicographically-ordered</strong> basis\r\n          {`\\\\[\r\n          (e_i\\\\otimes f_j : e_i \\\\otimes f_j \\\\leq e_k\\\\otimes f_\\\\ell \\\\textrm\\{ if \\} i < k \\\\textrm\\{ or \\} i=k, j<\\\\ell ).\r\n          \\\\]`}\r\n        </p>\r\n        <p>\r\n          With the setting understood, we move on to our story's characters.\r\n          Recall a vector space {\"\\\\(V\\\\)\"} equipped with an inner product{\" \"}\r\n          {\"\\\\(\\\\langle\\\\cdot,\\\\cdot\\\\rangle\\\\)\"} induces a norm{\" \"}\r\n          {\"\\\\(\\\\|\\\\cdot\\\\|\\\\)\"} by{\" \"}\r\n          {\"\\\\(\\\\|v\\\\|=\\\\sqrt{\\\\langle v,v\\\\rangle}\\\\)\"}. If the associated\r\n          metric space is complete and {\"\\\\(F=\\\\mathbb{R}\\\\)\"} or{\" \"}\r\n          {\"\\\\(F=\\\\mathbb{C}\\\\)\"} (if the choice does not matter, we will write{\" \"}\r\n          {\"\\\\(\\\\mathbb{F}\\\\)\"}), then {\"\\\\(V\\\\)\"} is a{\" \"}\r\n          <strong>Hilbert space</strong>. This definition comes from functional\r\n          analysis, however, and so is slightly overkill for us, as we will only\r\n          look at finite-dimensional spaces (where we always have completion).\r\n          The canonical Hilbert space is {\"\\\\(\\\\mathbb{C}^n\\\\)\"} equipped with\r\n          the standard inner product.\r\n        </p>\r\n        <p>\r\n          Our parts will be operators over Hilbert spaces, and our combinations\r\n          will be their tensor products. We will first go over what kind of\r\n          operators we are considering. Consider a Hilbert space{\" \"}\r\n          {\"\\\\(\\\\mathcal{H}\\\\)\"} lying over the field {\"\\\\(\\\\mathbb{F}\\\\)\"}. The{\" \"}\r\n          <strong>dual space</strong> {\"\\\\(\\\\mathcal{H}^\\\\ast\\\\)\"} is the set of{\" \"}\r\n          <strong>linear functionals</strong>, linear maps{\" \"}\r\n          {\"\\\\(\\\\mathcal{H}\\\\to\\\\mathbb{F}\\\\)\"}.\r\n        </p>\r\n        <Theorem\r\n          no=\"1\"\r\n          name=\"Riesz–Fréchet\"\r\n          statement=\"\r\n               Consider some \\(\\varphi\\in\\mathcal{H}^\\ast\\). Then, there exists a unique \\(f_{\\varphi}\\in\\mathcal{H}\\) such that \\(\\varphi(x)=\\langle x,f_{\\varphi}\\rangle\\) for every \\(x\\in\\mathcal{H}\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Let \\(\\{e_1,\\dots,e_n\\}\\) be an orthonormal basis of \\(\\mathcal{H}\\). Then, using properties of orthonormality and linear functionals, for arbitrary \\(x\\) we have\r\n                \\[\r\n                  \\varphi(x)=\\varphi\\left(\\sum_{i=1}^n \\langle x,e_i\\rangle e_i\\right)=\\sum_{i=1}^n\\langle x,e_i\\rangle\\varphi(e_i)=\\sum_{i=1}^n \\langle x,\\overline{\\varphi(e_i)}e_i\\rangle=\\left\\langle x,\\sum_{i=1}^n\\overline{\\varphi(e_i)}e_i\\right\\rangle. \r\n              \\]\r\n              Let us take the latter component as a candidate for \\(f_{\\varphi}\\) (indeed, observe it is independent of \\(x\\)). For uniqueness, suppose there is some other satisfactory \\(g_{\\varphi}\\) such that\r\n              \\[\r\n                \\langle x,f_{\\varphi}\\rangle=\\varphi(x)=\\langle x,g_{\\varphi}\\rangle.\r\n                \\]\r\n                Then,\r\n                \\[\r\n                  \\langle x,f_{\\varphi}\\rangle-\\langle x,g_{\\varphi}\\rangle =\\langle x,f_{\\varphi}-g_{\\varphi}\\rangle=0\r\n                  \\]\r\n                  and it remains only to consider \\(x=0\\) to see \\(f_{\\varphi}=g_{\\varphi}\\).\"\r\n        />\r\n        <p>\r\n          There is a subtly in the above theorem and its proof, namely in\r\n          regards to the assumption that {\"\\\\(\\\\mathcal{H}\\\\)\"} is\r\n          finite-dimensional. The theorem is (partially) true in\r\n          infinite-dimensional Hilbert spaces (the requirement{\" \"}\r\n          {\"\\\\(\\\\varphi\\\\)\"} be continuous must be appended), however the proof\r\n          technique must change as there are no orthonormal bases in such\r\n          spaces. A further remark, for those familiar with Dirac notation, is\r\n          that the above theorem legitmizes the identification of a unique bra{\" \"}\r\n          {\"\\\\(\\\\langle \\\\psi |\\\\)\"} for each ket {\"\\\\(|\\\\psi\\\\rangle\\\\)\"}.\r\n        </p>\r\n        <p>\r\n          This theorem lets us define the <strong>adjoint</strong>. Fix a linear\r\n          operator {\"\\\\(T\\\\)\"} on {\"\\\\(\\\\mathcal{H}\\\\)\"} and some vector{\" \"}\r\n          {\"\\\\(y\\\\in\\\\mathcal{H}\\\\)\"}. The map{\" \"}\r\n          {\"\\\\(x\\\\mapsto\\\\langle T x,y\\\\rangle\\\\)\"} defines a linear functional,\r\n          and hence we obtain a unique {\"\\\\(T_y\\\\in\\\\mathcal{H}\\\\)\"} such that{\" \"}\r\n          {\"\\\\(x\\\\mapsto \\\\langle x, T_y\\\\rangle\\\\)\"}. We use this process to\r\n          define the linear map {\"\\\\(T^\\\\ast\\\\)\"} by{\" \"}\r\n          {\"\\\\(T^\\\\ast y\\\\coloneqq T_y\\\\)\"}. Equivalently, {\"\\\\(T^\\\\ast\\\\)\"} is\r\n          the unique linear operator such that{\" \"}\r\n          {\"\\\\(\\\\langle Tx,y\\\\rangle=\\\\langle x,T^\\\\ast y\\\\rangle\\\\)\"} for all{\" \"}\r\n          {\"\\\\(x,y\\\\in\\\\mathcal{H}\\\\)\"}. When {\"\\\\(T\\\\)\"} is a matrix,{\" \"}\r\n          {\"\\\\(T^\\\\ast\\\\)\"} is given by conjugate transposition. If{\" \"}\r\n          {\"\\\\(T=T^\\\\ast\\\\)\"}, we say {\"\\\\(T\\\\)\"} is{\" \"}\r\n          <strong>self-adjoint</strong> (or <strong>Hermitian</strong>).\r\n        </p>\r\n        <p>\r\n          We need one more definition: a linear operator is called{\" \"}\r\n          <strong>positive</strong> if its <strong>spectrum</strong> (in finite\r\n          dimensions, precisely its set of eigenvalues) is entirely\r\n          non-negative. When working with matrices,{\" \"}\r\n          <strong>positive-semidefinite</strong> is often seen instead. At last,\r\n          we arrive at <strong>density operators</strong> over a Hilbert space\r\n          (correspondingly, <strong>density matrices</strong>, and also{\" \"}\r\n          <strong>states</strong>), the set of self-adjoint positive operators\r\n          with unit trace.\r\n        </p>\r\n        <p>\r\n          As we will be working over finite-dimensional complex vector spaces\r\n          (and note{\" \"}\r\n          {\"\\\\(\\\\mathbb{C}^m\\\\otimes\\\\mathbb{C}^n\\\\cong\\\\mathbb{C}^{mn}\\\\)\"}),\r\n          we will make constant (implicit) appeals to the following spectral\r\n          theorem. The proof is not hard, but it involves introducing another\r\n          theorem (that of Schur), which is slightly out-of-scope. The statement\r\n          may actually be strengthened from just self-adjoint operators to\r\n          normal operators, however this is similarly digressive.\r\n        </p>\r\n        <Theorem\r\n          no=\"2\"\r\n          statement=\"\r\n               Every self-adjoint linear operator over a finite-dimensional complex inner product space has a diagonal matrix of its eigenvalues with respect to its orthonormal set of eigenvectors.\"\r\n        />\r\n        <p>\r\n          This means given any state, say {\"\\\\(\\\\rho\\\\)\"}, we may take its\r\n          eigenvectors {\"\\\\(\\\\{v_i\\\\}\\\\)\"} and eigenvalues{\" \"}\r\n          {\"\\\\(\\\\{\\\\lambda_i\\\\}\\\\)\"}, and write its{\" \"}\r\n          <strong>eigendecomposition</strong>\r\n          {`\\\\[\r\n          \\\\rho=\\\\sum_i \\\\lambda_i P_\\{v_i\\}\r\n        \\\\]`}\r\n          where {\"\\\\(P_{v}\\\\)\"} is the orthogonal projection onto the\r\n          one-dimensional subspace spanned by {\"\\\\(v\\\\)\"}. Due to the definition\r\n          of state, each {\"\\\\(\\\\lambda_i\\\\geq 0\\\\)\"} and{\" \"}\r\n          {\"\\\\(\\\\sum_i \\\\lambda_i=1\\\\)\"}. In general, given any set of\r\n          coefficients {\"\\\\(p_i\\\\geq 0\\\\)\"} for {\"\\\\(i=1,\\\\dots,k\\\\)\"} such that{\" \"}\r\n          {\"\\\\(\\\\sum_{i=1}^k p_i=1\\\\)\"}, and a set of unit vectors{\" \"}\r\n          {\"\\\\(\\\\{u_1,\\\\dots, u_k\\\\}\\\\)\"}, we call\r\n          {`\\\\[\r\n          \\\\sum_{i=1}^k p_i P_\\{u_i\\}\r\n        \\\\]`}\r\n          an <strong>ensemble</strong>. These representation of a state as an\r\n          ensemble is generally not unique (not even in length!), due to the\r\n          following.\r\n        </p>\r\n        <Theorem\r\n          no=\"3\"\r\n          name=\"Schrödinger\"\r\n          statement=\"\r\n               Consider a state \\(\\rho\\) represented by the ensemble \\(\\sum_{i=1}^k p_iP_{u_i}\\). Then, we may also write \\(\\rho\\) as the ensemble \\(\\sum_{j=1}^\\ell q_iP_{v_i}\\) if and only if there exists some unitary \\(\\ell\\)-by-\\(\\ell\\) matrix \\(U\\) such that \\[\r\n                 v_i=\\frac{1}{\\sqrt{q_i}}\\sum_{j=1}^k U_{ij}\\sqrt{p_j}u_j.\r\n                \\]\"\r\n        />\r\n        <p>\r\n          As a reminder, a matrix {\"\\\\(U\\\\)\"} is <strong>unitary</strong> if{\" \"}\r\n          {\"\\\\(U^\\\\ast=U^{-1}\\\\)\"}. One situation where the ensemble\r\n          representation is unique is if {\"\\\\(\\\\rho\\\\)\"} itself is a projector\r\n          (that is, {\"\\\\(\\\\rho=P_v\\\\)\"} for some unit vector {\"\\\\(v\\\\)\"}). This\r\n          follows immediately from the defining properties of states. Such{\" \"}\r\n          {\"\\\\(\\\\rho\\\\)\"} are called <strong>pure</strong>. States which are not\r\n          pure are <strong>mixed</strong>.\r\n        </p>\r\n        <p>\r\n          We will now travel toward the tensor product, wherein resides\r\n          entanglement. For the remainder of this post, unless otherwise stated,{\" \"}\r\n          {\"\\\\(\\\\mathcal{H}=\\\\mathcal{H}_m\\\\otimes\\\\mathcal{H}_n\\\\)\"} where{\" \"}\r\n          {\"\\\\(\\\\mathcal{H}_m\\\\)\"} is a Hilbert space of dimension {\"\\\\(m\\\\)\"}.\r\n          As {\"\\\\(\\\\mathcal{H}\\\\)\"} itself is a Hilbert space, the notion of\r\n          pure and mixed states remains identical. However, we may now have the\r\n          ability to describe states in {\"\\\\(\\\\mathcal{H}\\\\)\"} in terms of\r\n          states in {\"\\\\(\\\\mathcal{H}_m\\\\)\"} and {\"\\\\(\\\\mathcal{H}_n\\\\)\"}. Given\r\n          some {\"\\\\(\\\\rho\\\\)\"} over {\"\\\\(\\\\mathcal{H}\\\\)\"}, if we can write\r\n          {`\\\\[\r\n            \\\\rho=\\\\sum_i p_i\\\\sigma_i\\\\otimes\\\\tau_i\r\n            \\\\]`}\r\n          where {\"\\\\(p_i\\\\geq 0\\\\)\"} and {\"\\\\(\\\\sum_i p_i=1\\\\)\"}, and the{\" \"}\r\n          {\"\\\\(\\\\sigma_i,\\\\tau_i\\\\)\"} are themselves pure states in the\r\n          component Hilbert spaces, we call {\"\\\\(\\\\rho\\\\)\"}{\" \"}\r\n          <strong>separable</strong> (or <strong>disentangled</strong>). If a\r\n          state is not separable, it is <strong>entangled</strong>. Note that\r\n          the case where the {\"\\\\(\\\\sigma_i,\\\\tau_i\\\\)\"} are instead mixed\r\n          actually describes the same set (the proof for this hinges on\r\n          Carathéodory's result for convex hulls and the compactness of pure\r\n          states in the component Hilbert spaces), so purity is assumed without\r\n          loss of generality.\r\n        </p>\r\n        <p>\r\n          Now, how do we determine if a state is entangled or separable?\r\n          Moreover, are there different levels of entanglement? Unfortunately,\r\n          there is no nice answer to either of these questions. Given an\r\n          arbitrary state, there is no straightforward process to determine its\r\n          separability (of course, some special cases exist, e.g. the\r\n          Peres–Horodecki critereon for{\" \"}\r\n          {\"\\\\(\\\\mathcal{H}_m\\\\otimes\\\\mathcal{H}_n\\\\)\"} when{\" \"}\r\n          {\"\\\\(mn\\\\leq 6\\\\)\"}\r\n          ). There are also multiple mutually-inconsistent ways to measure\r\n          levels of entanglement; two such measures will be our focus today.\r\n        </p>\r\n        <p>\r\n          Before we discuss them, let us precisely define what we mean by\r\n          measure. Such a map on states over {\"\\\\(\\\\mathcal{H}\\\\)\"}, call it{\" \"}\r\n          {\"\\\\(E\\\\)\"}, must satisfy three properties. Firstly, that{\" \"}\r\n          {\"\\\\(E(\\\\rho)=0\\\\)\"} if and only if {\"\\\\(\\\\rho\\\\)\"} is separable.\r\n          Secondly, {\"\\\\(E\\\\)\"} must be invariant under{\" \"}\r\n          <strong>locally unitary operations</strong>, meaning that if given\r\n          unitary {\"\\\\(U\\\\in\\\\mathcal{H}_m\\\\)\"} and{\" \"}\r\n          {\"\\\\(V\\\\in\\\\mathcal{H}_n\\\\)\"}, then{\" \"}\r\n          {\"\\\\[E(\\\\rho)=E((U\\\\otimes V)\\\\rho(U^\\\\ast\\\\otimes V^\\\\ast)).\\\\]\"} We\r\n          also require <strong>convexity</strong>, meaning for any{\" \"}\r\n          {\"\\\\(\\\\alpha\\\\in [0,1]\\\\)\"} we have\r\n          {\r\n            \"\\\\[E(\\\\alpha\\\\rho +(1-\\\\alpha)\\\\sigma)\\\\leq \\\\alpha E(\\\\rho)+(1-\\\\alpha)E(\\\\sigma).\\\\]\"\r\n          }\r\n          The reason for the first property is obvious. The latter two are\r\n          related to the physical motivation behind the postulates of quantum\r\n          mechanics, as well as state geometry. It should also be noted that\r\n          this list is a bare minimum. There are several other desirable\r\n          properties (e.g. continuity), however the difficulty in constructing\r\n          such maps, known as <strong>entanglement measures</strong>, means we\r\n          cannot be too picky and demand everything at once. In fact, it is\r\n          usually extremely hard to determine whether an entanglement measure\r\n          has these extra properties, given how tricky they are to work with (as\r\n          we will soon see).\r\n        </p>\r\n        <p>\r\n          The construction of our first entanglement measure begins on pure\r\n          states. We start with a definition. Given two linear operators{\" \"}\r\n          {\"\\\\(S,T\\\\)\"} over {\"\\\\(\\\\mathcal{H}_m,\\\\mathcal{H}_n\\\\)\"}, the{\" \"}\r\n          <strong>partial trace</strong> of {\"\\\\(S\\\\otimes T\\\\)\"} is{\" \"}\r\n          {\"\\\\[\\\\operatorname{tr}_2(S\\\\otimes T)=\\\\operatorname{tr}(T)S,\\\\]\"}\r\n          extended linearly. Then, the <strong>entanglement entropy</strong> of\r\n          a unit vector {\"\\\\(v\\\\in\\\\mathcal{H}\\\\)\"} is\r\n          {\r\n            \"\\\\[E(v)=-\\\\sum_{\\\\lambda_i \\\\in\\\\,\\\\operatorname{spec}\\\\operatorname{tr}_2 P_v}\\\\lambda_i\\\\ln\\\\lambda_i\\\\]\"\r\n          }\r\n          with the convention {\"\\\\(0\\\\cdot\\\\ln 0=0\\\\)\"}. There exists a nicer,\r\n          more explicit formula, which also shows it does not matter which\r\n          partial trace we use in the definition (i.e.{\" \"}\r\n          {\"\\\\(\\\\operatorname{tr}_1\\\\)\"} versus {\"\\\\(\\\\operatorname{tr}_2\\\\)\"}).\r\n        </p>\r\n        <Theorem\r\n          no=\"4\"\r\n          name=\"Schmidt\"\r\n          statement=\"\r\n               Let \\(v\\in\\mathcal{H}_m\\otimes\\mathcal{H}_n\\). Then, there exist orthonormal bases \\(\\{e_i\\},\\{f_i\\}\\) for \\(\\mathcal{H}_m,\\mathcal{H}_n\\), respectively, such that \\[v=\\sum_{i=1}^{\\min\\{m,n\\}} \\alpha_i e_i\\otimes f_i\\]\r\n               and the \\(\\alpha_i\\) are uniquely-given, real, and non-negative.\"\r\n        />\r\n        <p>\r\n          The proof of the Schmidt decomposition is essentially the same as that\r\n          of the singular value decomposition. The above {\"\\\\(\\\\alpha_i\\\\)\"} are\r\n          called the <strong>Schmidt coefficients</strong> of {\"\\\\(v\\\\)\"}.\r\n        </p>\r\n        <Theorem\r\n          no=\"5\"\r\n          statement=\"\r\n               The entanglement entropy of a unit vector \\(v\\in\\mathcal{H}\\) is \\[E(v)=-\\sum_i \\alpha_i^2\\ln\\alpha_i^2\\] where the \\(\\alpha_i\\) are the Schmidt coefficients of \\(v\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Recall that the projector \\(P_v\\) is given by \\(vv^\\ast\\), where \\(v^\\ast\\) is the conjugate transpose of the column vector of \\(v\\), or defined by the linear functional \\(u\\mapsto \\langle u,v\\rangle\\). Written with respect to the Schmidt decomposition, we have\r\n                \\[\r\n                  vv^\\ast=\\left(\\sum_i \\alpha_i e_i\\otimes f_i\\right)\\left(\\sum_i \\alpha_i e_i\\otimes f_i\\right)^\\ast=\\sum_{i,j} \\alpha_i\\overline{\\alpha_j} (e_i\\otimes f_i)(e_j\\otimes f_j)^\\ast.\r\n                \\]\r\n                Distributing the conjugate transposition and multiplying through using properties of the Kronecker product, we obtain\r\n                \\[\r\n                  vv^\\ast=\\sum_{i,j} \\alpha_i\\overline{\\alpha_j}(e_ie_j^\\ast\\otimes f_if_j^\\ast)=\\sum_i \\alpha_i^2 (e_ie_i^\\ast\\otimes f_if_i^\\ast)\r\n                  \\]\r\n                  with the last equality following from the orthonormality of our bases. Taking the partial trace,\r\n                  \\[\\begin{aligned}\r\n                  \\operatorname{tr}_2(vv^\\ast) &= \\operatorname{tr}_2\\left(\\sum_i \\alpha_i^2 (e_ie_i^\\ast\\otimes f_if_i^\\ast)\\right) \\\\\r\n                  &= \\sum_i \\alpha_i^2 \\operatorname{tr}_2{(e_ie_i^\\ast\\otimes f_if_i^\\ast)} \\\\\r\n                  &= \\sum_i \\alpha_i^2 \\operatorname{tr}(f_if_i^\\ast)e_ie_i^\\ast.\r\n                  \\end{aligned}\\]\r\n                  However, \\(f_if_i^\\ast=P_{f_i}\\), and so \\(\\operatorname{tr}(f_if_i^\\ast)=1\\) for each \\(i\\). The \\(e_ie_i^\\ast=P_{e_i}\\) are also projectors, and moreover they are all orthogonal to each other, hence we see \\(\r\n                    \\operatorname{spec}\\operatorname{tr}_2P_v=\\{\\alpha_i^2\\}\r\n                    \\), as desired.\"\r\n        />\r\n        <p>\r\n          To see entropy in action, denote by {\"\\\\(\\\\{e_1,e_2\\\\}\\\\)\"} the\r\n          standard basis for {\"\\\\(\\\\mathbb{C}^2\\\\)\"}, and examine the unit\r\n          vector {\"\\\\(e_1\\\\otimes e_1\\\\in\\\\mathbb{C}^2\\\\otimes\\\\mathbb{C}^2\\\\)\"}\r\n          . We can project onto it by{\" \"}\r\n          {`\\\\[P_{e_1\\\\otimes e_1}=(e_1\\\\otimes e_1)(e_1\\\\otimes e_1)^\\\\ast= e_1e_1^\\\\ast\\\\otimes e_1e_1^\\\\ast=P_{e_1}\\\\otimes P_{e_1}.\\\\]`}\r\n          This is clearly separable, and the partial trace is just{\" \"}\r\n          {\"\\\\(\\\\operatorname{tr}_2 P_{e_1\\\\otimes e_1}=P_{e_1}\\\\)\"}, giving{\" \"}\r\n          {\"\\\\(E(e_1\\\\otimes e_1)=0\\\\)\"} as expected. All pure separable states\r\n          will have zero entropy for this reason. For an entangled state,\r\n          consider\r\n          {`\\\\[v=\\\\frac{1}{\\\\sqrt{2}}(e_1\\\\otimes e_1+e_2\\\\otimes e_2)\\\\in\\\\mathbb{C}^2\\\\otimes\\\\mathbb{C}^2.\\\\]`}\r\n          Then, with respect to the standard (lexicographic) basis of the tensor\r\n          product,\r\n          {`\\\\[\r\n            P_v=\\\\begin{pmatrix}\r\n            \\\\frac{1}{2} & 0 & 0 & \\\\frac{1}{2} \\\\\\\\\r\n            0 & 0 & 0 & 0 \\\\\\\\\r\n            0 & 0 & 0 & 0 \\\\\\\\\r\n            \\\\frac{1}{2} & 0 & 0 & \\\\frac{1}{2}\r\n           \\\\end{pmatrix}.\r\n            \\\\]`}\r\n          Computing partial trace is simple given an actual matrix (we just\r\n          trace over the blocks), obtaining\r\n          {`\\\\[\\\\operatorname{tr}_2 P_v=\\\\begin{pmatrix}\r\n            \\\\operatorname{tr}\\\\begin{pmatrix}\\\\frac{1}{2} & 0 \\\\\\\\ 0 & 0\\\\end{pmatrix} &  \\\\operatorname{tr}\\\\begin{pmatrix}0 & \\\\frac{1}{2} \\\\\\\\ 0 & 0\\\\end{pmatrix} \\\\\\\\\r\n            \\\\operatorname{tr}\\\\begin{pmatrix}0 & 0 \\\\\\\\ \\\\frac{1}{2} & 0\\\\end{pmatrix} &  \\\\operatorname{tr}\\\\begin{pmatrix}0 & 0 \\\\\\\\ 0 & \\\\frac{1}{2}\\\\end{pmatrix}\r\n           \\\\end{pmatrix}=\\\\begin{pmatrix}\\\\frac{1}{2} & 0 \\\\\\\\ 0 & \\\\frac{1}{2}\\\\end{pmatrix}.\\\\]`}\r\n          Therefore,\r\n          {`\\\\[E(v)=-\\\\left(\\\\frac{1}{2}\\\\ln\\\\frac{1}{2}+\\\\frac{1}{2}\\\\ln\\\\frac{1}{2}\\\\right)=\\\\ln 2\\\\]`}\r\n          and so the state given by {\"\\\\(v\\\\)\"} is entangled (in fact, this is\r\n          the most entangled a state can be in{\" \"}\r\n          {\"\\\\(\\\\mathbb{C}^2\\\\otimes\\\\mathbb{C}^2\\\\)\"}).\r\n        </p>\r\n        <p>\r\n          The question now is how to extend {\"\\\\(E\\\\)\"} from pure states (though\r\n          we technically defined it for vectors, these are just projectors up to\r\n          a rotational identification) to mixed states. The natural approach is\r\n          to weigh the entropy with respect to the coefficients of an ensemble,\r\n          defining\r\n          {`\\\\[E(\\\\rho)=\\\\sum_i p_i E(v_i).\\\\]`}\r\n          However, recall that, due to Schrödinger, ensemble representations are\r\n          generally not unique. This would be fine if the above were invariant\r\n          under choice, but unfortunately this is not the case. One solution is\r\n          to iterate over the entire ensemble space, writing say\r\n          {`\\\\[E_F(\\\\rho)=\\\\inf_{\\\\mathrm{ensembles}}\\\\sum_i p_iE(v_i),\\\\]`}\r\n          which defines <strong>entanglement of formation</strong>. This process\r\n          may actually be done for any of notion of entanglement initially\r\n          defined on pure states, and is called a{\" \"}\r\n          <strong>convex roof construction</strong>.\r\n        </p>\r\n        <p>\r\n          Though the definition is intuitive and easy to write down, the value\r\n          is devilishly hard to compute. Indeed, closed-form expressions are\r\n          only known for special cases (e.g. over{\" \"}\r\n          {\"\\\\(\\\\mathbb{C}^2\\\\otimes\\\\mathbb{C}^2\\\\)\"}, see{\" \"}\r\n          <a\r\n            className=\"linkPurple\"\r\n            href=\"https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.80.2245\"\r\n          >\r\n            here\r\n          </a>\r\n          ). The question of whether this infimum is ever even attained (that\r\n          is, whether some ensemble realizes {\"\\\\(E_F\\\\)\"}) is also non-trivial\r\n          (though it is known to be true in many cases, see{\" \"}\r\n          <a\r\n            className=\"linkPurple\"\r\n            href=\"https://www.mdpi.com/1099-4300/12/7/1799\"\r\n          >\r\n            here\r\n          </a>\r\n          ). The reason {\"\\\\(E_F(\\\\rho)=0\\\\)\"} when {\"\\\\(\\\\rho\\\\)\"} is\r\n          separable, however, is that the ensemble showing it is separable will\r\n          satisfy {\"\\\\(E(v_i)=0\\\\)\"} for each {\"\\\\(i\\\\)\"}, as seen earlier, and\r\n          so the infimum will be attained there.\r\n        </p>\r\n        <p>\r\n          Another approach is to construct some notion of distance between\r\n          states, and see how far away a state is from the set of separable\r\n          ones. For this, we introduce <strong>von Neumann entropy</strong>,\r\n          {`\\\\[S(\\\\rho)=-\\\\operatorname{tr}\\\\rho\\\\ln\\\\rho.\\\\]`} The notation\r\n          warrants a brief discussion. The actual matrix logarithm{\" \"}\r\n          {\"\\\\(\\\\ln\\\\rho\\\\)\"} will not always exist (as density matrices may be\r\n          singular), so some care must be taken. It may be easier to understand\r\n          this as notational shorthand applied to the eigendecomposition, where\r\n          {`\\\\[\\\\rho\\\\ln\\\\rho=\\\\sum_i (\\\\lambda_i\\\\ln\\\\lambda_i) P_{v_i}\\\\]`}{\" \"}\r\n          with {\"\\\\(0\\\\cdot\\\\ln 0=0\\\\)\"} as before. When the matrix{\" \"}\r\n          {\"\\\\(\\\\ln\\\\rho\\\\)\"} exists, the two definitions coincide. This\r\n          quantity is closely related to entanglement entropy (indeed,\r\n          entanglement entropy is sometimes called the reduced von Neumann\r\n          entropy, as {\"\\\\(E(v)=S(\\\\operatorname{tr}_2 P_v)\\\\)\"}).\r\n        </p>\r\n        <p>\r\n          With this, we may now define the <strong>relative entropy</strong> of{\" \"}\r\n          {\"\\\\(\\\\rho\\\\)\"} with respect to {\"\\\\(\\\\sigma\\\\)\"} by{\" \"}\r\n          {`\\\\[S(\\\\rho\\\\|\\\\sigma)=\\\\operatorname{tr}(\\\\rho(\\\\ln\\\\rho-\\\\ln\\\\sigma)).\\\\]`}\r\n          This gives us the notion of entropic distance we desired (but note it\r\n          is just a notion, not a literal metric). So, we go on to define the\r\n          measure\r\n          {`\\\\[E_R(\\\\rho)=\\\\inf_{\\\\textrm{separable}} S(\\\\rho\\\\|\\\\sigma)\\\\]`}\r\n          called <strong>relative entanglement</strong> (the infimum is\r\n          iterating over each separable state {\"\\\\(\\\\sigma\\\\)\"}). If{\" \"}\r\n          {\"\\\\(\\\\rho\\\\)\"} is not entangled, this quantity will vanish once the\r\n          entropy is taken relative to itself.\r\n        </p>\r\n        <p>\r\n          Unfortunately, just like for entanglement of formation, actually\r\n          computing relative entanglement is quite hard. It is interesting to\r\n          note though that both {\"\\\\(E_F\\\\)\"} and {\"\\\\(E_R\\\\)\"} reduce to the\r\n          entanglement entropy {\"\\\\(E\\\\)\"} over pure states (this is trivial for\r\n          the former, but the argument for the latter is involved, see{\" \"}\r\n          <a\r\n            className=\"linkPurple\"\r\n            href=\"https://journals.aps.org/pra/abstract/10.1103/PhysRevA.57.1619\"\r\n          >\r\n            here\r\n          </a>\r\n          ).\r\n        </p>\r\n        <p>\r\n          This subject, best described as quantum information theory, is\r\n          situated at an interesting place for me. I remember in high school\r\n          posting a question on Stack Exchange, asking what the quotient of a\r\n          vector space even means and why it would ever come up. A couple of\r\n          years later, and I see them show up here (as one of the ways) to\r\n          define tensor products, which are then used to discuss what happens\r\n          during very expensive laboratory experiments. Though I can't say I\r\n          feel particularly motivated to learn about the actual physics and\r\n          real-world interpretations behind all of this, I nonetheless find it\r\n          really fascinating (or maybe comforting?) to know that some of the\r\n          seemingly abstract theory I've been working with this summer has\r\n          interpretations this tangible and uses this practical. But maybe this\r\n          is just me reorienting my compass again, this time embarking to become\r\n          an applied mathematician. Who knows?\r\n        </p>\r\n      </div>\r\n    );\r\n  }\r\n}\r\n\r\nexport default Entanglement;\r\n","import React, { Component } from \"react\";\r\n/* environments */\r\nimport Figure from \"../../../components/Figure\";\r\nimport Theorem from \"../../../components/Theorem\";\r\nimport Proof from \"../../../components/Proof\";\r\n\r\nclass SOME1 extends Component {\r\n  componentDidMount() {\r\n    window.KaTeXRender();\r\n  }\r\n\r\n  render() {\r\n    return (\r\n      <div class=\"postContent leftMargin\">\r\n        <p style={{ textAlign: \"center\" }}>\r\n          <iframe\r\n            src=\"https://www.youtube.com/embed/4zD8Kd3HgJA\"\r\n            title=\"YouTube video player\"\r\n            frameborder=\"0\"\r\n            allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\r\n            allowfullscreen\r\n            style={{ height: \"50vh\", width: \"80%\" }}\r\n          ></iframe>\r\n        </p>\r\n      </div>\r\n    );\r\n  }\r\n}\r\n\r\nexport default SOME1;\r\n","export default __webpack_public_path__ + \"static/media/fig1(koch).b55a4c6d.png\";","export default __webpack_public_path__ + \"static/media/fig2(transv).eaa3dc15.png\";","export default __webpack_public_path__ + \"static/media/fig3(wind).3c138aea.png\";","export default __webpack_public_path__ + \"static/media/fig4(gp).52edce34.jpg\";","import React, { Component } from \"react\";\r\n/* environments */\r\nimport Figure from \"../../../components/Figure\";\r\nimport Theorem from \"../../../components/Theorem\";\r\nimport Proof from \"../../../components/Proof\";\r\n/* figures */\r\nimport Fig1Koch from \"./fig1(koch).png\";\r\nimport Fig2Transv from \"./fig2(transv).png\";\r\nimport Fig3Wind from \"./fig3(wind).png\";\r\nimport Fig4GP from \"./fig4(gp).jpg\";\r\n\r\nclass JordanBrouwer extends Component {\r\n    \r\n  componentDidMount() {\r\n    window.KaTeXRender();\r\n  }\r\n\r\n  render() {\r\n    return (\r\n      <div class=\"postContent leftMargin\">\r\n        <p>\r\n          If I were to draw a circle or some polygon, like a square, on a piece\r\n          of paper, and ask you to identify the inside and outside, you would\r\n          likely look at me as if I had gone mad. It is incredibly easy to both\r\n          define what the inside is and identify where it lies, as these curves\r\n          can be described by a product of intervals, or some simple\r\n          parametrization. But what of, say, the Koch snowflake, as in figure 1?\r\n          The precise curve is actually the limit case of the figure - a\r\n          fractal. The curve is still continuous, being without holes, and does\r\n          not overlap (except at the beginning and end). However, its perimetre\r\n          is infinite, and its parametrization is nowhere differentiable. How\r\n          would you formally describe what lies inside it? In fact, for a curve\r\n          like this it is not unreasonable to suspect that may not be\r\n          well-defined in the first place; perhaps some point behaves weirdly in\r\n          the limit case and cannot be simply classified.\r\n        </p>\r\n        <Figure no=\"1\" src={Fig1Koch} caption=\"Koch snowflake\" />\r\n        <p>\r\n          Thankfully someone, specifically Jordan, proved we don't need to worry\r\n          about such a thing. His result on these curves gave them a special\r\n          name, <strong>Jordan curves</strong>. These are simple closed curves\r\n          on the plane, meaning they are continuous curves in{\" \"}\r\n          {\"\\\\(\\\\mathbb{R}^2\\\\)\"} with no self-intersections, except at the\r\n          start and end. His precise result was as follows.\r\n        </p>\r\n        <Theorem\r\n          name=\"Jordan\"\r\n          statement=\"\r\n                Every Jordan curve divides the plane into two components, an unbounded exterior and a bounded interior, such that the curve is the boundary of each component.\"\r\n        />\r\n        <p>\r\n          What is interesting is that such a seemingly \"obvious\" result,\r\n          something that every school child understands implicitly when they are\r\n          told to \"colour inside the lines\", has an entirely non-obvious proof.\r\n          Indeed, even today there are no easy proofs of it. They all span\r\n          multiple pages, and use machinery which, at least on the surface,\r\n          appears to be overkill for such a simple sounding statement.\r\n        </p>\r\n        <p>\r\n          This can actually be considered as a special case of a stronger result\r\n          proved by Brouwer a few decades after Jordan's initial publication.\r\n          However, to get there we will need a few definitions. I have already\r\n          discussed manifolds in the past, however there is an object which\r\n          slightly generalizes them. We call these{\" \"}\r\n          <strong>manifolds with boundary</strong>. While a \\(k\\)-manifold is\r\n          diffeomorphic to {\"\\\\(\\\\mathbb{R}^k\\\\)\"}, we require only that\r\n          manifolds with boundary are diffeomorphic to the{\" \"}\r\n          <strong>upper-half plane </strong>\r\n          {\r\n            \"\\\\[\\\\mathcal{H}^k:=\\\\{(x_1,\\\\dots x_k)\\\\in\\\\mathbb{R}^k : x_k\\\\geq 0\\\\}.\\\\]\"\r\n          }\r\n        </p>\r\n        <p>\r\n          Visually, the obvious notion of a boundary on the upper-half plane\r\n          occurs precisely where \\(x_k=0\\), and we denote it by{\" \"}\r\n          {\"\\\\(\\\\partial\\\\mathcal{H}^k\\\\)\"}. It is important to note that this\r\n          is completely different from a topological boundary, even though we\r\n          use the same notation. A manifold with boundary \\(X\\) of dimension\r\n          \\(k\\), then, has a neighbourhood around each point diffeomorphic to{\" \"}\r\n          {\"\\\\(\\\\mathcal{H}^k\\\\)\"}, and its boundary \\(\\partial X\\) is the set\r\n          of points which lie in {\"\\\\(\\\\partial\\\\mathcal{H}^k\\\\)\"} under some\r\n          set of local coordinates (one can show this is well-defined and will\r\n          in fact be identical for any arbitrary system). It is immediate the\r\n          boundary then is itself a manifold of dimension \\(k-1\\), as we can\r\n          parametrize it to {\"\\\\(\\\\mathbb{R}^{k-1}\\\\)\"} by cutting off the last\r\n          coordinate (as it will always be \\(0\\)), and composing.\r\n        </p>\r\n        <p>\r\n          Of note is that any compact, connected \\(1\\)-manifold with boundary is\r\n          diffeomorphic to the unit interval \\([0,1]\\) or to the unit circle\r\n          \\(S^1\\) (visually, compactness and connectedness means you can only\r\n          end somewhere or loop back to where you started). This is actually\r\n          non-trivial to show as well, much like the Jordan curve theorem,\r\n          despite being intuitively quite obvious. We will take it for granted,\r\n          as we will need the following fact later.\r\n        </p>\r\n        <Theorem\r\n          no=\"1\"\r\n          statement=\"\r\n                Every compact \\(1\\)-manifold with boundary has an even number of points in its boundary.\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Every component will be diffeomorphic to \\([0,1]\\) or \\(S^1\\), which have \\(2\\) and \\(0\\) points in the boundary, respectively.\"\r\n        />\r\n        <p>\r\n          This is the only definition we need to generalize Jordan's result. We\r\n          call a manifold {\"\\\\(X\\\\subseteq\\\\mathbb{R}^n\\\\)\"} a{\" \"}\r\n          <strong>hypersurface</strong> if it is of dimension \\(n-1\\) (note that\r\n          this can be generalized to submanifolds and codimensions, but we will\r\n          not need that).\r\n        </p>\r\n        <Theorem\r\n          name=\"Jordan-Brouwer\"\r\n          statement=\"\r\n                If \\(X\\) is a compact, connected hypersurface in \\(\\mathbb{R}^n\\), then \\(\\mathbb{R}^n\\setminus X\\) consists of two open connected components, \\(D_0\\) and \\(D_1\\), such that \\(\\overline{D_0}\\) is a compact manifold with boundary, and in particular \\(\\partial\\overline{D_0}=X\\).\"\r\n        />\r\n        <p>\r\n          Perhaps being slightly misleading, I will not be talking about the\r\n          Jordan-Brouwer theorem itself in this post. Instead, I will be talking\r\n          about something intimately related to it. To prove this theorem, we\r\n          must at some point have candidates for \\(D_0\\) and \\(D_1\\), and this\r\n          is what I will be discussing: how do we define inside and outside in\r\n          the first place?\r\n        </p>\r\n        <p>\r\n          The first stop is at the intersections of curves. Recall that there is\r\n          a nice condition for when the preimage of a map \\(f\\colon X\\to Y\\)\r\n          would have {\"\\\\(f^{-1}(y)\\\\)\"} be a manifold. Specifically, it was\r\n          when \\(y\\) was a regular value, meaning \\(df_x\\) was surjective at\r\n          each point {\"\\\\(x\\\\in f^{-1}(y)\\\\)\"}. This is, in fact, a special case\r\n          of the more general concept of{\" \"}\r\n          <strong>transversal intersections</strong>. In particular, \\(f\\) is\r\n          transversal to a submanifold \\(Z\\subseteq Y\\), written \\(f\\pitchfork\r\n          Z\\), if {\"\\\\(T_{f(x)}(Z)+\\\\operatorname{im}df_x=T_{f(x)}(Y)\\\\)\"} for\r\n          every {\"\\\\(x\\\\in f^{-1}(Z)\\\\)\"}.\r\n        </p>\r\n        <Theorem\r\n          no=\"2\"\r\n          statement=\"\r\n                For smooth \\(f\\colon X\\to Y\\) with \\(Z\\) a submanifold of \\(Y\\), then \\(f^{-1}(Z)\\) is a submanifold of \\(X\\) if \\(f\\pitchfork Z\\).\"\r\n        />\r\n        <Proof proof=\"Consider some \\(x\\in f^{-1}(Z)\\), and let \\(y=f(x)\\). Let \\(\\ell=\\operatorname{codim}Z\\). Take local coordinates around \\(y\\) such that the last \\(\\ell\\) coordinates vanish on \\(Y\\setminus Z\\) (locally); call these last \\(\\ell\\) coordinates \\(g=(g_1,\\dots,g_\\ell)\\). Consider the composition \\(g\\circ f\\colon f^{-1}(Z)\\to\\mathbb{R}^\\ell\\), and note \\[d(g\\circ f)_x=dg_y\\circ df_x.\\] As\\(f\\pitchfork Z\\), this derivative is surjective at \\(x\\). However, \\(x\\) was an arbitrary point in the preimage and we have \\((g\\circ f)(x)=0\\), meaning \\(0\\) is a regular value of \\(f\\). Then, \\(f^{-1}(Z)=(g\\circ f)^{-1}(0)\\) is a submanifold. \" />\r\n        <p>\r\n          This is a very visual idea, essentially meaning that tangent spaces\r\n          add up to the ambient space. However, this has the caveat of therefore\r\n          being dependent on the ambient space, and so intersections transversal\r\n          in one setting may not be transversal elsewhere. This is demonstrated\r\n          in figure 2 below.\r\n        </p>\r\n        <Figure\r\n          no=\"2\"\r\n          src={Fig2Transv}\r\n          caption=\"Transversal intersection (left) and non-transversal intersection (right)\"\r\n        />\r\n        <p>\r\n          This is quite a nice, simple condition to verify if a preimage will be\r\n          a submanifold, and captures the spirit of differential topology: for\r\n          us to learn about behaviour globally (being a manifold), we reduce it\r\n          to local linear behaviour (a union of vector spaces). However, there\r\n          is the very real question of whether intersections like this exist, in\r\n          general. After all, intersections can be very tricky. If we take any\r\n          function {\"\\\\(\\\\mathbb{R}\\\\to\\\\mathbb{R}\\\\)\"} which crosses the\r\n          \\(x\\)-axis, any slight variation of that function will undoubtedly\r\n          move that crossing point, and so it is very hard, in general, to find\r\n          a function which has a root at a specific value (outside of contrived\r\n          examples). Might it be the same for transversal intersections?\r\n          Thankfully, no; in fact, essentially all intersections are\r\n          transversal, and these intersections are not affected by\r\n          perturbations. To formalize this idea, we introduce homotopy.\r\n        </p>\r\n        <p>\r\n          Two maps \\(f_0,f_1\\colon X\\to Y\\) are <strong>homotopic</strong>,\r\n          written \\(f_0\\sim f_1\\), if there exists some smooth map \\(F\\colon\r\n          X\\times [0,1]\\to Y\\) such that \\(F(x,0)=f_0(x)\\) and\r\n          \\(F(x,1)=f_1(x)\\). A property of \\(f_0\\) is said to be{\" \"}\r\n          <strong>stable</strong> if for any homotopy \\(F(x,t)\\eqqcolon\r\n          f_t(x)\\), there exists some \\(\\varepsilon \\gt 0\\) such that \\(f_t\\)\r\n          has that property when \\(t \\lt \\varepsilon\\). A great deal of\r\n          interesting properties are stable, such as embeddings, submersions,\r\n          etc. In particular, as transversal intersections at the heart rely on\r\n          submersions, it follows that they are stable as well. The proofs for\r\n          these all essentially rely on these conditions being a statement about\r\n          the determinant of some matrix, by the inverse function theorem, and\r\n          the determinant function being continuous.\r\n        </p>\r\n        <p>\r\n          What is far more interesting is that transversality is generic,\r\n          meaning that given any smooth map \\(f\\) and any submanifold \\(Z\\), we\r\n          can find some \\(g\\) homotopic to \\(f\\) so \\(g\\pitchfork Z\\). This is\r\n          quite remarkable given that the behaviour of \\(f\\) with respect to\r\n          \\(Z\\) can be as pathological as we want - we need only to slightly\r\n          wiggle it to get a nice intersection. Proving transversal\r\n          intersections are generic is dry and lengthy (it would involve\r\n          numerous technical lemmas, all for a rather technical result). It\r\n          could be a whole post in and of itself, so instead I will simply state\r\n          the two results we will need.\r\n        </p>\r\n        <Theorem\r\n          no=\"2\"\r\n          name=\"Transversality-Homotopy\"\r\n          statement=\"\r\n                Let \\(f\\colon X\\to Y\\) be smooth between a manifold \\(X\\) and a boundaryless manifold \\(Y\\). If \\(Z\\) is a boundaryless submanifold of \\(Y\\), there is some smooth \\(g\\sim f\\) such that \\(g\\pitchfork Z\\) and \\(\\partial g\\pitchfork Z\\), where \\(\\partial g :\\equiv g\\vert_{\\partial X}\\).\"\r\n        />\r\n        <p>\r\n          For \\(f\\colon X\\to Y\\) we say that \\(f\\pitchfork Z\\) on a subset \\(C\\)\r\n          of \\(X\\) if {\"\\\\(f\\\\vert_{C\\\\cap f^{-1}(Z)}\\\\pitchfork Z\\\\)\"}. We can\r\n          slightly strengthen theorem 2, useful in some situations.\r\n        </p>\r\n        <Theorem\r\n          no=\"3\"\r\n          name=\"Extension Theorem\"\r\n          statement=\"\r\n                Let \\(f\\colon X\\to Y\\) be smooth between a manifold \\(X\\) and a boundaryless manifold \\(Y\\), and \\(C\\subseteq X\\) be closed. If \\(Z\\) is a closed boundaryless submanifold of \\(Y\\) such that \\(f\\pitchfork Z\\) on \\(C\\) and \\(\\partial f\\pitchfork Z\\) on \\(C\\cap\\partial X\\), there is some \\(g\\sim f\\) such that \\(g\\pitchfork Z\\) and \\(\\partial g\\pitchfork Z\\) and \\(g\\equiv f\\) on a neighbourhood of \\(C\\).\"\r\n        />\r\n        <p>\r\n          We will use these to continue our trek toward the main result, and\r\n          that is determining what lies inside and outside a hypersurface. We\r\n          will do this with transversal intersections of a specific function and\r\n          a special invariant. This invariant will come from the{\" \"}\r\n          <strong>intersection number</strong>. For \\(f\\colon X\\to Y\\) and\r\n          \\(f\\pitchfork Z\\) a closed submanifold of \\(Y\\), such that{\" \"}\r\n          {\r\n            \"\\\\(\\\\operatorname{dim}X+\\\\operatorname{dim}Z=\\\\operatorname{dim}Y\\\\)\"\r\n          }\r\n          , we define the intersection number modulo 2 of \\(f\\) with respect to\r\n          \\(Z\\), written \\(I_2(f,Z)\\), to be{\" \"}\r\n          {\"\\\\(\\\\left|f^{-1}(Z)\\\\right|_2\\\\)\"} (the cardinality of the preimage\r\n          modulo 2). Observe that due to the condition on our dimensions,{\" \"}\r\n          {\"\\\\(f^{-1}(Z)\\\\)\"} will be a manifold of dimension \\(0\\) (hence a\r\n          finite set), so the intersection number is well-defined. Of course,\r\n          not all maps will intersect \\(Z\\) transversally, but recall that\r\n          transversality is generic, and theorem 1 gives us a nice statement\r\n          about cardinalities of boundaries modulo 2, to get the following\r\n          result.\r\n        </p>\r\n        <Theorem\r\n          no=\"4\"\r\n          statement=\"\r\n                If \\(f_0,f_1\\colon X\\to Y\\) are homotopic so \\(f_0\\pitchfork Z\\) and \\(f_1\\pitchfork Z\\), where \\(Z\\) is a closed submanifold of \\(Y\\) so \\(\\operatorname{dim}X+\\operatorname{dim}Z=\\operatorname{dim}Y\\), then \\(I_2(f_0,Z)=I_2(f_1,Z)\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Let \\(F\\colon X\\times [0,1]\\to Y\\) be a homotopy of \\(f_0\\) and \\(f_1\\). Without loss of generality, take \\(F\\pitchfork Z\\), for otherwise observe that \\(F\\pitchfork Z\\) on \\(X\\times \\{0,1\\}\\) (as \\(f_0\\) and \\(f_1\\) are both transversal), which is closed in \\(X\\times [0,1]\\). Then, the extension theorem lets us take some \\(G\\sim F\\) so \\(G\\pitchfork Z\\) yet \\(G\\equiv F\\) on \\(X\\times \\{0,1\\}\\) (in fact, it will be true on a neighbourhood thereof), hence \\(G(x,0)=f_0(x)\\) and \\(G(x,1)=f_1(x)\\).\\[\\] \r\n                \r\n                Now, note that \\(\\partial (X\\times [0,1])=X\\times\\{0\\}\\cup X\\times\\{1\\}\\), hence \\(F\\equiv f_0\\) or \\(F\\equiv f_1\\) on \\(\\partial (X\\times [0,1])\\), so \\(\\partial F\\pitchfork Z\\). Then,\r\n                \\[\r\n                    \\operatorname{dim}(X\\times [0,1])-\\operatorname{dim}F^{-1}(Z) =\\operatorname{dim}X+1-\\operatorname{dim}F^{-1}(Z)=\\operatorname{dim}Y-\\operatorname{dim}Z\r\n                \\]\r\n                and our assumptions on dimensions means \\(\\operatorname{dim}F^{-1}(Z)=1\\). Observe that\r\n                \\[\r\n                    \\begin{aligned}\r\n                    \\partial F^{-1}(Z)&=F^{-1}(Z)\\cap\\partial(X\\times [0,1])\\\\\r\n                    &=F^{-1}(Z)\\cap(X\\times\\{0\\})\\cup F^{-1}(Z)\\cap(X\\times\\{1\\})\\\\\r\n                    &=f_0^{-1}(Z)\\cup f_1^{-1}(Z)\r\n                    \\end{aligned}\r\n                \\]\r\n                however, by theorem 1, this means \\(I_2(f_0,Z)=I_2(f_1,Z)\\), as desired. \"\r\n        />\r\n        <Theorem\r\n          no=\"5\"\r\n          name=\"Boundary Theorem\"\r\n          statement=\"\r\n                If \\(W\\) is compact with \\(\\partial W=X\\), and \\(g\\colon X\\to Y\\) can be extended to \\(W\\), then \\(I_2(g,Z)=0\\) for all closed submanifolds \\(Z\\) in \\(Y\\) such that \\(\\operatorname{dim}X+\\operatorname{dim}Z=\\operatorname{dim}Y\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Say \\(G\\) is the extension of \\(g\\). By transversality-homotopy, take \\(F\\sim G\\) so \\(F\\pitchfork G\\) and \\(\\partial F\\pitchfork G\\). Observe that \\(\\partial G=g\\) and \\(\\partial F=: f\\sim g\\). Therefore, \\(I_2(g,Z)=|f^{-1}(Z)|_2\\) by theorem 4, but as \\(F^{-1}(Z)\\) is a \\(1\\)-manifold with boundary, \\(I_2(g,Z)=0\\) by theorem 1.\"\r\n        />\r\n        <p>\r\n          Then, for an arbitrary map \\(g\\) (with all the same conditions as\r\n          before), we can define \\(I_2(g,Z)=I_2(f,Z)\\), where \\(f\\sim g\\) is an\r\n          arbitrary homotopy transversal to \\(Z\\), which will exist by\r\n          transversality-homotopy. Our next step in constructing this invariant\r\n          is to exploit that our hypersurface will be connected.\r\n        </p>\r\n        <Theorem\r\n          no=\"6\"\r\n          statement=\"If \\(f\\colon X\\to Y\\) is smooth with equidimensional compact \\(X\\) and connected \\(Y\\), then \\(I_2(f,\\{y\\})\\) is invariant under choice of \\(y\\in Y\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Without loss of generality, assume \\(f\\pitchfork \\{y\\}\\) (note this is identical to assuming \\(y\\) is a regular value). By the stack of records theorem (proved in an earlier post of mine), there is a neighbourhood \\(U\\) of \\(y\\) such that \\(f^{-1}(U)=\\dot{\\bigcup}_{k=1}^n V_k\\) where each \\(V_k\\) is open in \\(X\\) and \\(f\\) is locally diffeomorphic on each.\\[\\]\r\n                Then, \\(I_2(f,\\{z\\})=n\\) for any \\(z\\in U\\), and so the map \\(y\\mapsto I_2(f,\\{y\\})\\) is locally constant on \\(U\\). As \\(Y\\) is connected, this extends to a globally constant map.\"\r\n        />\r\n        <p>\r\n          We call this value the modulo 2 <strong>degree</strong> of \\(f\\),\r\n          written {\"\\\\(\\\\operatorname{deg}_2 f\\\\)\"}. Now, we begin the\r\n          construction. Let \\(X\\) be a compact, connected manifold (we will\r\n          shortly examine hypersurfaces in particular) in{\" \"}\r\n          {\"\\\\(\\\\mathbb{R}^n\\\\)\"}, with {\"\\\\(f\\\\colon X\\\\to\\\\mathbb{R}^n\\\\)\"}{\" \"}\r\n          smooth and for {\"\\\\(z\\\\in\\\\mathbb{R}^n\\\\setminus f(X)\\\\)\"} define the{\" \"}\r\n          <strong>unit vector</strong>\r\n          {\r\n            \"\\\\[u_z\\\\colon X\\\\to S^{n-1}\\\\textrm{ by }u_z(x)=\\\\frac{f(x)-z}{|f(x)-z|}.\\\\]\"\r\n          }\r\n        </p>\r\n        <p>\r\n          Note that \\(u_z\\) satisfies the hypotheses of theorem 6, hence we can\r\n          consider {\"\\\\(\\\\operatorname{deg}_2 u_z\\\\)\"}. Observe that,\r\n          geometrically, this is the number (modulo 2) of points \\(x\\in X\\)\r\n          whose unit vector from \\(f(x)\\) to \\(z\\) will point in a particular\r\n          direction (as we compute the degree by fixing some vector in{\" \"}\r\n          {\"\\\\(S^{n-1}\\\\)\"}). Thus, we call this the winding number modulo 2 of\r\n          \\(f\\) around \\(z\\), written{\" \"}\r\n          {\"\\\\(W_2(f,z):=\\\\operatorname{deg}_2 u_z\\\\)\"}. A visual representation\r\n          is seen below in figure 3.\r\n        </p>\r\n        <Figure\r\n          no=\"3\"\r\n          src={Fig3Wind}\r\n          caption=\"A particular unit vector \\(u_z\\) with points in its preimage (blue). Here, \\(W_2(f,z)=1\\).\"\r\n        />\r\n        <p>\r\n          This winding number is the key to the separation theorem. We will use\r\n          it to compute what is \"inside\" and \"outside\", and we begin with a\r\n          technical result.\r\n        </p>\r\n        <Theorem\r\n          no=\"7\"\r\n          statement=\"\r\n                Let \\(f\\colon X\\to\\mathbb{R}^n\\) be smooth with \\(D\\) a compact manifold with boundary \\(X\\) such that \\(F\\colon D\\to\\mathbb{R}^n\\) extends \\(f\\). If \\(z\\notin f(X)\\) is a regular value of \\(F\\), then \\(F^{-1}(Z)\\) is finite and \\(|F^{-1}(z)|\\equiv_2 W_2(f,z)\\). \"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Suppose \\(F^{-1}(z)=\\varnothing\\). As \\(f\\) can be extended to \\(D\\), so can the unit vector \\(u_z\\) as \\(F(x)\\neq z\\) for all \\(x\\in D\\), so it is well-defined. Then, by the boundary theorem, we have that\r\n                \\[\r\n                    \\operatorname{deg}_2 u_z=0=W_2(f,z)=|\\varnothing|\r\n                \\]\r\n                as the degree is defined as an intersection number. \\[\\]\r\n                Suppose now \\(F^{-1}(z)=\\{x_1,\\dots ,x_\\ell\\}\\). For each \\(x_i\\), take a closed ball of radius \\(\\varepsilon_i\\) around \\(x_i\\), call it \\(\\mathcal{B}_i(x_i,\\varepsilon_i)\\), small enough such that the \\(\\mathcal{B}_i\\) are disjoint from each other and from \\(X\\). Define \\(g_i\\colon\\partial\\mathcal{B}_i\\to\\mathbb{R}^n\\) as a restriction of \\(F\\), and let \\(D_k:=D\\setminus\\dot{\\bigcup}_{i=1}^k\\operatorname{int}\\mathcal{B}_i\\), \\(X_k:=\\partial D_k\\), and \\(f_k:=F\\vert_{X_k}\\). \\[\\]\r\n                Now, note that \\(W_2(f_0,z)=W_2(f,z)\\), and\r\n                \\[\r\n                    W_2(f_k,z)=W_2(f_{k-1},z)+W_2(g_k,z).\r\n                \\]\r\n                Thus,\r\n                \\[\r\n                    W_2(f_\\ell,z)=W_2(f_{\\ell-1},z)+W_2(g_\\ell,z)=W_2(g_1,z)+\\cdots +W_2(g_1,z)+W_2(f_0,z).\r\n                \\]\r\n                As \\(z\\notin D_\\ell\\), we can extend \\(f_\\ell\\) to \\(D_\\ell\\), hence by the boundary theorem \\(W_2(f_\\ell,z)=0\\), meaning\r\n                \\[\r\n                    -W_2(f_0,z)=-W_2(f,z)=W_2(g_1,z)+\\cdots+W_2(g_\\ell,z).\r\n                \\]\r\n                By \\(z\\) being a regular value and the balls being disjoint, we know \\(F\\) is locally diffeomorphic in some neighbourhood of the closed balls. Restricting the unit vector map (induced by \\(g_k\\)) will have it be bijective, hence \\(W_2(g_k,z)=1\\), and taking everything modulo \\(2\\) we are done.\"\r\n        />\r\n        <p>\r\n          One can apply theorem 7 to the case where \\(X\\) is a hypersurface and\r\n          \\(f=\\imath\\) is the inclusion. If one can prove that the complement of\r\n          \\(X\\) consists of two connected sets, each open with \\(X\\) being their\r\n          boundary, with one bounded and one unbounded, then it will precisely\r\n          state that \\(W_2(X,z):=W_2(\\imath,z)\\) (this is what we mean when we\r\n          talk about winding numbers of manifolds) is equal to the number of\r\n          points in the preimage of the extension of the inclusion map. That is,\r\n          the winding number will be equal to \\(1\\) if it lies \"inside\" and\r\n          \\(0\\) if it lies \"outside\". This is the invariant we seek to compute,\r\n          which we will do using the following curve.\r\n        </p>\r\n        <p>\r\n          Given {\"\\\\(z\\\\in\\\\mathbb{R}^n\\\\setminus X\\\\)\"} in the complement of\r\n          our compact, connected hypersurface, we define a <strong>ray</strong>{\" \"}\r\n          emanating from \\(z\\) in the direction of \\(v\\) to be{\" \"}\r\n          {\"\\\\[r:=\\\\{z+tv:0\\\\leq t\\\\in\\\\mathbb{R}\\\\}.\\\\]\"}.\r\n        </p>\r\n        <Theorem\r\n          no=\"8\"\r\n          statement=\"\r\n                A ray \\(r\\) from \\(z\\) in the direction of \\(v\\) is transversal to \\(X\\) if and only if \\(v\\) is a regular value of the unit vector \\(u_z\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Suppose that \\(r\\pitchfork X\\). Then,\r\n                \\[\r\n                    T_x(X)+\\operatorname{im}dr_t=T_x(\\mathbb{R}^n)=\\mathbb{R}^n\r\n                \\]\r\n                for any \\(x\\in X\\cap r\\), where \\(x=z+tv\\). With \\(v=(v_1,\\dots, v_n)\\), we know that\r\n                \\[\r\n                    dr_t=\\begin{pmatrix}\r\n                    v_1 & \\cdots & v_n\r\n                    \\end{pmatrix}^T(t)\r\n                \\]\r\n                and so the image under \\(\\mathbb{R}\\) is just the ray extended to the line. Then, recall that \\(u_z(x)=(x-z)/|x-z|\\) (as our map \\(f\\) here is just the inclusion), and \\(v\\) is a regular value if and only if for all \\(x\\) such that \\(u_z(x)=v\\) we have \\(d(u_z)_x=\\mathbb{R}^{n-1}\\). This, however, happens if and only if \\(T_x(X)\\perp \\{tv:t\\in\\mathbb{R}\\}\\), precisely equivalent to our transversality condition.\"\r\n        />\r\n        <Theorem\r\n          no=\"9\"\r\n          statement=\"\r\n                Let \\(r\\) be a ray emanating from \\(z_0\\) in the direction \\(v\\) so \\(r\\pitchfork X\\). Let \\(z\\neq z_0\\) be in the complement of \\(X\\) but on \\(r\\), with \\(\\ell\\) being the number of intersections of \\(r\\) and \\(X\\) between \\(z\\) and \\(z_0\\). Then, \\(W_2(X,z_0)=W_2(X,z)+\\ell\\) all modulo \\(2\\). \"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Observe that, by theorem 8, we must have that \\(v\\) is a regular value of both \\(u_z\\) and \\(u_{z_0}\\) by theorem 8. Therefore, \\(W_2(X,z)=|u_z^{-1}(v)|_2\\) and \\(W_2(X,z_0)=|u_{z_0}^{-1}(v)|_2\\). Therefore, \\(W_2(X,z_0)=W_2(X,z)+\\ell\\), for if \\(x\\in u_z^{-1}(v)\\) lies after \\(z\\) but before \\(z_0\\), then \\(u_{z_0}(x)=-v\\), hence not contributing to the winding number. \"\r\n        />\r\n        <p>\r\n          At last, we have our central result. Recall that we are assuming we\r\n          have already proven the complement of our hypersurface consists of the\r\n          two components as posited in the Jordan-Brouwer theorem statement, and\r\n          so theorem 7 tells points in the same component have the same winding\r\n          number.\r\n        </p>\r\n        <Theorem\r\n          no=\"10\"\r\n          statement=\"\r\n                Let \\(r\\) be a ray emanating from \\(z\\) in the direction of \\(v\\), such that \\(r\\pitchfork X\\). Then, \\(z\\) lies inside \\(X\\) if and only if \\(r\\) intersects \\(X\\) an odd number of times.\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Observe that, as \\(X\\) is compact, we can find some \\(z_0\\) outside of \\(X\\) such that \\(W_2(X,z)=0\\). By theorem 9, then, \\(W_2(X,z)+\\ell=W_2(X,z_0)=0\\), meaning \\(W_2(X,z)=-\\ell\\) all modulo 2. However, as \\(z_0\\) was outside with winding number \\(0\\), this means \\(z\\) will be outside as well if and only if \\(-\\ell=0\\) modulo 2, equivalently if and only if \\(\\ell\\) is even. \"\r\n        />\r\n        <p>\r\n          I find this is a beautiful argument. Recalling figure 3, we can take\r\n          the dashed line extending \\(u_z\\) to be our ray, and we see there are\r\n          \\(5\\) intersections. If \\(f(X)=\\imath(X)=X\\), then we see\r\n          \\(W_2(X,z)=1\\) and indeed, \\(z\\) lies inside the curve (which is just\r\n          a hypersurface in {\"\\\\(\\\\mathbb{R}^2\\\\)\"}). In fact, due to Sard,\r\n          almost all values of \\(u_z\\) will be regular, hence by theorem 8\r\n          almost all such rays will intersect transversally. So, taking a\r\n          hypersurface, we can just draw random rays, and with probability 1 we\r\n          will have one to which we can apply theorem 10. This immediately gives\r\n          the following.\r\n        </p>\r\n        <Theorem\r\n          no=\"11\"\r\n          statement=\"\r\n                A point \\(z\\) lies inside a hypersurface \\(X\\) if and only if almost all rays emanating from \\(z\\) intersect \\(X\\) an odd number of times.\"\r\n        />\r\n        <p>\r\n          This is astoundingly simple, so I can now rest easy, knowing if I ever\r\n          find myself in a life-or-death situation where the only escape is by\r\n          knowing whether a point lies inside or outside a picture, I just need\r\n          a pencil and straightedge.\r\n        </p>\r\n        <Figure\r\n          no=\"4\"\r\n          src={Fig4GP}\r\n          caption=\"Figure 2-19 (89), Guillemin and Pollack\"\r\n        />\r\n      </div>\r\n    );\r\n  }\r\n\r\n}\r\n\r\nexport default JordanBrouwer;","import React, { Component } from \"react\";\r\n\r\nclass HeisigKanji extends Component {\r\n\r\n  render() {\r\n    return (\r\n      <div class=\"postContent leftMargin\">\r\n        <p>\r\n          <i>\r\n            As a preface to everything I say below: I am no expert in Japanese.\r\n            I am still learning, and still very early in my learning too. Below\r\n            are just my personal experiences, and this post is not in any way an\r\n            authoritative recommendation.\r\n          </i>\r\n        </p>\r\n        <p>\r\n          In the Japanese language-learning community (which is surprisingly\r\n          large for a language so localized), Heisig's{\" \"}\r\n          <i>Remembering the Kanji</i> ('RTK') is an incredibly divisive book.\r\n          Even worse, it's a clean division: most people either blindly swear by\r\n          it and insist it's the only way to begin learning Japanese, or\r\n          denounce the book and aver it's a complete waste of time. For me,\r\n          community sentiment was irrelevant when I began learning, simply\r\n          because I wasn't aware of it. Rather, I asked a friend of mine who\r\n          went from no Japanese to passing N1 in a little over a year, and\r\n          simply planned to emulate his journey. However, I can imagine if\r\n          someone is planning to learn the language and they're getting their\r\n          advice strictly online, it would be very hard to consolidate all of\r\n          these inconsistent views. Should they read it? Should they not? The\r\n          situation is not so simple as to warrant a blanket \"Yes\" or \"No\", in\r\n          my opinion, and I aim to elucidate my reasoning as to why in this\r\n          post, as well as how I think it should be answered instead.\r\n        </p>\r\n        <p>\r\n          I will assume you are familiar with what kanji are. If not, there are\r\n          plenty of explanations online about the difference between the three\r\n          Japanese scripts. To many, kanji are a fairly intimidating aspect of\r\n          Japanese. I find this is related to that fact that language is, of\r\n          course, solely an oral construction, and completely disjoint from\r\n          orthography. Thus, even if you have a very strong vocabulary and solid\r\n          understanding of grammar, you will remain functionally illiterate if\r\n          you do not know kanji. In particular, this means that even if your\r\n          knowledge of the <i>language</i> surpasses a level, that does not\r\n          necessarily mean you can also <i>read</i> the next level, as more\r\n          difficult texts begin to use both more kanji and less furigana. This\r\n          gap in orthography exists for quite a while; depending on the\r\n          end-material you wish to read it can require you to learn somewhere\r\n          between 1500-3000 kanji until it goes away. Of course, Japanese people\r\n          don't have (too many - character amnesia is an interesting phenomenon)\r\n          issues with this, because the level of material they can understand\r\n          will generally match their orthographic knowledge as they grow up.\r\n          However, as an adult, it can be frustrating enough to read children's\r\n          books when learning any language, but being limited to children's\r\n          books even though you could read more complex material if it was\r\n          written <i>in a different script</i> is even more frustrating, and not\r\n          an issue that is even possible in most languages. Most do not have an\r\n          orthography that works like this - you can learn how to nearly\r\n          fluently read Hangul over lunch, or even both kanas over the weekend.\r\n          However, Japanese people don't care how difficult it is for foreigners\r\n          to learn their orthography (and rightfully so) because, like I said,\r\n          they don't usually encounter such a gap, and kanji have many benefits\r\n          for Japanese (e.g. density:「こころよい」versus「快い」;\r\n          disambiguation: look up「かける」in a dictionary). Thus, you will\r\n          eventually have to learn kanji, and quite a few: at least 1000 at a\r\n          bare minimum, but realistically far more.\r\n        </p>\r\n        <p>\r\n          This is where Heisig's book comes in. He took a list of the 2136 Jōyō\r\n          kanji (plus a few extra), broke them down into their component\r\n          sub-kanji, and then broke those sub-kanji down again, and continued\r\n          until he arrived at atomic kanji - radicals. He then took a few basic\r\n          radicals, and found all kanji which are combinations of those or\r\n          combinations of the combinations (c.f. the sub-kanji). Once that list\r\n          was exhausted, he introduced a new radical and repeated the process,\r\n          continuing until he ordered all of the kanji. Afterward, Heisig{\" \"}\r\n          <u>assigned</u> (the phrasing here is important and I will recount it\r\n          later) all of these kanji a unique keyword. Now, given his ordering\r\n          process, each kanji has with it a minimal list of sub-kanji or\r\n          radicals, which also have a unique keyword assigned. His technique\r\n          then was to take a kanji, look at its keyword, look at the list of\r\n          keywords that compose it, and then come up with some sort of visual\r\n          imagery based on that list to remind him of the greater keyword.\r\n          Repeat this for each kanji, and you end up with a process which,\r\n          certainly at least mathematically, is the most efficient way to learn\r\n          the kanji.\r\n        </p>\r\n        <p>\r\n          So then, where is the criticism? Surely the most efficient way is the\r\n          best way, right? Well, as in economics, theoretically efficiency here\r\n          does not (necessarily) translate to pragmatism. The thing is, if your\r\n          goal is literally to just learn the kanji, there is absolutely no\r\n          question - Heisig's method is the only way to go. However, most (and\r\n          in fact, I would wager all) people who are looking to learn kanji are\r\n          doing it in the context of the greater goal of{\" \"}\r\n          <i>learning Japanese</i>. And the thing is, RTK does absolutely\r\n          nothing to help in that regard, on the surface (as I mentioned before,\r\n          this is just orthography). At around 5 minutes per character, going\r\n          through the book will take 180 hours <i>not including reviews</i>, and\r\n          you will understand just as much Japanese content at hour 180 as you\r\n          did at hour 0.\r\n        </p>\r\n        <p>\r\n          If you have not gone through the book you might be confused as to how\r\n          this is possible. Aren't the keywords teaching you the meaning of\r\n          kanji? What does it even mean to learn kanji if that isn't it? Doesn't\r\n          this mean RTK is useless? I certainly wondered this. Well, recall how\r\n          I specified Heisig <u>assigned</u> keywords to the kanji. The purpose\r\n          of these keywords is primarily to distinguish the kanji from each\r\n          other - a memory and bookkeeping tool. It doesn't actually matter\r\n          exactly what they are; they're not super special or sacred words. Take\r\n          any set of 2200 words, biject those to the kanji, and you have a new\r\n          set of keywords that will work just as well as the keywords Heisig\r\n          gave (in terms of completing the book). This is because many kanji\r\n          have multiple meanings, or their meanings are very abstract. For\r\n          example, Heisig assigns「重」the keyword \"Heavy\". This appears in many\r\n          words, from「\r\n          <ruby>\r\n            重<rt>おも</rt>\r\n          </ruby>\r\n          い」, also meaning <strong>Heavy</strong>, to「\r\n          <ruby>\r\n            重<rt>じゅう</rt>要<rt>よう</rt>\r\n          </ruby>\r\n          」meaning <strong>Important</strong>, or「\r\n          <ruby>\r\n            重<rt>かさ</rt>\r\n          </ruby>\r\n          なる」meaning <strong>To be piled up</strong>. In some sense these all\r\n          come from the keyword, but as you can see it's a very vague idea; you\r\n          can easily replace it with something like \"Large\", \"Stacked\", or\r\n          \"Multiple\" and you don't lose nor gain any information. On the other\r\n          hand, we can take「本」which is assigned the word \"Book\" and see it\r\n          appears in the word「\r\n          <ruby>\r\n            日<rt>に</rt>本<rt>ほん</rt>\r\n          </ruby>\r\n          」meaning <strong>Japan</strong>,「\r\n          <ruby>\r\n            本<rt>ほん</rt>\r\n          </ruby>\r\n          」meaning <strong>Book</strong>,「\r\n          <ruby>\r\n            本<rt>ほん</rt>能<rt>のう</rt>\r\n          </ruby>\r\n          」meaning <strong>Instinct</strong>, or「\r\n          <ruby>\r\n            本<rt>ほん</rt>気<rt>き</rt>\r\n          </ruby>\r\n          」meaning <strong>Earnestness</strong>. Here, it's quite obvious that\r\n          not all of its uses are accounted for by the keyword.\r\n        </p>\r\n        <p>\r\n          Of course though, some keywords are better than others, and Heisig's\r\n          are overall pretty good. Although the keyword \"Heavy\" doesn't\r\n          communicate all of the ideas 「重」 gives off, it <i>did</i> come\r\n          pretty close in most of them, and sometimes exactly matched the\r\n          meaning, as seen in「重い」. This is something I think a lot of people\r\n          neglect to bring up. Sure, a kanji like「本」doesn't solely mean\r\n          \"Book\", but can also mean something like \"Main\", \"Reality\", or\r\n          \"Japan\", but that doesn't change that it <i>does</i> does sometimes\r\n          mean \"Book\". Overall, it does a really good job at helping you\r\n          understand what basic words mean, and certainly what words using just\r\n          the kanji alone mean.\r\n        </p>\r\n        <p>\r\n          What this means is that going through RTK makes it easier to learn\r\n          Japanese, but it alone doesn't teach you anything. The payoff in\r\n          trudging through the mind-numbing memorization isn't when you finish\r\n          the book. It isn't even when you first start learning grammar and\r\n          words. For me, I only appreciated it after I memorized several hundred\r\n          words and could begin to read basic texts by myself. This is where I\r\n          began to realize that I wasn't burdened by kanji at all. One reason is\r\n          that I had the ability to learn every word in its kanji-form from the\r\n          get-go, meaning I do not have to worry about how frequently a word is\r\n          written in kanji nor at what reading level the kanji is preferred over\r\n          the kana. For example, I have seen both「暫く」and「しばらく」(\r\n          <strong>For a while</strong>), as well as「きれい」and「綺麗」(\r\n          <strong>Pretty</strong> or <strong>Pure</strong>), while reading\r\n          pretty basic texts despite both words being listed as \"Usually kana\"\r\n          in dictionaries. Another is that knowing keywords gave huge a huge\r\n          boost to my effective word-count. One of the first sentence cards I\r\n          made exemplifies this:「\r\n          <ruby>\r\n            屋根<rt>やね</rt>\r\n          </ruby>\r\n          の\r\n          <ruby>\r\n            虫<rt>むし</rt>\r\n          </ruby>\r\n          が\r\n          <ruby>\r\n            鳴<rt>な</rt>\r\n          </ruby>\r\n          くぞよ。」. This was my first time seeing the words「屋根」(\r\n          <strong>Roof</strong>), 「虫」(<strong>Insect</strong>), or「鳴く」(\r\n          <strong>To chirp</strong>) (which is literally every single word in\r\n          sentence), yet I knew exactly what the sentence meant because I could\r\n          read the kanji as \"Roof... roots\", \"Insect\", and \"Chirp\". Of course,\r\n          not every word is this straightforward. For example, good luck with「\r\n          <ruby>\r\n            立<rt>りっ</rt>派<rt>ぱ</rt>\r\n          </ruby>\r\n          」(<strong>Exquisite</strong>) being parsed as \"Stand up... faction\",\r\n          or「\r\n          <ruby>\r\n            機<rt>き</rt>関<rt>かん</rt>\r\n          </ruby>\r\n          」(<strong>Engine</strong> or <strong>Institution</strong>) being\r\n          parsed as \"Mechanism... connection\". However, I find that many words\r\n          are, particularly in very short or very long compounds. Furthermore, I\r\n          noticed that I never mistook certain kanji for others, even though\r\n          they may look similar on the surface, due to the fact that rigorously\r\n          going through them means they all look completely unique.\r\n        </p>\r\n        <p>\r\n          However, RTK does not somehow eliminate the need to worry about kanji.\r\n          It merely repositions it. And that is where its largest downfall comes\r\n          in. Going through the book <i>sucks</i>. A <i>lot</i>. Recall that I\r\n          said it takes around 180 hours total. This means that I read the book\r\n          for, on average, 6 hours a day. My review time was usually around 2\r\n          hours a day (~250 cards at ~25 seconds per). I could only do this\r\n          because I was an unemployed student during the summer. If I had a job?\r\n          Then I could only keep this pace on the days I worked less than 4\r\n          hours - any more and I have to start swapping work for reading,\r\n          meaning a full 8 hour day leaves only 2 hours of studying. If I was in\r\n          school? I could maybe pull 2 hours a day during a slow part of the\r\n          semester (but as I will show you, this would require it being\r\n          exceptionally slow). Now, there's nothing inherently wrong with taking\r\n          longer to get through RTK. After all, the kanji aren't going anywhere.\r\n          However, it becomes so much harder when you do. I know this from\r\n          personal experience. I originally started the book during the school\r\n          year, and on an average (read: light) day I could read for maybe 30\r\n          minutes. At that pace, it would take a full <i>year</i> to finish the\r\n          book (obviously this is false because the school year only lasts 8\r\n          months, but this is irrelevant given what I'm about to say right now)\r\n          and I ended up giving up 3 months in, having finished ~200 kanji,\r\n          simply because I could not maintain any motivation in this journey to\r\n          \"learn Japanese\" as I was seeing no progress -{\" \"}\r\n          <i>because that wasn't what I was doing.</i> Getting it done in a\r\n          month was doable, and 2 or 3 months might even be easier because it's\r\n          less work every day, but going past 4 months seems like you would be\r\n          pushing it dangerously close to the territory I was in.\r\n        </p>\r\n        <p>\r\n          When I started again, having forgotten basically everything more\r\n          intricate than「口」, I realized that if I wanted to get this done, I\r\n          need to get it done as fast as possible, so that this burnout cannot\r\n          catch up to me again. I initially set a goal to do at least 40 kanji a\r\n          day. As I ended up doing closer to 50, I upped my goal to do a minimum\r\n          of 60. In the end, I was doing around 80 per day. The good thing is\r\n          that despite being boring, RTK is not hard or stressful. Memorizing\r\n          kanji becomes fairly easy after your first 100, and although\r\n          diminishing returns set in pretty quickly afterward, it does become\r\n          slightly easier with each extra one you learn. This means that whether\r\n          I spent 4 hours or 8 hours reading the book and creating these\r\n          stories, I was just as effective at the beginning as I was at the end,\r\n          and I didn't feel mentally fatigued. A digression: I wish reading\r\n          maths textbooks was this easy - I start becoming antsy and frustrated\r\n          after around an hour of reading and struggle to comprehend anything\r\n          after the second. Even with breaks, it is hard to do anything more\r\n          than 2-4 hours in a day.\r\n        </p>\r\n        <p>\r\n          However, I would occasionally encounter kanji for which I could not\r\n          come up with a compelling story. Interestingly, this had nothing to do\r\n          with the number of strokes, position in the book, ambiguity in the\r\n          keyword, or anything like that. It seemed to happen at random. Notable\r\n          examples that I recorded\r\n          were「敏」,「河」,「貼」,「読」,「判」,「錯」, and, rather\r\n          embarrassingly,「引」. However, I obviously know all of these now, so\r\n          what did I do to make the story compelling? Well, I slightly ignored\r\n          Heisig. For some of these, I just brute-forced them in Anki until I\r\n          got them. I really do not recommend doing this, because if you forget\r\n          them later, you're screwed, as you have nothing to fall back on. There\r\n          are a handful (literally, as in less than 10) of kanji for which I did\r\n          this. For others, I used some cheap tricks such as verbal mnemonics.\r\n          Heisig covers in detail why these shouldn't be the primary approach\r\n          (basically it's because visual imagery is usually an intuitive\r\n          response to the words, whereas verbal tricks have no basis), however\r\n          if the words prompt nothing, it's better than brute-force. The most\r\n          helpful backup, however, was{\" \"}\r\n          <a className=\"linkPurple\" href=\"https://kanji.koohii.com/\">Kanji Koohii</a> (however I used\r\n          it indirectly through{\" \"}\r\n          <a className=\"linkPurple\" href=\"https://hochanh.github.io/rtk/\">rtk-search</a>). Although\r\n          those stories weren't my personal stories, they were stories\r\n          nonetheless, and oftentimes I didn't need to rip a full one from a\r\n          user, but just read some to get inspired.\r\n        </p>\r\n        <p>\r\n          There is another reason to use these websites, and that is to correct\r\n          some of Heisig's mistakes. There are a few suspicious keywords, such\r\n          as using \"Ghost\" for「鬼」instead of just saying \"Oni\",\r\n          giving「校」the keyword \"Exam\" despite it appearing in every single\r\n          word involving schools <i>and</i> the word \"School\" never being used\r\n          as a keyword elsewhere, or teaching only the simplified kanji for{\" \"}\r\n          <strong>Dragon</strong>,「\r\n          <ruby>\r\n            竜<rt>りゅう</rt>\r\n          </ruby>\r\n          」, despite「龍」also being extremely common (enough to be a top-1800\r\n          kanji despite not being jōyō) and looking sick (it's the only kanji\r\n          I've memorized through stroke-order alone). There are also better\r\n          meanings to give to kanji as radicals: assigning「糸」the meaning of\r\n          \"Spiderman\" on the left and \"Venom\" on the bottom, rather than the\r\n          dull \"Thread\" wherever, makes all its derivatives fairly easy. There\r\n          are also a few ingenious stories made by some users, such as user\r\n          fiminor coming up with one story to\r\n          encapsulate「陸」,「睦」,「勢」,「熱」,「菱」, and「陵」. In general,\r\n          I would check the user-submitted stories for each kanji before I moved\r\n          on, even if I made a good story myself, to make sure I would be aware\r\n          of these things.\r\n        </p>\r\n        <p>\r\n          In order to come up with these good stories in the first place, there\r\n          are a few things I found helpful to keep in mind. The biggest, by far,\r\n          is to try to combine multiple kanji into one story. Heisig's book\r\n          orders the kanji in a way that naturally lends itself to this, and\r\n          there are around 100-200 kanji that I learned \"for free\", as I didn't\r\n          have to come up with a separate story for them. For example, I did\r\n          this for「監」,「覧」,「濫」, and「鑑」, and I continue to do this\r\n          today when I encounter new kanji (which I will discuss in detail soon)\r\n          such as appending「綾」to fiminor's saga. I also found it important to\r\n          give very specific images. For example, I struggled to\r\n          distinguish「帝」and「王」because both of their keywords (\"Sovereign\"\r\n          and \"King\", respectively) are pretty similar and I pictured generic\r\n          male royalty for both. I solved this by emphasizing a sceptre held in\r\n          the latter (as I took it to be a pictograph of one), and picturing\r\n          Julius Caesar in the former. When the primitive \"Altar\" came up, it\r\n          appears to the left as in「視」or underneath as in「款」, and I always\r\n          pictured the former as more of a statue and the latter as an offering\r\n          table, in order to identify their physical position in the kanji. I\r\n          also tried to include real-life components, such as friends or\r\n          recounting events, to have a stronger and more grounded story. For\r\n          example, for「梢」the keyword \"Treetop\" and components \"Tree...\r\n          extinguish\" reminded me of the time I went to the Arashiyama grove\r\n          with my friend, who insisted there would be lights on, only to get off\r\n          the train at night and walk to a completely pitch-black set of\r\n          treetops. Be aware though that sometimes you <i>don't</i> need\r\n          intricate stories for kanji. Something like「分」with the keyword\r\n          \"Part\" can be taken instantly as a pictograph of a dagger splitting a\r\n          board (or something). In general, I felt that it was only around kanji\r\n          1000 or so that I got a feel for kanji and could feel that certain\r\n          combinations or positions were unnatural, and began to play\r\n          fast-and-loose with my stories; before that I kept everything very\r\n          deliberate.\r\n        </p>\r\n        <p>\r\n          That is essentially all the advice I can give. Going through RTK is a\r\n          fairly personal journey, and like I mentioned before, you will\r\n          struggle at seemingly random points that others will not, and likely\r\n          find kanji someone else finds exceedingly hard to be quite\r\n          straightforward. Overall, I found the hardest part of the book to be\r\n          the section of around 20 kanji beginning at number 595, where Heisig\r\n          introduces the \"Turkey\" primitive (funnily enough, I use the memory of\r\n          my struggle here to remember the later-learned「難」, given the\r\n          keyword \"Difficult\"). The hardest kanji to come up with stories for\r\n          were「藍」and「璽」, although I don't think either of these took\r\n          longer than 15 minutes. Mentally, the hardest parts were around kanji\r\n          700 and 1400, where I really wanted to quit for no particular reason\r\n          other than being sick of the book and doing flashcards.\r\n        </p>\r\n        <p>\r\n          The kanji「璽」brings up an important critique of Heisig's RTK too. An\r\n          analysis of around 800 million kanji uses,{\" \"}\r\n          <a className=\"linkPurple\" href=\"http://scriptin.github.io/kanji-frequency/\">\r\n            available here\r\n          </a>\r\n          , lists it as the 2938th most used character in the best case,\r\n          Wikipedia, and in one week of Twitter analysis it never came up at\r\n          all. For some context, 1500 kanji generally gives you 97-99% coverage,\r\n          depending on the material. So why is it in Heisig's book? Because the\r\n          jōyō list has nothing to do with frequency. Sure, some (actually, a\r\n          supermajority of) parts conveniently overlap, but the list is just a\r\n          set of characters approved for general-use (as is the literal name).\r\n          Due to the nature of kanji and literacy that I discussed at the\r\n          beginning, it should be clear that the government needs some official\r\n          list to which they can adhere, and so they need to ensure political\r\n          topics are covered, which is why that kanji (keyword \"Imperial Seal\")\r\n          made the cut. Do you need to know it? I doubt it. Thankfully, it's\r\n          near the end of the book, so you can skip it without a loss. However,\r\n          there are many kanji like this that appear throughout Heisig's book,\r\n          and in general, the order in which they are presented in RTK has\r\n          nothing to do with how important they are. This poses to me a problem\r\n          much more significant than learning a few scores of uncommon kanji -\r\n          an absurdly large amount of the most common kanji appear near the end\r\n          of the book. And unfortunately, you can't skip to them and do them\r\n          first (generally speaking), because they are built upon kanji learned\r\n          earlier, so the method won't work. Plus, the first 500 or so kanji in\r\n          the book have exposition written by Heisig through which he slowly\r\n          teaches you how to come up with stories on your own; immediately\r\n          skipping to「帰」and reading \"Spear... broom... apron\" will seem\r\n          impossible to handle. This means Heisig's book loses a lot of its\r\n          usefulness unless you're willing to push to at least the 1600 or 1800\r\n          mark.\r\n        </p>\r\n        <p>\r\n          This also means a few fairly simple kanji that <i>aren't</i> jōyō,\r\n          such as the「嬉」of「\r\n          <ruby>\r\n            嬉<rt>うれ</rt>\r\n          </ruby>\r\n          しい」(<strong>Pleased</strong>) or both kanji in「\r\n          <ruby>\r\n            喧<rt>けん</rt>嘩<rt>か</rt>\r\n          </ruby>\r\n          」(<strong>Argument</strong>), hence are not in RTK. However, this\r\n          doesn't really matter, because there aren't too many of them, and once\r\n          you've gotten that far learning new kanji is very easy. Whenever they\r\n          come up, I don't need to sit down for 5 minutes again and try to look\r\n          up stories online. The whole process (plus coming up with a keyword on\r\n          my own!) - identifying components and making a story - rarely takes\r\n          more than 45 seconds. And since you are learning at most 5 new ones in\r\n          a day, you won't forgot them. This is another thing that I refer to\r\n          when I say I don't have to worry about kanji anymore: that handling\r\n          them now is second nature.\r\n        </p>\r\n        <p>\r\n          Those are my thoughts on Heisig's <i>Remembering the Kanji</i>. I\r\n          found it incredibly helpful. I was free for a summer, grinded out the\r\n          book in a very short amount of time, and began learning Japanese with\r\n          a large effective-vocabulary, an easy time memorizing new words, never\r\n          stressing when I encountered new kanji - which happened fairly rarely\r\n          anyways - and never having to worry about not knowing enough kanji to\r\n          read a piece of literature. At the same time, I tried it beforehand\r\n          and (thankfully only temporarily) gave up on learning the language and\r\n          wasted a few months of my time, but potentially could've turned a\r\n          blind-eye to Japanese for the rest of my life. Is it worth it? That's\r\n          for you to decide. I've experienced the good and the bad, and laid out\r\n          to you why and when that happened. Hopefully that makes the decision\r\n          simple for you. And if you choose to go through with it, hopefully my\r\n          advice can help you through from learning「一」all the way to「巳」.\r\n        </p>\r\n      </div>\r\n    );\r\n  }\r\n\r\n}\r\n\r\nexport default HeisigKanji;","import React, { Component } from \"react\";\r\n\r\nclass Diagram extends Component {\r\n\r\n  render() {\r\n    return (\r\n      <table class=\"figureContainer\">\r\n        <tr>\r\n          <td class=\"figure\">\r\n            <img src={this.props.src} alt=\"\"></img>\r\n          </td>\r\n        </tr>\r\n      </table>\r\n    );\r\n  }\r\n\r\n}\r\n\r\nexport default Diagram;","export default __webpack_public_path__ + \"static/media/svg1.5c1a4c20.svg\";","export default __webpack_public_path__ + \"static/media/svg2.f20d0332.svg\";","export default __webpack_public_path__ + \"static/media/svg3.cecf0205.svg\";","export default __webpack_public_path__ + \"static/media/svg4.0e4d54c2.svg\";","import React, { Component } from \"react\";\r\n/* environments */\r\nimport Figure from \"../../../components/Figure\";\r\nimport Theorem from \"../../../components/Theorem\";\r\nimport Proof from \"../../../components/Proof\";\r\nimport Diagram from \"../../../components/Diagram\";\r\n/* diagrams */\r\nimport svg1 from \"./svg1.svg\";\r\nimport svg2 from \"./svg2.svg\";\r\nimport svg3 from \"./svg3.svg\";\r\nimport svg4 from \"./svg4.svg\";\r\n\r\nclass UniversalIsomorphism extends Component {\r\n    \r\n  componentDidMount() {\r\n    window.KaTeXRender();\r\n  }\r\n\r\n  render() {\r\n    return (\r\n      <div class=\"postContent leftMargin\">\r\n        <p>\r\n          While reading Aluffi's <i>Algebra: Chapter 0</i> and finishing the\r\n          proofs for the isomorphism theorems for modules, I began to grow\r\n          slightly suspect that there was something going on behind the scenes,\r\n          as the proofs were exactly the same as the ones for rings, which were\r\n          the same as the ones for groups. Presented in his book, they all\r\n          essentially stem from the fact that for a set-map \\(f:A\\longrightarrow\r\n          B\\) and the equivalence relation \\(\\sim\\) defined by \\(a\\sim b\\) if\r\n          and only if \\(f(a)=f(b)\\),\r\n        </p>\r\n        <Diagram src={svg1} />\r\n        <p style={{ textIndent: \"0\" }}>\r\n          where \\(\\pi_\\sim\\) is the projection to the equivalence class:\r\n          \\(\\pi_\\sim(a)=[a]_\\sim\\).\r\n        </p>\r\n        <p>\r\n          How do we know {\"\\\\(\\\\tilde{f}\\\\)\"} exists, let alone is unique? As\r\n          the diagram must commute, given any{\" \"}\r\n          {\"\\\\(\\\\tilde{f}: A/\\\\!\\\\!\\\\sim\\\\longrightarrow B\\\\)\"} we must have{\" \"}\r\n          {\"\\\\(\\\\tilde{f}\\\\circ\\\\pi_\\\\sim(a)=f(a)\\\\)\"} for all \\(a\\in A\\), and\r\n          so {\"\\\\(\\\\tilde{f}\\\\)\"} is forced to be \\([a]_\\sim\\mapsto f(a)\\). This\r\n          is well-defined, recalling our definition of \\(\\sim\\). In recognition\r\n          of the fact that this map is unique and can be deduced from any\r\n          arbitrary set-map, we say that this quotient, \\(A/\\!\\!\\sim\\),\r\n          satisfies a <strong>universal property</strong> in a particular\r\n          category.\r\n        </p>\r\n        <p>\r\n          What is a <strong>category</strong>? It is just a collection of\r\n          objects and <strong>morphisms</strong> between them, which are just\r\n          ways to send one object to another. There are also a few checkmarks to\r\n          glance over (such as existence of an identity and composition) to make\r\n          sure your morphisms behave well, however they are not too important\r\n          for us to formally cover. Above, for example, our objects are the\r\n          ordered pair \\((B,f)\\) where \\(B\\) is a set and \\(f\\) is a map\r\n          \\(A\\longrightarrow B\\); it is much cleaner to write them as a diagram\r\n        </p>\r\n        <Diagram src={svg2} />\r\n        <p>\r\n          A morphism between two objects \\((B,f)\\) and \\((C,g)\\) must then be\r\n          some way to transform the map \\(f:A\\longrightarrow B\\) to\r\n          \\(g:A\\longrightarrow C\\). This can be done by any map\r\n          \\(j:B\\longrightarrow C\\) such that \\(j\\circ f = g\\); lucidity can be\r\n          found by thinking of \\(j\\) as a morphism \"between diagrams\", meaning\r\n          the following commutes:\r\n        </p>\r\n        <Diagram src={svg3} />\r\n        <p>\r\n          Note that we are not guaranteed to have such a \\(j\\) to exist.\r\n          However, this diagram seems awfully suspicious to the one involving\r\n          quotients at the very beginning, and that is because one does exist\r\n          there. In fact we say \\(A/\\!\\!\\sim\\) (or rather, the diagram\r\n          represented by \\((A/\\!\\!\\sim,\\pi_\\sim)\\)) is <strong>initial</strong>{\" \"}\r\n          in this category, because there exists a unique morphism from it to\r\n          any other object.\r\n        </p>\r\n        <p>\r\n          Now, with the concept of universal properties clarified, one can\r\n          consider the canonical decomposition of our original map \\(f\\), which\r\n          is the commutative diagram\r\n        </p>\r\n        <Diagram src={svg4} />\r\n        <p>\r\n          From here, much of the work in proving the isomorphism theorems is\r\n          done. Indeed, this is because groups and rings all have underlying\r\n          sets, and we can restrict ourselves by ensuring \\(f\\) is a\r\n          homomorphism, as that is just a set-map which preserves the\r\n          artificially-imposed structure. The formal way to do this is to work\r\n          in a separate category, such as {\"\\\\(\\\\mathbf{Grp}\\\\)\"}, whose objects\r\n          are groups and morphisms are group homomorphisms - precisely these\r\n          structure-preserving set-maps. Once in this domain, define the\r\n          quotient and prove it is initial again, and we can see why the first\r\n          isomorphism theorem holds instantly, as if \\(f\\) is a surjective\r\n          homomorphism then {\"\\\\(\\\\mathrm{im}\\\\,f = B\\\\)\"}. Note that I didn't\r\n          even specify what type of homomorphism \\(f\\) was; the reasoning holds\r\n          identically for groups, rings, and modules. The remaining theorems\r\n          just aim to construct such a surjective \\(f\\).\r\n        </p>\r\n        <p>\r\n          Above, however, is a massive asterisk. It is not always\r\n          straightforward to define \\(\\sim\\). For example, in{\" \"}\r\n          {\"\\\\(\\\\mathbf{Grp}\\\\)\"} we cannot merely take a subgroup, but must\r\n          also insist it is normal. Meanwhile in {\"\\\\(\\\\mathbf{Ring}\\\\)\"}, we\r\n          don't even bother with subrings, and instead provide the (rather\r\n          obtuse, if you arrive directly from subgroups) definition of an ideal.\r\n          This is where my suspicion mentioned at the beginning was inlaid - is\r\n          there any relationship between these quotients? Although algebra is\r\n          often tautological in this way, with definitions being nice to work\r\n          with because the definitions were changed until they were (c.f. the\r\n          word \"normal\" appearing everywhere), it seemed too coincidental that a\r\n          quotient could always be found, regardless of what structure was\r\n          imposed. My suspicion lasted merely a few minutes, however, because\r\n          the simple query \"isomorphism theorems\" immediately led to the answer\r\n          - universal algebra.\r\n        </p>\r\n        <p>\r\n          Universal algebra begins by recognizing that all of these different\r\n          structures boil down to two things - a set with operations. In\r\n          particular, we call \\(f\\) an \\(n\\)-<strong>ary operation</strong> on a\r\n          set \\(A\\) if \\(f:A^n\\longrightarrow A\\). Then, we define a{\" \"}\r\n          <strong>type</strong> to be a set{\" \"}\r\n          {\"\\\\(\\\\mathfrak{F}=\\\\left\\\\{(f_1,n_1),(f_2,n_2),\\\\dots\\\\right\\\\}\\\\)\"}{\" \"}\r\n          where each \\(f_i\\) is called an \\(n_i\\)-\r\n          <strong>ary operation symbol</strong>. Be aware that the subscript\r\n          will be dropped if distinguishing it from another symbol is not of\r\n          concern. An <strong>algebra</strong> {\"\\\\(\\\\mathcal{A}\\\\)\"} of type{\" \"}\r\n          {\"\\\\(\\\\mathfrak{F}\\\\)\"} is just an ordered pair \\((A,F)\\) where \\(A\\)\r\n          is a set and \\(F\\) is a set of \\(n\\)-ary operations so that for each\r\n          \\(n_i\\)-ary operation symbol {\"\\\\(f_i\\\\in\\\\mathfrak{F}\\\\)\"}, there is\r\n          a corresponding \\(n_i\\)-ary operation {\"\\\\(f_i^\\\\mathcal{A}\\\\in F\\\\)\"}\r\n          . We call \\(A\\) the <strong>universe</strong> of{\" \"}\r\n          {\"\\\\(\\\\mathcal{A}\\\\)\"} and \\(F\\) its{\" \"}\r\n          <strong>fundamental operations</strong>.\r\n        </p>\r\n        <p>\r\n          For example, an algebra {\"\\\\(\\\\mathcal{G}\\\\)\"} of type{\" \"}\r\n          {\"\\\\(\\\\mathfrak{F}=\\\\left\\\\{(1,0),(^{-1},1),(\\\\cdot,2)\\\\right\\\\}\\\\)\"}{\" \"}\r\n          is an ordered pair \\((G,F)\\) with \\(G\\) any set and \\(F\\) a set\r\n          containing a nullary (‽), unary, and binary operation on \\(G\\). What\r\n          is a nullary operation? It must be an operation which returns\r\n          something despite taking in no inputs - in other words, a constant\r\n          function. We write {\"\\\\(\\\\mathcal{G}=(G,1,^{-1},\\\\cdot)\\\\)\"} to\r\n          consolidate our operations in \\(F\\) with the symbols in{\" \"}\r\n          {\"\\\\(\\\\mathfrak{F}\\\\)\"}. We call {\"\\\\(\\\\mathcal{G}\\\\)\"} a{\" \"}\r\n          <strong>group</strong> if\r\n          {`\r\n                    \\\\[\r\n                    \\\\begin{aligned}\r\n                    &\\\\cdot (1,x)=x=\\\\cdot\\\\,(x,1);\\\\\\\\\r\n                    &\\\\cdot(x,^{-1}\\\\!(x))=1=\\\\cdot\\\\,(^{-1}\\\\!(x),x);\\\\\\\\\r\n                    &\\\\cdot(x,y\\\\cdot z)=\\\\cdot\\\\,(x\\\\cdot y,z).\r\n                    \\\\end{aligned}\r\n                    \\\\]\r\n                    `}\r\n        </p>\r\n        <p>\r\n          This is all looks quite cumbersome when written strictly treating\r\n          these operations as functions. Thankfully, by taking liberty with the\r\n          operation symbols, and giving the element to which \\(1\\) maps a rather\r\n          suggestive symbol like \\(e\\), we can intuitively rewrite this as\r\n          {`\r\n                    \\\\[\r\n                        \\\\begin{aligned}\r\n                        &e\\\\cdot x=x=x\\\\cdot e;\\\\\\\\\r\n                        &x\\\\cdot x^{-1}=e=x^{-1}\\\\cdot x;\\\\\\\\\r\n                        &x\\\\cdot(y\\\\cdot z)=(x\\\\cdot y)\\\\cdot z.\r\n                        \\\\end{aligned}\r\n                    \\\\]\r\n                    `}\r\n          This is all very familiar - after all, it is just a group. However,\r\n          note that we have fully described it without using any quantifying\r\n          symbols. For example, the existence of an identity isn't denoted by\r\n          \"For all {\"\\\\(x\\\\in\\\\mathcal{G}\\\\)\"}...\", but rather a consequence of\r\n          an operation and how it interacts with other operations.\r\n        </p>\r\n        <p>\r\n          What might our subgroups look like? We know we need them to behave\r\n          like a regular algebra on their own, but also be identified within its\r\n          parent. So, for two algebras {\"\\\\(\\\\mathcal{A}=(A,F_A)\\\\)\"} and{\" \"}\r\n          {\"\\\\(\\\\mathcal{B}=(B,F_B)\\\\)\"} of type {\"\\\\(\\\\mathfrak{F}\\\\)\"}, we say\r\n          that {\"\\\\(\\\\mathcal{B}\\\\)\"} is a <strong>subalgebra</strong> of{\" \"}\r\n          {\"\\\\(\\\\mathcal{A}\\\\)\"} if its universe is a{\" \"}\r\n          <strong>subuniverse</strong> of {\"\\\\(\\\\mathcal{A}\\\\)\"}, meaning\r\n          \\(B\\subseteq A\\) and \\(B\\) is closed under \\(F_A\\), and the operations\r\n          on {\"\\\\(\\\\mathcal{B}\\\\)\"} can be recovered by restricting the ones on{\" \"}\r\n          {\"\\\\(\\\\mathcal{A}\\\\)\"}, meaning\r\n          {`\r\n                    \\\\[\r\n                        f^\\\\mathcal{B}_i(b_1,\\\\cdots,b_n)=f^\\\\mathcal{A}_i\\\\vert_\\\\mathcal{B}(b_1,\\\\dots,b_n)\r\n                    \\\\]\r\n                    `}\r\n          for all {\"\\\\(f^\\\\mathcal{B}_i\\\\in F_B\\\\)\"} and{\" \"}\r\n          {\"\\\\(f^\\\\mathcal{A}_i\\\\in F_A\\\\)\"}.\r\n        </p>\r\n        <p>\r\n          Now, take an algebra {\"\\\\(\\\\mathcal{A}=(A,F)\\\\)\"} of type{\" \"}\r\n          {\"\\\\(\\\\mathfrak{F}\\\\)\"}. Let \\(\\sim\\) be an equivalence relation on{\" \"}\r\n          {\"\\\\(\\\\mathcal{A}\\\\)\"}. It is important that we recall the set\r\n          definition of an equivalence relation:\r\n          {`\r\n                    \\\\[\r\n                        \\n\\\\sim\\\\,=\\\\left\\\\{(a,b)\\\\in A\\\\times A: \\\\mathrm{ (1), (2), (3)}\\\\right\\\\}\\n\r\n                    \\\\]\\n\r\n                    \\\\[\r\n                        \\n a\\\\in A\\\\Rightarrow (a,a)\\\\in A;\\n\r\n                    \\\\]\\n\r\n                    \\\\[ \r\n                        \\n(a,b),(b,c)\\\\in A\\\\Rightarrow (a,c)\\\\in A;\\n\r\n                    \\\\]\\n\r\n                    \\\\[\r\n                        \\n(a,b)\\\\in A\\\\Rightarrow (b,a)\\\\in A.\\n\r\n                    \\\\] \r\n                    `}\r\n          We call \\(\\sim\\) a <strong>congruence</strong> on{\" \"}\r\n          {\"\\\\(\\\\mathcal{A}\\\\)\"} if given any \\(n\\)-ary{\" \"}\r\n          {\"\\\\(f\\\\in\\\\mathfrak{F}\\\\)\"} and for all \\(1\\leq i\\leq n\\), we have\r\n          {`\r\n                    \\\\[\\na_i\\\\sim b_i\\\\Rightarrow f^\\\\mathcal{A}(a_1,\\\\dots,a_n)\\\\sim f^\\\\mathcal{A}(b_1,\\\\dots,b_n).\\n\\\\]\r\n                    `}\r\n          The definition of congruence is reminiscent of normal subgroups. The\r\n          set of all congruences on {\"\\\\(\\\\mathcal{A}\\\\)\"} is denoted{\" \"}\r\n          {\"\\\\(\\\\mathrm{Con}\\\\,\\\\mathcal{A}\\\\)\"}. An element of this that we\r\n          will need in the distant future is \\(\\nabla_A=A\\times A\\), called the{\" \"}\r\n          <strong>all relation</strong>.\r\n        </p>\r\n        <p>\r\n          Naturally then, we go on to define quotients. For any \\(a\\in A\\) we\r\n          call the equivalence class under \\(\\sim\\) the set\r\n          {`\\\\[\\na/\\\\!\\\\!\\\\sim\\\\,=\\\\left\\\\{b\\\\in\\\\mathcal{A}:a\\\\sim b\\\\right\\\\}\\n\\\\]`}\r\n          and then we denote quotient of \\(A\\) by \\(\\sim\\) to be\r\n          {\r\n            \"\\\\[\\nA/\\\\!\\\\!\\\\sim\\\\,=\\\\left\\\\{a/\\\\!\\\\!\\\\sim:a\\\\in A\\\\right\\\\}.\\n\\\\]\"\r\n          }\r\n        </p>\r\n        <p>\r\n          Note that for the above, congruencey isn't important at all. Any\r\n          equivalence relation will do. However, to define an algebra with\r\n          universe \\(A/\\!\\!\\sim\\) that carries over the operations from{\" \"}\r\n          {\"\\\\(\\\\mathcal{A}\\\\)\"}, we need the following to be well-defined:\r\n          {\r\n            \"\\\\[\\nf^{\\\\mathcal{A}/\\\\sim}(a_1/\\\\!\\\\!\\\\sim,\\\\dots,a_n/\\\\!\\\\!\\\\sim)=f^\\\\mathcal{A}(a_1,\\\\dots,a_n)/\\\\!\\\\!\\\\sim.\\n\\\\]\"\r\n          }\r\n          Indeed, congruences let us achieve that. We then say the quotient\r\n          algebra of {\"\\\\(\\\\mathcal{A}\\\\)\"} by \\(\\sim\\),{\" \"}\r\n          {\"\\\\(\\\\mathcal{A}/\\\\!\\\\!\\\\sim\\\\)\"}, is the algebra\r\n          \\((A/\\!\\!\\sim,F_\\sim)\\) where \\(F_\\sim\\) is simply the set operations\r\n          gained after performing the above for all \\(f\\in F\\). Note that{\" \"}\r\n          {\"\\\\(\\\\mathcal{A}/\\\\!\\\\!\\\\sim\\\\)\"} is clearly also an algebra of type{\" \"}\r\n          {\"\\\\(\\\\mathfrak{F}\\\\)\"}. Of note is that quotients, in a sense,\r\n          preserve inclusions:\r\n        </p>\r\n        <Theorem\r\n          no=\"1\"\r\n          statement=\"\r\n                Let \\(\\sim_1,\\sim_2\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\) so that \\(\\sim_2\\,\\subseteq\\,\\sim_1\\). Then, \\(\\sim_1\\! /\\!\\sim_2\\) is a congruence on \\(\\mathcal{A}/\\!\\!\\sim_2\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Take some \\((\\alpha_i,\\beta_i)\\in\\sim_1\\!/\\!\\sim_2\\) for \\(1\\leq i\\leq n\\). Then, \\((\\alpha_i,\\beta_i)=(a_i/\\!\\!\\sim_2,b_i/\\!\\!\\sim_2)\\) where \\((a_i,b_i)\\in\\,\\sim_1\\). As \\(\\sim_1\\) is a congruence, we know for any \\(n\\)-ary \\(f\\), it holds that\r\n                \\[\r\n                    (f^\\mathcal{A}(a_1,\\dots,a_n),f^\\mathcal{A}(b_1,\\dots,b_n))\\in\\,\\sim_1\r\n                \\]\r\n                and so\r\n                \\[\r\n                \\begin{aligned}\r\n                    (f^\\mathcal{A}&(a_1,\\dots,a_n)/\\!\\!\\sim_2,f^\\mathcal{A}(b_1,\\dots,b_n)/\\!\\!\\sim_2)= \\\\\r\n                    &(f^{\\mathcal{A}/\\sim_2}(a_1/\\!\\!\\sim_2,\\dots,a_n/\\!\\!\\sim_2),f^{\\mathcal{A}/\\sim_2}(b_1/\\!\\!\\sim_2,\\dots,b_n/\\!\\!\\sim_2)\\in\\sim_1\\! /\\!\\!\\sim_2\r\n                \\end{aligned}\r\n                \\]\r\n                because \\(\\sim_2\\) is also a congruence. \"\r\n        />\r\n        <p>\r\n          The last thing we need is a way to communicate between different\r\n          algebras. This is done as one would expect. Given two algebras{\" \"}\r\n          {\"\\\\(\\\\mathcal{A}=(A,F_A)\\\\)\"} and {\"\\\\(\\\\mathcal{B}=(B,F_B)\\\\)\"} of\r\n          type {\"\\\\(\\\\mathfrak{F}\\\\)\"}, a map \\(\\alpha:A\\longrightarrow B\\) is\r\n          called an <strong>algebra homomorphism</strong> between{\" \"}\r\n          {\"\\\\(\\\\mathcal{A}\\\\)\"} and {\"\\\\(\\\\mathcal{B}\\\\)\"} if\r\n          {\r\n            \"\\\\[\\n\\\\alpha f_i^\\\\mathcal{A}(a_1,\\\\dots,a_n)=f_i^\\\\mathcal{B}(\\\\alpha a_1,\\\\dots,\\\\alpha a_n)\\n\\\\]\"\r\n          }\r\n          for every {\"\\\\(f_i\\\\in\\\\mathfrak{F}\\\\)\"}. We call a homomorphism an{\" \"}\r\n          <strong>isomorphism</strong> if the underlying map is bijective.\r\n        </p>\r\n        <p>\r\n          We immediately have a homomorphism at our disposal. First, we define\r\n          the <strong>natural map</strong> \\(\\nu_\\sim:A\\longrightarrow\r\n          A/\\!\\!\\sim\\) to be \\(a\\mapsto a/\\!\\!\\sim\\). We call the homomorphism\r\n          it induces the <strong>natural homomorphism</strong>. But is it\r\n          actually a homomorphism, or am I lying?\r\n        </p>\r\n        <Theorem\r\n          no=\"1\"\r\n          statement=\"\r\n                The natural map is a homomorphism from \\(\\mathcal{A}\\) to \\(\\mathcal{A}/\\!\\!\\sim\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Take some \\(n\\)-ary operation symbol \\(f\\) in type \\(\\mathfrak{F}\\) of \\(\\mathcal{A}\\) and \\(a_1,\\dots,a_n\\in A\\). Then,\r\n                \\[\r\n                    \\begin{aligned}\r\n                    \\nu_\\sim f^\\mathcal{A}(a_1,\\dots,a_n)&=f^\\mathcal{A}(a_1,\\dots,a_n)/\\!\\!\\sim\\\\\r\n                    &=f^{\\mathcal{A}/\\sim}(a_1/\\!\\!\\sim,\\dots,a_n/\\!\\!\\sim)\\\\\r\n                    &=f^{\\mathcal{A}/\\sim}(\\nu_\\sim a_1,\\dots,\\nu_\\sim a_n)\r\n                    \\end{aligned}\r\n                \\] \r\n                so indeed, my conscience is clean. \"\r\n        />\r\n        <p>\r\n          The <strong>kernel</strong> of a homomorphism has a definition that\r\n          seems slightly odd, however recall that we can't freely speak about\r\n          \"sending elements to zero\" or anything of the sort, since that hinges\r\n          on a specific choice of operations and identities. So, we instead\r\n          define it as\r\n          {\r\n            \"\\\\[\\n\\\\mathrm{ker}(\\\\alpha)=\\\\left\\\\{(a,b)\\\\in A\\\\times A: \\\\alpha(a)=\\\\alpha(b)\\\\right\\\\}.\\n\\\\]\"\r\n          }\r\n          Note that if we take this definition and return to our definition of a\r\n          group, for example, we quickly recover the usual definition of kernel.\r\n        </p>\r\n        <p>\r\n          Now, we have all the background we need to dig into the theorems.\r\n          First, we handle some grunt-work.\r\n        </p>\r\n        <Theorem\r\n          no=\"3\"\r\n          statement=\"\r\n                The kernel of a homomorphism \\(\\alpha:\\mathcal{A}\\longrightarrow\\mathcal{B}\\) is a congruence on \\(\\mathcal{A}\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Take some \\(n\\)-ary \\(f\\) and Let \\((a_i,b_i)\\in\\mathrm{ker}\\,\\alpha\\) for \\(1\\leq i\\leq n\\). Then,\r\n                \\[\r\n                    \\begin{aligned}\r\n                    \\alpha f^\\mathcal{A}(a_1,\\dots,a_n)&=f^\\mathcal{B}(\\alpha a_1,\\dots,\\alpha a_n)\\\\\r\n                    &=f^\\mathcal{B}(\\alpha b_1,\\dots,\\alpha b_n)\\\\\r\n                    &=\\alpha f^\\mathcal{A}(b_1,\\dots,b_n)\r\n                    \\end{aligned}\r\n                \\]\r\n                meaning \\((f^\\mathcal{A}(a_1,\\dots,a_n),f^\\mathcal{A}(b_1,\\dots,b_n))\\in\\mathrm{ker}\\,\\alpha\\).\"\r\n        />\r\n        <Theorem\r\n          no=\"4\"\r\n          statement=\"\r\n                Given homomorphisms \\(\\alpha:\\mathcal{A}\\longrightarrow\\mathcal{B}\\) and \\(\\beta:\\mathcal{B}\\longrightarrow\\mathcal{C}\\), the composition of the set-maps \\(\\beta\\circ\\alpha:A\\longrightarrow C\\) is a homomorphism from \\(\\mathcal{B}\\) to \\(\\mathcal{C}\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Take some \\(n\\)-ary \\(f\\), and let \\(a_1,\\dots,a_n\\in A\\). Then,\r\n                \\[\r\n                    \\begin{aligned}\r\n                    \\beta\\circ\\alpha f^\\mathcal{A}(a_1,\\dots,a_n)&=\\beta(\\alpha   f^\\mathcal{A}(a_1,\\dots,a_n))\\\\\r\n                    &=\\beta f^\\mathcal{B}(\\alpha a_1,\\dots,\\alpha a_n)\\\\\r\n                    &=f^\\mathcal{C}(\\beta(\\alpha a_1),\\dots,\\beta(\\alpha a_n))\\\\\r\n                    &=f^\\mathcal{C}(\\beta\\circ\\alpha a_1,\\dots,\\beta\\circ\\alpha a_n)\r\n                    \\end{aligned}\r\n                \\]\r\n                as desired. \"\r\n        />\r\n        <p>Now, we tackle the first big result.</p>\r\n        <Theorem\r\n          no=\"5\"\r\n          name=\"First Isomorphism Theorem (FIT)\"\r\n          statement=\"\r\n                If \\(\\alpha:\\mathcal{A}\\longrightarrow\\mathcal{B}\\) is a surjective homomorphism, then there exists an isomorphism from \\(\\mathcal{A}/\\mathrm{ker}\\,\\alpha\\) to \\(\\mathcal{B}\\). In particular, this isomorphism is defined by \\(a_{\\mathrm{ker}\\,\\alpha}\\mapsto\\alpha a\\).\r\n                \"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Let \\(\\beta:A/\\mathrm{ker}\\,\\alpha\\longrightarrow B\\) be the above mapping. Given some \\(b\\in B\\), we know there exists some \\(a\\in A\\) so that \\(\\alpha a=b\\), by hypothesis. Then, \\(\\beta a_{\\mathrm{ker}\\,\\alpha}=b\\), so our map is surjective. Suppose now we have \\(\\beta a_{\\mathrm{ker}\\,\\alpha} =\\beta a'_{\\mathrm{ker}\\,\\alpha} \\). Thus, \\(\\alpha a=\\alpha a'\\), however this means \\((a,a')\\in\\mathrm{ker}\\,\\alpha\\), and thus \\( a_{\\mathrm{ker}\\alpha}=a'_{\\mathrm{ker}\\,\\alpha}\\), so our map is injective.\\[\\]\r\n                We just need to verify \\(\\beta\\) plays nice with our operations. So, take some \\(n\\)-ary \\(f\\) and \\(a_1,\\dots,a_n\\in A\\), and we see\r\n                \\[\r\n                    \\begin{aligned}\r\n                    \\beta(f^{\\mathcal{A}/\\mathrm{ker}\\,\\alpha}(a_1/\\mathrm{ker}\\,\\alpha,\\dots,a_n/\\mathrm{ker}\\,\\alpha))&=\\beta(f^\\mathcal{A}(a_1,\\dots,a_n)/\\mathrm{ker}\\,\\alpha)\\\\\r\n                    &=\\alpha f^\\mathcal{A}(a_1,\\dots,a_n)\\\\\r\n                    &=f^\\mathcal{B}(\\alpha a_1,\\dots,\\alpha a_n)\\\\\r\n                    &=f^\\mathcal{B}(\\beta(a_1/\\mathrm{ker}\\,\\alpha),\\dots,\\beta(a_n/\\mathrm{ker}\\,\\alpha))\r\n                    \\end{aligned}\r\n                \\]\r\n                so \\(\\beta\\) is indeed a homomorphism.\"\r\n        />\r\n        <p>\r\n          Using (2) and (4), we opt to write \\(\\alpha=\\beta\\circ\\nu_\\sim\\) to\r\n          encapsulate the definition of \\(\\beta\\). Next, we recall (1) from the\r\n          very beginning, and out-of-order tackle the third theorem:\r\n        </p>\r\n        <Theorem\r\n          no=\"6\"\r\n          name=\"Third Isomorphism Theorem\"\r\n          statement=\"\r\n                If \\(\\sim_1,\\sim_2\\,\\in\\mathrm{Con}\\,A\\) with \\(\\sim_2\\,\\subseteq\\,\\sim_1\\), then\r\n                \\[\r\n                    \\alpha:\\frac{A/\\!\\!\\sim_2}{\\sim_1\\! /\\!\\!\\sim_2}\\longrightarrow A/\\!\\!\\sim_1\\quad\\mathrm{by}\\quad \\frac{a/\\!\\!\\sim_2}{\\sim_1\\! /\\!\\!\\sim_2}\\mapsto a/\\!\\!\\sim_1\r\n                \\]\r\n                is an isomorphism from \\(\\frac{\\mathcal{A}/\\sim_2}{\\sim_1 /\\sim_2}\\) to \\(\\mathcal{A}/\\!\\!\\sim_1\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Consider the map \\(\\alpha':A/\\!\\!\\sim_2\\longrightarrow A/\\!\\!\\sim_1\\) defined by \\(a/\\!\\!\\sim_2\\,\\mapsto a/\\!\\!\\sim_1\\). We see that this is well-defined, for if \\(a/\\!\\!\\sim_2=b/\\!\\!\\sim_2\\), then \\((a,b)\\in\\sim_2\\), and by inclusion, \\((a,b)\\in\\,\\sim_1\\) so \\(a/\\!\\!\\sim_1=b/\\!\\!\\sim_1\\). Now, take any \\(a/\\!\\!\\sim_1\\,\\in A/\\!\\!\\sim_1\\), and it clear that \\(\\alpha'(a/\\!\\!\\sim_2)\\) reaches this element. Thus, \\(\\alpha'\\) is surjective.\\[\\]\r\n                Take now any \\(n\\)-ary \\(f\\), and \\(a_1/\\!\\!\\sim_2,\\dots,a_n/\\!\\!\\sim_2\\,\\in A/\\!\\!\\sim_2\\). We see\r\n                \\[\r\n                    \\begin{aligned}\r\n                    \\alpha'f^{\\mathcal{A}/\\sim_2}(a_1/\\!\\!\\sim_2,\\dots,a_n/\\!\\!\\sim_2)&=\\alpha'(f^\\mathcal{A}(a_1,\\dots,a_n)/\\!\\!\\sim_2)\\\\\r\n                    &=f^\\mathcal{A}(a_1,\\dots,a_n)/\\!\\!\\sim_1\\\\\r\n                    &=f^{\\mathcal{A}/\\sim_1}(a_1/\\!\\!\\sim_1,\\dots,a_n/\\!\\!\\sim_1)\\\\\r\n                    &=f^{\\mathcal{A}/\\sim_1}(\\alpha'(a_1/\\!\\!\\sim_2),\\dots,\\alpha'(a_n/\\!\\!\\sim_2))\r\n                    \\end{aligned}\r\n                \\]\r\n                so this is actually a homomorphism as well. Now, take note that\r\n                \\[\r\n                    \\begin{aligned}\r\n                    \\mathrm{ker}\\,\\alpha'&=\\left\\{(a/\\!\\!\\sim_2,b/\\!\\!\\sim_2)\\in (A/\\!\\!\\sim_2)^2:\\alpha'(a/\\!\\!\\sim_2)=\\alpha'(b/\\!\\!\\sim_2)\\right\\}\\\\\r\n                    &=\\left\\{(a/\\!\\!\\sim_2,b/\\!\\!\\sim_2)\\in (A/\\!\\!\\sim_2)^2:a/\\!\\!\\sim_1=b/\\!\\!\\sim_1\\right\\}\\\\\r\n                    &=\\left\\{(a/\\!\\!\\sim_2,b/\\!\\!\\sim_2)\\in (A/\\!\\!\\sim_2)^2:(a,b)\\in\\sim_1\\right\\}\\\\\r\n                    &=\\,\\sim_1\\! /\\!\\!\\sim_2\r\n                    \\end{aligned}\r\n                \\]\r\n                so by (FIT),\r\n                \\[\r\n                    \\frac{A/\\!\\!\\sim_2}{\\sim_1\\! /\\!\\!\\sim_2}\\cong A/\\!\\!\\sim_1 \r\n                \\]\r\n                and we see indeed taking \\(\\alpha'=\\alpha\\circ\\nu_{\\sim_1/\\sim_2}\\) gives the claimed mapping.\"\r\n        />\r\n        <p>\r\n          We now need one more definition. Take an algebra{\" \"}\r\n          {\"\\\\(\\\\mathcal{A}\\\\)\"} and take any \\(B\\subseteq A\\). Then, we define\r\n          {\r\n            \"\\\\[\\n\\\\bigcap\\\\left\\\\{X:B\\\\subseteq X\\\\mathrm{\\\\ and\\\\ }X\\\\mathrm{\\\\ is\\\\ a\\\\ subuniverse\\\\ of\\\\ }\\\\mathcal{A}\\\\right\\\\}\\n\\\\]\"\r\n          }\r\n          to be the <strong>subuniverse generated</strong> by \\(B\\). It is clear\r\n          this induces a subalgebra, notably the{\" \"}\r\n          <strong>subalgebra generated</strong> by \\(B\\). We are interested in\r\n          one particular instance of this. Let{\" \"}\r\n          {\"\\\\(\\\\sim\\\\,\\\\in\\\\mathrm{Con}\\\\,\\\\mathcal{A}\\\\)\"}. Define for\r\n          \\(B\\subseteq A\\) the set\r\n          {\r\n            \"\\\\[B^\\\\sim=\\\\left\\\\{a\\\\in A:B\\\\cap a/\\\\!\\\\!\\\\sim\\\\,\\\\neq\\\\varnothing\\\\right\\\\}.\\\\]\"\r\n          }\r\n          We denote {\"\\\\(\\\\mathcal{B}^\\\\sim\\\\)\"} to be the subalgebra generated\r\n          by \\(B^\\sim\\). If we have a subalgebra {\"\\\\(\\\\mathcal{B}=(B,F)\\\\)\"},\r\n          then we write {\"\\\\(\\\\mathcal{B}^\\\\sim\\\\)\"} to describe this process on\r\n          \\(B\\). Of note is that in this case our generated subalgebra does not\r\n          grow:\r\n        </p>\r\n        <Theorem\r\n          no=\"7\"\r\n          statement=\"\r\n                 If \\(\\mathcal{B}\\) is a subalgebra of \\(\\mathcal{A}\\) and \\(\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\), then the universe of \\(\\mathcal{B}^\\sim\\) is \\(B^\\sim\\).\r\n                \"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Take some \\(n\\)-ary \\(f\\). Take any \\(a_1,\\dots,a_n\\in B^\\sim\\). By definition of \\(B^\\sim\\), there is some \\(b_i\\in B\\) so that \\((a_i,b_i)\\in\\,\\sim\\) for \\(1\\leq i\\leq n\\). Thus,\r\n                \\[\r\n                    (f^\\mathcal{A}(a_1,\\dots,a_n),f^\\mathcal{A}(b_1,\\dots,b_n))\\in\\,\\sim\r\n                \\]\r\n                but this means \\(f^\\mathcal{A}(a_1,\\dots,a_n)\\in B^\\sim\\). We know \\(B^\\sim\\) is a subset of our universe, however we have just showed that \\(B^\\sim\\) is a subuniverse of \\(A\\), and therefore will generate itself. Thus, our universe is indeed \\(\\mathcal{B}^\\sim\\).\"\r\n        />\r\n        <p>\r\n          Denote for a congruence \\(\\sim\\) on {\"\\\\(\\\\mathcal{A}\\\\)\"} the{\" \"}\r\n          <strong>restriction</strong> of \\(\\sim\\) to \\(B\\subseteq A\\) to be the\r\n          set \\(\\sim\\!\\vert_B=\\,\\sim\\cap\\,(B\\times B)\\). If \\(B\\) is a\r\n          subuniverse, then this is clearly a congruence \\((B,F_B)\\).\r\n        </p>\r\n        <Theorem\r\n          no=\"8\"\r\n          name=\"Second Isomorphism Theorem\"\r\n          statement=\"\r\n                If \\(\\mathcal{B}\\) is a subalgebra of \\(\\mathcal{A}\\) and \\(\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\), then \\(\\mathcal{B}/\\!\\!\\sim\\!\\vert_B\\cong\\mathcal{B}^\\sim\\! /\\!\\!\\sim\\!\\vert_{B^\\sim}\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Consider the map \\(\\alpha:\\mathcal{B}\\longrightarrow\\mathcal{B}^\\sim\\! /\\!\\!\\sim\\!\\vert_{B^\\sim}\\) defined by \\(b\\mapsto b/\\!\\!\\sim\\!\\vert_{B^\\sim}\\). This map is clearly well-defined. Now take some \\(n\\)-ary \\(f\\) and \\(b_1,\\dots,b_n\\in B\\) and we see\r\n                \\[\r\n                    \\begin{aligned}\r\n                    \\alpha f^\\mathcal{B}(b_1,\\dots,b_n)&=f^\\mathcal{B}(b_1,\\dots,b_n)/\\!\\!\\sim\\!\\vert_{B^\\sim}\\\\\r\n                    &=f^{\\mathcal{B}/\\sim\\vert_{B^\\sim}}(b_1/\\!\\!\\sim\\!\\vert_{B^\\sim},\\dots,b_n/\\!\\!\\sim\\!\\vert_{B^\\sim})\\\\\r\n                    &=f^{\\mathcal{B}/\\sim\\vert_{B^\\sim}}(\\alpha b_1,\\dots,\\alpha b_n)\r\n                    \\end{aligned}\r\n                \\]\r\n                and noting that because \\(\\mathcal{B}/\\!\\!\\sim\\!\\vert_{B^\\sim}\\) is clearly a subalgebra of \\(\\mathcal{B}^\\sim/\\!\\!\\sim\\!\\vert_{B^\\sim}\\), we can pull our operation up, thus showing \\(\\alpha\\) is a homomorphism. Now, take some \\(b/\\!\\!\\sim\\!\\vert_{B^\\sim}\\in B^\\sim\\! /\\!\\!\\sim\\!\\vert_{B^\\sim}\\). We know that there is some \\(b'\\in B\\) so that \\(b'\\sim b\\), by definition of \\(B^\\sim\\). Thus, \\(\\alpha b'=b/\\!\\!\\sim\\!\\vert_{B^\\sim}\\), meaning it is surjective.\\[\\]\r\n                Naturally, we proceed inspect the kernel of \\(\\alpha\\). As \r\n                \\[\r\n                    \\begin{aligned}\r\n                    \\mathrm{ker}\\,\\alpha&=\\left\\{(b,b')\\in B^2:\\alpha(b)=\\alpha(b')\\right\\}\\\\\r\n                    &=\\left\\{(b,b')\\in B^2 : b/\\!\\!\\sim\\!\\vert_{B^\\sim}=b'/\\!\\!\\sim\\!\\vert_{B^\\sim} \\right\\}\\\\\r\n                    &=\\left\\{(b,b')\\in B^2:(b,b')\\in\\,\\sim\\!\\vert_{B^\\sim}\\right\\}\r\n                    \\end{aligned}\r\n                \\]\r\n                and given \\(B\\subseteq B^\\sim\\), this means \\(\\mathrm{ker}\\,\\alpha=\\,\\sim\\!\\vert_B\\). Then, by (FIT), we are done.\"\r\n        />\r\n        <p>\r\n          That's the three covered! However, there is one more theorem which is\r\n          often presented alongside the isomorphism theorems - the\r\n          correspondence theorem - which I will include for completeness. This\r\n          is where the language of universal algebra takes a slight detour away\r\n          from the conventional language used in, say, group theory. We call a\r\n          non-empty set \\(L\\) endowed with two binary operations - \\(\\wedge\\) (\r\n          <strong>meet</strong>) and \\(\\vee\\) (<strong>join</strong>) - a\r\n          lattice if both meet and join are commutative and associative, along\r\n          with being <strong>idempotent</strong>, meaning \\[ x\\vee x = x\\qquad\r\n          x\\wedge x = x \\] and <strong>absorptive</strong>, meaning \\[\r\n          x\\vee(x\\wedge y)=x\\qquad x\\wedge(x\\vee y)=x. \\] A{\" \"}\r\n          <strong>sublattice</strong> is a non-empty subset of a lattice, closed\r\n          under meet and join.\r\n        </p>\r\n        <p>\r\n          A map \\(\\alpha:L\\longrightarrow S\\) where \\(L\\) and \\(S\\) are lattices\r\n          is called a <strong>lattice homomorphism</strong> if for \\(a,b\\in L\\),\r\n          \\[ \\alpha(a\\wedge_Lb)=\\alpha a\\wedge_S\\alpha b\\qquad\r\n          \\alpha(a\\vee_Lb)=\\alpha a\\vee_S\\alpha b. \\]\r\n        </p>\r\n        <p>\r\n          Next, we call a set \\(A\\) a <strong>partially-ordered set</strong> (\r\n          <strong>poset</strong>) if there exists a relation \\(\\leq\\) which is\r\n          reflexive and transitive, along with being{\" \"}\r\n          <strong>antisymmetric</strong>, meaning\r\n          {\"\\\\[a\\\\leq b\\\\mathrm{\\\\ and\\\\ } b\\\\leq a\\\\Rightarrow a=b.\\\\]\"}\r\n          We write \\((A,\\leq)\\). The only thing separating this from a{\" \"}\r\n          <strong>total-order</strong> (e.g. the usual definition of \\(\\leq\\) on{\" \"}\r\n          {\"\\\\(\\\\mathbb{N}\\\\)\"}) is that a partial-order does not guarantee\r\n          \\(a\\leq b\\) or \\(b\\leq a\\), in general. On posets, an{\" \"}\r\n          <strong>interval</strong> \\(\\left[a,b\\right]\\) or \\((a,b)\\),{\" \"}\r\n          <strong>supremum</strong>, and <strong>infimum</strong> are defined\r\n          exactly the same as they are for totally-ordered sets.\r\n        </p>\r\n        <p>\r\n          The reason posets are important is that every lattice has a natural\r\n          partial-order, namely writing \\(a\\leq b\\) if \\(a=a\\wedge b\\).\r\n          Verifying this is actually a partial-order is just symbol-pushing, so\r\n          I will not include it here.\r\n        </p>\r\n        <Theorem\r\n          no=\"9\"\r\n          statement=\"\r\n                Every interval of a lattice is a sublattice.\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Take \\([a,b]\\) to be our interval. Let \\(p,q\\in [a,b]\\). Then,\r\n                \\[\r\n                    a\\wedge (p\\wedge q)=(a\\wedge p)\\wedge q=a\\wedge q=a\r\n                \\]\r\n                so \\(a\\leq p\\wedge q\\). Similarly, \\(p\\wedge q\\leq b\\). Then,\r\n                \\[\r\n                    a\\wedge(p\\vee q)=a\\wedge((p\\vee (p\\wedge a))\\vee q)=a\\wedge((p\\vee a)\\vee q)=a\\wedge(a\\vee(p\\vee q))=a\r\n                \\]\r\n                meaning \\(a\\leq p\\vee q\\), and similarly \\(p\\vee q\\leq b\\). Thus, our interval is closed under both meet and join.\"\r\n        />\r\n        <p style={{ textIndent: \"0\" }}>\r\n          We write \\(\\llbracket a,b\\rrbracket\\) to describe this lattice.\r\n        </p>\r\n        <p>\r\n          Similar to how we take a lattice and impose an ordering, we can take a\r\n          poset and end up with a lattice by defining meet and join. In\r\n          particular, we take\r\n          {\r\n            \"\\\\[\\na\\\\wedge b=\\\\inf\\\\left\\\\{a,b\\\\right\\\\}\\\\qquad a\\\\vee b=\\\\sup\\\\left\\\\{a,b\\\\right\\\\}\\n\\\\]\"\r\n          }\r\n          and verifying these satisfy the conditions for meet and join is\r\n          straightforward. This all culminates into our final theorem,\r\n          discussing the lattice{\" \"}\r\n          {\"\\\\((\\\\mathrm{Con}\\\\,\\\\mathcal{A},\\\\subseteq)\\\\)\"}.\r\n        </p>\r\n        <Theorem\r\n          no=\"10\"\r\n          name=\"Correspondence Theorem\"\r\n          statement=\"\r\n                Let \\(\\mathcal{A}\\) be an algebra and let \\(\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\). Then,\r\n                \\[\r\n                    \\llbracket\\sim,\\nabla_A\\rrbracket\\cong\\mathrm{Con}\\,\\mathcal{A}/\\!\\!\\sim\r\n                \\]\r\n                as lattices under \\(\\subseteq\\) by \\(r\\mapsto r/\\!\\!\\sim\\)\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n                Let \\(\\alpha\\) denote this mapping. Take some \\(r,s\\in[\\sim,\\nabla_A]\\) so that \\(r\\neq s\\). Without loss of generality, take some \\(a,b\\in A\\) so that \\((a,b)\\in r\\setminus s\\). This means \\((a/\\!\\!\\sim,b/\\!\\!\\sim)\\in r/\\!\\!\\sim\\!\\setminus\\, s/\\!\\!\\sim\\) meaning \\(\\alpha r\\neq\\alpha s\\).\\[\\]\r\n                Now, take some congruence \\(r/\\!\\!\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}/\\!\\!\\sim\\). Let \\(s=\\mathrm{ker}(\\nu_r\\circ\\nu_\\sim)\\). We see that \r\n                \\[\r\n                    (a/\\!\\!\\sim,b/\\!\\!\\sim)\\in r/\\!\\!\\sim\\,\\Leftrightarrow (a,b)\\in s\\Leftrightarrow (a/\\!\\!\\sim,b/\\!\\!\\sim)\\in s/\\!\\!\\sim\r\n                \\]\r\n                meaning \\(\\alpha s=r\\). In total, our map is bijective.\\[\\]\r\n                Now take \\(r,s\\in[\\sim,\\nabla_A]\\). Without loss of generality, take \\(s\\subseteq r\\). It is clear \\(s/\\!\\!\\sim\\,\\subseteq r/\\!\\!\\sim\\). Thus, \\(\\alpha\\) preserves inclusions, meaning it preserves our induced meet and join, and thus is a lattice homomorphism too.\"\r\n        />\r\n        <p>\r\n          This took far longer than I thought it would. Going in, I assumed that\r\n          everything would be fairly simple and clean, in the same way the\r\n          proofs of the isomorphism theorems for specific structures are.\r\n          However, given the variation between ideals and normal subgroups that\r\n          I mentioned at the beginning, in hindsight I should have expected the\r\n          overarching notion (i.e. congruences) to not necessarily be the\r\n          friendliest or most familiar concept. Nonetheless, it is satisfying to\r\n          have my curiosity quenched, even if it was slightly confusing at\r\n          times.\r\n        </p>\r\n        <p>\r\n          I have read that, apparently, universal algebra is pretty dead in\r\n          terms of study today, supposedly having been subsumed into category\r\n          theory. Although I find the hedonistic study of category theory to be\r\n          quite sour, I will say that I find the category theory used in algebra\r\n          to be more interesting and cleaner than universal algebra. It also far\r\n          more powerful for identifying overarching ideas, whereas universal\r\n          algebra limits itself to strictly algebra, by definition. However, I\r\n          peeked into the end of Burris' and Sankappanavar's book and saw a\r\n          large ampersand used as an operator over some set, so I am going to\r\n          wager my freshman's opinion is quite ill-informed and there are deeper\r\n          reasons the field is not very active today (if that's even true at\r\n          all!).\r\n        </p>\r\n      </div>\r\n    );\r\n  }\r\n\r\n}\r\n\r\nexport default UniversalIsomorphism;","export default __webpack_public_path__ + \"static/media/svg1.68acb4a6.svg\";","export default __webpack_public_path__ + \"static/media/svg2.82d2c6f8.svg\";","export default __webpack_public_path__ + \"static/media/svg3.2f752a21.svg\";","export default __webpack_public_path__ + \"static/media/svg4.7f2d9061.svg\";","export default __webpack_public_path__ + \"static/media/svg5.c29c7486.svg\";","export default __webpack_public_path__ + \"static/media/svg6.90f4730c.svg\";","export default __webpack_public_path__ + \"static/media/svg7.6093a484.svg\";","export default __webpack_public_path__ + \"static/media/svg8.8c5b64af.svg\";","export default __webpack_public_path__ + \"static/media/fig1records.193c1ea7.png\";","import React, { Component } from \"react\";\r\n/* environments */\r\nimport Figure from \"../../../components/Figure\";\r\nimport Theorem from \"../../../components/Theorem\";\r\nimport Proof from \"../../../components/Proof\";\r\nimport Diagram from \"../../../components/Diagram\";\r\n/* diagrams */\r\nimport svg1 from \"./svg1.svg\";\r\nimport svg2 from \"./svg2.svg\";\r\nimport svg3 from \"./svg3.svg\";\r\nimport svg4 from \"./svg4.svg\";\r\nimport svg5 from \"./svg5.svg\";\r\nimport svg6 from \"./svg6.svg\";\r\nimport svg7 from \"./svg7.svg\";\r\nimport svg8 from \"./svg8.svg\";\r\n/* figures */\r\nimport Fig1GP from \"./fig1records.png\";\r\n\r\nclass StackOfRecords extends Component {\r\n    \r\n  componentDidMount() {\r\n    window.KaTeXRender();\r\n  }\r\n\r\n  render() {\r\n    return (\r\n      <div class=\"postContent leftMargin\">\r\n        <p>\r\n          Although Eratosthenes calculated the Earth's circumference around 250\r\n          B.C.E with a very small margin of error, it is hard to see the Earth\r\n          is round when simply standing outside. Even atop mountains and cliffs\r\n          facing out to the sea, the Earth seems quite flat. It is only when we\r\n          look at Earth as a whole that we see the curvature. In fact, this is\r\n          true of any ball-shaped object.\r\n        </p>\r\n        <p>\r\n          In mathematics, we call objects like this <strong>manifolds</strong>,\r\n          and say they are <strong>locally Euclidean</strong>. An important part\r\n          of being locally Euclidean is that there are no sudden jumps or cusps\r\n          or anything of the sort; the surface is smooth. Beginning with this\r\n          notion, we study <strong>smooth functions</strong>. Take $U$ as an\r\n          open subset of {\"$\\\\mathbb{R}^n$\"}. We say the map{\" \"}\r\n          {\"$f:U\\\\rightarrow\\\\mathbb{R}^m$\"} is smooth if it is{\" \"}\r\n          {\"$\\\\mathcal{C}^\\\\infty$\"}, or if it has continuous partial\r\n          derivatives of all orders. An example of this is{\" \"}\r\n          {\"$f:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}$\"} by $x\\mapsto x^3$. However,\r\n          suppose we had a function {\"$f:[0,1]\\\\rightarrow\\\\mathbb{R}$\"}. Our\r\n          $U$ in this case is not open. How do we talk about differentiation at\r\n          the points $x=0$ or $x=1$? Of course, we cannot; $f$ is not continuous\r\n          at these points and so is not differentiable. However, <i>should</i>{\" \"}\r\n          we be able to differentiate $f$? With \\(x\\mapsto x^3\\), the answer is\r\n          clearly yes. So, in the same way we complete {\"$\\\\mathbb{Q}$\"} with\r\n          Cauchy sequences which should converge, we say{\" \"}\r\n          {\"$f:U\\\\rightarrow\\\\mathbb{R}^m$\"} is smooth on a closed{\" \"}\r\n          {\"$U\\\\subseteq\\\\mathbb{R}^n$\"} if around every $u\\in U$ there exists\r\n          an open {\"$V\\\\subseteq\\\\mathbb{R}^n$\"} and a smooth{\" \"}\r\n          {\"$F:V\\\\rightarrow\\\\mathbb{R}^m$\"} such that{\" \"}\r\n          {\"$F\\\\vert_{V\\\\cap U}=f\\\\vert_{V\\\\cap U}$\"}. We call this $F$ a{\" \"}\r\n          <strong>smooth extension</strong> of $f$ at $x$.\r\n        </p>\r\n        <p>\r\n          With this idea of smoothness in mind we are almost ready to define\r\n          manifolds. The only obstacle is the ability to go to and from our\r\n          spaces. For example, $x\\mapsto x^3$ is smooth, however its inverse{\" \"}\r\n          {\"$y\\\\mapsto\\\\sqrt[3]{y}$\"} is not, as it is not differentiable at\r\n          $y=0$. We need to ensure we can take our manifold and straighten it\r\n          out locally, but also be able to undo that process by folding things\r\n          back up onto the manifold. This introduces{\" \"}\r\n          <strong>diffeomorphisms</strong>. A smooth map $f:X\\rightarrow Y$,\r\n          where $X$ and $Y$ are subsets of a Euclidean space, is called a\r\n          diffeomorphism if {\"$f^{-1}:Y\\\\rightarrow X$\"} is also smooth. We say\r\n          $X$ and $Y$ are diffeomorphic. A useful result follows.\r\n        </p>\r\n        <Theorem\r\n          no=\"1\"\r\n          statement=\"\r\n          The composition of diffeomorphisms is a diffeomorphism.\r\n          \"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n          Suppose we have diffeomorphisms $f:X\\rightarrow Y$ and $g:Y\\rightarrow Z$. Consider $g\\circ f:X\\rightarrow Z$. Let $x\\in X$. Given $f$ and $g$ are smooth we can find open neighborhoods $U$ of $x$ and $V$ of $f(x)$, as well as smooth extensions $F:U\\rightarrow Y$ and $G:V\\rightarrow Z$. Let $\\tilde{U}=U\\cap F^{-1}(V)$. Then note that\r\n          \\[\r\n            G\\circ F:\\tilde{U}\\rightarrow Z    \r\n          \\]\r\n          is smooth as it is defined on open sets. Furthermore, $(G\\circ F)\\vert_{X\\cap\\tilde{U}}=(g\\circ f)\\vert_{X\\cap\\tilde{U}}$ and is therefore our desired smooth extension. Applying the same technique to the inverses, we are done.\"\r\n        />\r\n        <p>\r\n          Now, we can define manifolds! Although there are ways to define\r\n          manifolds on abstract topological spaces, it is not necessary for our\r\n          discussion. So, we say {\"$X\\\\subseteq\\\\mathbb{R}^n$\"} is a $k$-\r\n          <strong>dimensional</strong> manifold (or $k$-manifold) if for each\r\n          $x\\in X$ there exists a diffeomorphism $\\varphi:U\\rightarrow V$ where\r\n          $V$ is an open set around $x$ in $X$ (as in, {\"$V=X\\\\cap\\\\tilde{V}$\"}{\" \"}\r\n          for some open {\"$\\\\tilde{V}\\\\subset\\\\mathbb{R}^n$\"}) and $U$ is an\r\n          open subset of {\"$\\\\mathbb{R}^k$\"}. We call a diffeomorphism going\r\n          this way (from a Euclidean space) a <strong>parametrization</strong>{\" \"}\r\n          of $X$ about $x$, and we call {\"$\\\\varphi^{-1}:V\\\\rightarrow U$\"}{\" \"}\r\n          <strong>local coordinates</strong> on $X$ about $x$. We usually write{\" \"}\r\n          {\"$\\\\varphi^{-1}=(x_1,\\\\cdots,x_k)$\"}, where each $x_i$ takes in an\r\n          element of $X$ and returns you a point in {\"$\\\\mathbb{R}$\"}, making it\r\n          clear how $X$ really is $k$-dimensional. In other words, $X$ is\r\n          diffeomorphic to {\"$\\\\mathbb{R}^k$\"}.\r\n        </p>\r\n        <Theorem\r\n          no=\"2\"\r\n          statement=\"\r\n        Every open ball in $\\mathbb{R}^n$ is diffeomorphic to $\\mathbb{R}^n$.\r\n        \"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        Let our $n$-ball of radius $r$ be denoted $\\mathcal{B}_r$. Define $f:\\mathcal{B}_r\\rightarrow\\mathbb{R}^n$ by\r\n        $$x\\mapsto\\frac{rx}{\\sqrt{r^2-\\|x\\|^2}}.$$\r\n        It is clear this map is smooth, as it is just multiple applications of (1). We also note the map $f^{-1}:\\mathbb{R}^n\\rightarrow\\mathcal{B}_r$ defined by\r\n        $$x\\mapsto\\frac{rx}{\\sqrt{r^2+\\|x\\|^2}}$$\r\n        is smooth and is the inverse of $f$, justifying our clever choice of name.\"\r\n        />\r\n        <p>\r\n          Using the above fact, whenever we parametrize a $k$-manifold $X$ by{\" \"}\r\n          {\"$\\\\varphi:U\\\\subseteq\\\\mathbb{R}^k\\\\rightarrow V\\\\subseteq X$\"}, we\r\n          will instead just take {\"$\\\\varphi:\\\\mathbb{R}^k\\\\rightarrow V$\"}, by\r\n          implicit composition. If the exact image of our parametrization is not\r\n          important (for instance, if we do not need to invert it), we will\r\n          write {\"\\\\(\\\\varphi:\\\\mathbb{R}^k\\\\rightarrow X\\\\)\"}.\r\n        </p>\r\n        <p>\r\n          One reason we impose all of these restrictions on manifolds is that\r\n          they are the perfect conditions to study spaces on which we can borrow\r\n          ideas from calculus. One of these is tangency. Just like how a\r\n          differentiable function {\"$f:\\\\mathbb{R}\\\\rightarrow\\\\mathbb{R}$\"} can\r\n          be locally approximated by its derivative, we can locally approximate\r\n          the potentially very complicated global behaviour of a manifold by its\r\n          derivative as well. Let {\"$X\\\\subseteq\\\\mathbb{R}^n$\"} be our\r\n          $k$-manifold, and let $x_0\\in X$. Take{\" \"}\r\n          {\"$\\\\varphi:\\\\mathbb{R}^k\\\\rightarrow X$\"} to be a parametrization\r\n          about $x_0$, and without loss of generality take $\\varphi(0)=x_0$. Its\r\n          derivative is\r\n          {\"$$d\\\\varphi_{x_0}:\\\\mathbb{R}^k\\\\rightarrow\\\\mathbb{R}^n.$$\"}\r\n          We call the image of {\"$d\\\\varphi_{x_0}$\"} our{\" \"}\r\n          <strong>tangent space</strong>, $T_xX$. Just as the line locally\r\n          approximating our function $f$ at $x_0$ is given by $f(x_0)+xf'(x)$,\r\n          our tangent space can be put on $X$ by{\" \"}\r\n          {\"$\\\\varphi(0)+d\\\\varphi_{x_0}x$\"}. In fact, we do not need to use all\r\n          of $X$; any open neighborhood around $x_0$ will do.\r\n        </p>\r\n        <p>\r\n          However, note we defined $T_xX$ with respect to a particular\r\n          parametrization. Thankfully, the tangent space is the same for all\r\n          parametrizations, as we will show.\r\n        </p>\r\n        <Theorem\r\n          no=\"3\"\r\n          statement=\"\r\n        The tangent space of a manifold is invariant under choice of parametrization.\r\n        \"\r\n        />\r\n        {/* i hate inserting diagrams into proofs now */}\r\n        <Proof\r\n          proof={\r\n            <span>\r\n              Suppose we have {\"$\\\\varphi:\\\\mathbb{R}^k\\\\rightarrow X$\"} and{\" \"}\r\n              {\"$\\\\psi:\\\\mathbb{R}^k\\\\rightarrow X$\"} both parametrizing $X$\r\n              about $x$, such that $\\varphi(x)=0=\\psi(x)$. Shrinking our domains\r\n              to some $U$ and $V$ in {\"\\\\(\\\\mathbb{R}^k\\\\)\"} if necessary, we\r\n              can make their images equal. Thus, <Diagram src={svg1} /> where{\" \"}\r\n              {\"$h=\\\\psi^{-1}\\\\circ\\\\varphi:U\\\\rightarrow V$\"} is a\r\n              diffeomorphism by (1). Then, we see $d\\varphi_0=d\\psi_0\\circ\r\n              dh_0$, so{\" \"}\r\n              {\"$d\\\\varphi_0(\\\\mathbb{R}^k)\\\\subseteq d\\\\psi_0(\\\\mathbb{R}^k)$\"}\r\n              , and the reverse direction shows their images are actually equal,\r\n              meaning the tangent space is identical regardless of\r\n              parametrization chosen.{\" \"}\r\n            </span>\r\n          }\r\n        />\r\n        <Theorem\r\n          no=\"4\"\r\n          statement=\"\r\n        If $X\\subseteq\\mathbb{R}^n$ is a $k$-manifold, then $\\mathrm{dim}\\,T_xX=k$ for all $x\\in X$.\r\n        \"\r\n        />\r\n        <Proof proof=\"Let $x\\in X$ and parametrize about it by $\\varphi$. Then, $\\varphi^{-1}\\circ\\varphi=\\mathrm{Id}$. Given $\\mathrm{Id}$ is linear, $d\\mathrm{Id}_0=\\mathrm{Id}$, so ordinary chain rule requires that $d\\varphi^{-1}_x\\circ d\\varphi_0=\\mathrm{Id}$. Therefore, $d\\varphi_0$ is bijective, so it is an isomorphism, and the dimension follows.\" />\r\n        <p>\r\n          Now that we know tangent spaces are well-defined, we begin to unveil\r\n          how powerful they are, by letting us learn a lot about manifolds from\r\n          relatively simple linear algebra. First, we must show they play nicely\r\n          with composition.\r\n        </p>\r\n        <Theorem\r\n          no=\"5\"\r\n          name=\"Chain Rule\"\r\n          statement=\"\r\n        With $j$-,$k$-, and $\\ell$-manifolds $X,Y,Z$ and smooth maps $f:X\\rightarrow Y$ and $g:Y\\rightarrow Z$,\r\n        $$d(g\\circ f)_x=dg_{f(x)}\\circ df_x.$$\r\n        \"\r\n        />\r\n        <Proof\r\n          proof={\r\n            <span>\r\n              Let $x\\in X$, and $y=f(x)$. Parametrize about $x$ and $y$ by\r\n              $\\varphi$ and $\\psi$, respectively. We again shrink their domains\r\n              as in (3) to $U$ and $V$, respectively, if need be. Taking\r\n              derivatives, we arrive at <Diagram src={svg2} /> suggesting{\" \"}\r\n              {\"$df_x=d\\\\psi_0\\\\circ dh_0\\\\circ d\\\\varphi^{-1}_0$\"}. Suppose\r\n              however we had a different parametrization about $x$, say\r\n              $\\varphi'$, whose domain is shrunk to $U'$. By (3), we have{\" \"}\r\n              <Diagram src={svg3} /> and so\r\n              {\r\n                \"$$d\\\\psi_0\\\\circ dh_0\\\\circ\\\\mathrm{Id}\\\\circ d(\\\\varphi')_0^{-1}= d\\\\psi_0\\\\circ dh_0\\\\circ d(\\\\varphi')_0^{-1}=d\\\\psi_0\\\\circ dh_0\\\\circ d\\\\varphi^{-1}_0=df_x$$\"\r\n              }\r\n              nonetheless, showing our choice does not matter. Applying the\r\n              above to <Diagram src={svg4} /> has the proof fall out\r\n              immediately.\r\n            </span>\r\n          }\r\n        />\r\n        <p>\r\n          There is one result that follows from this which will be particularly\r\n          useful later.\r\n        </p>\r\n        <Theorem\r\n          no=\"6\"\r\n          statement=\"\r\n        With $f:X\\rightarrow Y$ a diffeomorphism, $df_x$ is an isomorphism between their tangent spaces.\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        Let $x\\in X$, and $y=f(x)$. We know $f^{-1}\\circ f=\\mathrm{Id}$. By chain rule,\r\n        $$d(f^{-1}\\circ f)_x=\\mathrm{Id}=df^{-1}_y\\circ df_x$$\r\n        so in fact, $(df_x)^{-1}=df^{-1}_y$, and so it is an isomorphism.\"\r\n        />\r\n        <p>\r\n          Now that we know some basics about manifolds, as well as the basics\r\n          about maps between them, we can ask the question about whether a\r\n          transformation creates a manifold in the first place. Continuing with\r\n          the theme of differentiability, we define a{\" \"}\r\n          <strong>local diffeomorphism</strong>, which is exactly what it sounds\r\n          like. We call $f:X\\rightarrow Y$ a local diffeomorphism if around each\r\n          $x\\in X$ there exists an open neighborhood $U$ around $x$ which is\r\n          diffeomorphic to some neighborhood $V$ around $f(x)$. This is not an\r\n          empty definition, as a local diffeomorphism can very well not be an\r\n          actual diffeomorphism, perhaps failing to be bijective. An incredibly\r\n          powerful, and honestly shocking result applies to local\r\n          diffeomorphisms.\r\n        </p>\r\n        <Theorem\r\n          no=\"7\"\r\n          name=\"Inverse Function Theorem (IFT)\"\r\n          statement=\"\r\n        If $f:X\\rightarrow Y$ is smooth with $df_x$ an isomorphism, then $f$ is a local diffeomorphism at $x$.\"\r\n        />\r\n        <p>\r\n          The proof is far too long and outside the scope for this post. I\r\n          intend to soon (first learn about and then) write a separate post for\r\n          this theorem using the Banach Fixed-Point approach. Also, note the\r\n          relation to (6).\r\n        </p>\r\n        <Theorem\r\n          no=\"8\"\r\n          statement=\"\r\n        If $f:X\\rightarrow Y$ is smooth with $df_x$ an isomorphism,  then $f$ is locally equivalent to the identity at $x$.\"\r\n        />\r\n        <Proof\r\n          proof={\r\n            <span>\r\n              Parametrize about $x$ by $\\varphi$ and $y=f(x)$ by $\\psi$. Then,\r\n              we get <Diagram src={svg5} /> and differentiating gives{\" \"}\r\n              <Diagram src={svg6} /> Given we know $df_x$ is also an isomorphism\r\n              between $T_xX$ and $T_yY$, we know we can replace{\" \"}\r\n              {\"$d\\\\psi_0\\\\circ d\\\\varphi_x^{-1}$\"} with it. Then, by (7), we\r\n              can justify {\"$f=\\\\psi\\\\circ\\\\varphi^{-1}$\"} provided we\r\n              sufficiently shrink neighborhoods.\r\n            </span>\r\n          }\r\n        />\r\n        <p>\r\n          This is generally more useful for us than (7) is. To be more explicit\r\n          about what we have done here, we have actually given local coordinates\r\n          $(x_1,\\cdots,x_k)$ from {\"$\\\\varphi^{-1}$\"} such that\r\n          $f(x_1,\\cdots,x_k)=(x_1,\\cdots,x_k)$, and likewise for {\"$f^{-1}$\"}.\r\n          In a sense then, \\(X\\) and \\(Y\\) are the same manifold under a\r\n          different guise, because we do not have enough structure to\r\n          (meaningfully) differentiate between them. This is analogous two\r\n          different bases representing the same vector space. However, sometimes\r\n          our conditions are not this strong, but meaningful connections still\r\n          exist. For example, a subspace of a vector space is obviously related\r\n          to the vector space itself, even though we cannot biject their bases.\r\n          In the case of manifolds, this brings up the idea of{\" \"}\r\n          <strong>submersions</strong>.\r\n        </p>\r\n        <p>\r\n          When we have manifolds \\(X\\) and \\(Y\\) with \\(f:X\\rightarrow Y\\), but{\" \"}\r\n          {\"\\\\(k=\\\\mathrm{dim}\\\\,X\\\\geq\\\\mathrm{dim}\\\\,Y=\\\\ell\\\\)\"}, we cannot\r\n          have \\(df_x\\) for any \\(x\\in X\\) be a bijection between tangent spaces\r\n          unless the equality is actually met. However, we can have it be a\r\n          surjection, and in this case we call \\(f\\) a submersion.{\" \"}\r\n          <strong>The canonical submersion</strong> is just a projection, the\r\n          simplest of which being{\" \"}\r\n          {\"\\\\(\\\\pi:\\\\mathbb{R}^k\\\\rightarrow\\\\mathbb{R}^\\\\ell\\\\)\"} defined by\r\n          \\[ (x_1,\\dots,x_\\ell,\\dots,x_k)\\mapsto (x_1,\\dots,x_\\ell). \\] We will\r\n          use \\(\\pi_c\\) to represent the appropriate projection for the context.\r\n        </p>\r\n        <Theorem\r\n          no=\"9\"\r\n          name=\"Local Submersion Theorem\"\r\n          statement=\"\r\n        With \\(f:X\\rightarrow Y\\) a submersion at \\(x\\in X\\), \\(f\\) is locally equivalent to the canonical submersion.\"\r\n        />\r\n        <Proof\r\n          proof={\r\n            <span>\r\n              Appropriately parametrize to achieve the diagram{\" \"}\r\n              <Diagram src={svg7} /> We know{\" \"}\r\n              {\"\\\\(dg_0:\\\\mathbb{R}^k\\\\rightarrow\\\\mathbb{R}^\\\\ell\\\\)\"} to be\r\n              surjective, so for some basis it can be represented by the\r\n              \\(\\ell\\)-by-\\(k\\) block matrix{\" \"}\r\n              {\"\\\\(\\\\begin{pmatrix} I_\\\\ell & 0\\\\end{pmatrix}\\\\)\"}, where\r\n              \\(I_\\ell\\) is the \\(\\ell\\)-square identity. In order to apply (8),\r\n              we need bijectivity, so we define{\" \"}\r\n              {\"\\\\(G:\\\\mathbb{R}^k\\\\rightarrow\\\\mathbb{R}^k\\\\)\"} by\r\n              {`\\\\[\r\n                G(x)=(g(x)_1,\\\\dots,g(x)_\\\\ell,x_{\\\\ell+1},\\\\dots,x_k)\r\n                \\\\]`}\r\n              and by extending our basis chosen to represent \\(dg_0\\), we can\r\n              represent \\(dG_0\\) by \\(I_k\\). Then by (8), after said shrinking,\r\n              we get <Diagram src={svg8} /> as desired.\r\n            </span>\r\n          }\r\n        />\r\n        <p>\r\n          This is quite a powerful result, because it lets us easily create\r\n          manifolds when coupled with a few more useful tools. Say we have some\r\n          arbitrary map \\(f:X\\rightarrow Y\\). With \\(y\\in Y\\), we call the{\" \"}\r\n          <strong>fibre</strong> of \\(y\\) the set{\" \"}\r\n          {\"\\\\(\\\\left\\\\{x\\\\in X:f(x)=y\\\\right\\\\}=f^{-1}(y)\\\\)\"}. Note this is\r\n          the special case of a preimage, namely of the singleton{\" \"}\r\n          {\"\\\\(\\\\left\\\\{y\\\\right\\\\}\\\\)\"}. Cases where fibres are manifolds\r\n          themselves are of great interest, as we will soon see. However, how we\r\n          can we figure out if they are one in the first place? Drawing\r\n          inspiration from (9), suppose \\(f\\) is actually a smooth mapping of\r\n          manifolds. We call \\(y\\) a <strong>regular value</strong> if \\(f\\)\r\n          submerges its fibre (in the sense that it is a submersion at every\r\n          element).\r\n        </p>\r\n        <Theorem\r\n          no=\"10\"\r\n          name=\"Fibre Theorem\"\r\n          statement=\"\r\n        If \\(y\\in Y\\) is a regular value of a smooth \\(f:X\\rightarrow Y\\) between manifolds, then the fibre of \\(y\\) is a submanifold of \\(X\\) with dimension \\(\\mathrm{dim}\\,X-\\mathrm{dim}\\,Y\\).\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        Suppose we have some such \\(f\\), with \\(\\mathrm{dim}\\,X=k\\) and \\(\\mathrm{dim}\\,Y=\\ell\\). Let \\(x\\) be in our fibre. Choose local coordinates in a neighbourhood \\(U\\) of \\(x\\) by (9) such that \\(f(x_1,\\dots,x_k)=(x_1,\\dots,x_\\ell)\\). Then, note that\r\n        \\[\r\n            V=f^{-1}(y)\\cap U=\\left\\{x\\in U:x_1=\\cdots=x_\\ell=0\\right\\}.\r\n        \\]\r\n        However, this means \\(V\\) is an open subset of \\(f^{-1}(y)\\) diffeomorphic to \\(\\mathbb{R}^{k-\\ell}\\), as the local coordinate system \\((x_{\\ell+1},\\dots,x_k)\\) fully describes \\(V\\). In other words, \\(V\\) is a \\((k-\\ell)\\)-manifold.\"\r\n        />\r\n        <p>\r\n          This is remarkably powerful. For example, take the unit \\(n\\)-sphere{\" \"}\r\n          {\"\\\\(S^n\\\\subseteq\\\\mathbb{R}^{n+1}\\\\)\"}. To prove this is an\r\n          \\(n\\)-manifold explicitly is not the easiest task. We would need to\r\n          construct the stereographic projection, then show it is bijective and\r\n          smooth both ways (or something similar). Instead, however, we note\r\n          that\r\n          {\"\\\\[\\r\\nS^n=\\\\left\\\\{x\\\\in\\\\mathbb{R}^{n+1}:N(x)=1\\\\right\\\\}\\r\\n\\\\]\"}\r\n          where{\" \"}\r\n          {\"\\\\(N=\\\\|\\\\, \\\\|^2:\\\\mathbb{R}^{n+1}\\\\rightarrow\\\\mathbb{R}\\\\)\"} is\r\n          the square of the Euclidean norm. This means that \\(S^n\\) is the fibre\r\n          of \\(1\\) (under \\(N\\)). However, note that at{\" \"}\r\n          {\"\\\\(z\\\\in\\\\mathbb{R}^{n+1}\\\\)\"}{\" \"}\r\n          {\r\n            \"\\\\[\\r\\ndN_z=\\\\begin{pmatrix} 2z_1 & \\\\cdots & 2z_{n+1}\\\\end{pmatrix}\\r\\n\\\\]\"\r\n          }{\" \"}\r\n          is clearly surjective to {\"\\\\(\\\\mathbb{R}\\\\)\"} except when \\(z=0\\). In\r\n          particular, it is surjective when \\(z=1\\), meaning \\(S^n\\) is an\r\n          \\(n\\)-manifold.\r\n        </p>\r\n        <p>\r\n          One interesting remark is that {\"\\\\(dN_{-1}\\\\)\"} is also surjective.\r\n          In fact, this holds true for any \\(z \\lt 0\\), despite the fact that we\r\n          cannot have a negative radius. Although strange, it is merely\r\n          platitudinous, as {\"\\\\(N^{-1}(-1)=\\\\varnothing\\\\)\"} and the empty set\r\n          is vacuously a \\(0\\)-manifold (and also a basis for every kernel, and\r\n          has an infimum of infinity, and...).\r\n        </p>\r\n        <p>\r\n          There is an interesting consequence of working with these fibres under\r\n          certain conditions. We can use it to create a neighbourhood around a\r\n          point, by stacking various records induced by the fibre. The geometric\r\n          intuition here is nicely demonstrated in figure 1 taken from Guillemin\r\n          and Pollack's <i>Differential Topology</i>.\r\n        </p>\r\n        <Figure\r\n          no=\"1\"\r\n          src={Fig1GP}\r\n          caption=\" Stack of Records visualization, Fig 1-13 (26) G and P\"\r\n        />\r\n        <Theorem\r\n          no=\"11\"\r\n          name=\"Stack of Records\"\r\n          statement=\"\r\n        Suppose \\(y\\in Y\\) is a regular value of a smooth \\(f:X\\rightarrow Y\\) where \\(X\\) and \\(Y\\) are equidimensional manifolds, and \\(X\\) is compact. Then, the fibre of \\(y\\) is finite, and there exists an open neighbourhood of \\(y\\) whose preimage is the disjoint union of open neighbourhoods around each element in the fibre.\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        Suppose we have some such \\(y\\). Let \\(x\\in f^{-1}(y)\\). We know \\(df_x\\) is surjective from (10), and given \\(\\mathrm{dim}\\,X=\\mathrm{dim}\\,Y\\) it is in fact bijective. From (7), it is therefore locally diffeomorphic on the fibre. Suppose now the fibre is infinite. As \\(X\\) is compact, we know it contains a limit point of \\(f^{-1}(y)\\), say \\(x_0\\). As \\(f\\) is continuous, we know our fibre is compact as well, hence \\(x_0\\in f^{-1}(y)\\). Take consecutively smaller neighbourhoods of \\(x_0\\) to form a sequence of \\(x_i\\in f^{-1}(y)\\) which converge to \\(x_0\\). As \\(f\\) is a local diffeomorphism a neighbourhood of \\(x_0\\) diffeomorphic to some neighbourhood in \\(Y\\) must exist, but each neighbourhood will contain some \\(x_i\\neq x_0\\), hence failing to be injective. Thus, the fibre is finite, say \r\n        \\[\r\n            f^{-1}(y)=\\left\\{x_1,\\dots,x_n\\right\\}.\r\n        \\] \r\n        Choose open neighbourhoods \\(U_i\\) around each \\(x_i\\) diffeomorphic to some neighbourhood around \\(y\\), which we shrink until they are disjoint. Then, let \\(V=\\bigcap f(U_i)\\). Then, let \\(U_i^\\ast=U_i\\cap f^{-1}(V)\\). As \\(X\\setminus\\dot{\\bigcup}\\,U_i^\\ast\\) is closed, its image is compact, and therefore \\(V\\) is open. By construction \\(f^{-1}(V)=\\dot{\\bigcup}\\, U_i^\\ast\\), giving our desired records and stacking. \"\r\n        />\r\n        <p>\r\n          This is the reason I love differential topology. You get to go from a\r\n          very simple picture and idea, like stacking records on one another, to\r\n          the abstract and rigorous framework behind the proof itself, building\r\n          on top of other abstract and rigorous tools with the same intuitive\r\n          framing. Moreover, the tools themselves are quite simple - linear maps\r\n          and metric space topology - but they fuse perfectly with the\r\n          requirement that your space be locally Euclidean, letting you describe\r\n          complicated and otherwise obtuse structures with straightforward and\r\n          basic concepts.\r\n        </p>\r\n      </div>\r\n    );\r\n  }\r\n\r\n}\r\n\r\nexport default StackOfRecords;","import React, { Component } from \"react\";\r\n/* environments */\r\nimport Theorem from \"../../../components/Theorem\";\r\nimport Proof from \"../../../components/Proof\";\r\n\r\nclass Normal extends Component {\r\n\r\n  componentDidMount() {\r\n    window.KaTeXRender();\r\n  }\r\n\r\n  render() {\r\n    return (\r\n      <div class=\"postContent leftMargin\">\r\n        <p>\r\n          A few weeks ago I was working through some exercises out of Rudin's{\" \"}\r\n          <i>Principles of Mathematical Analysis</i> and exercise 4.22 brought\r\n          up normality. This piqued an interest in what a space which is{\" \"}\r\n          <i>not</i> normal would look like. Searching for non-trivial examples\r\n          brought up the Moore plane, and my understanding of what it is and why\r\n          it is not normal laid in a hazy propinquity. So, I spent some time\r\n          looking through some threads on MSE, Reddit, and other websites, as\r\n          well as some texts like Munkres' <i>Topology</i> to prove it starting\r\n          from the bottom up.\r\n        </p>\r\n        <p>\r\n          First, we must define what a topology is. Given some $X$, we define a \r\n          <strong> topology</strong> {\"$\\\\mathcal{T}$\"} to be a set of subsets of\r\n          $X$ such that\r\n        </p>\r\n        <ol>\r\n          <li>both $X$ and $\\varnothing$ are in {\"$\\\\mathcal{T}$\"};</li>\r\n          <li>\r\n            the union of any elements of {\"$\\\\mathcal{T}$\"} is too an element of{\" \"}\r\n            {\"$\\\\mathcal{T}$\"}; and\r\n          </li>\r\n          <li>\r\n            the finite intersection of any elements of {\"$\\\\mathcal{T}$\"} is too\r\n            an element of {\"$\\\\mathcal{T}$\"}.\r\n          </li>\r\n        </ol>\r\n        <p style={{ textIndent: \"0\" }}>\r\n          We then call $X$ a <strong>topological space</strong> once a topology\r\n          is specified. We then say a subset of $X$ is <strong>open</strong> if\r\n          it is an element of {\"$\\\\mathcal{T}$\"}. Then, a subset is{\" \"}\r\n          <strong>closed</strong> if its complement is open.\r\n        </p>\r\n        <p>\r\n          Describing topologies can be particularly difficult as listing an\r\n          infinite amount of sets takes a non-trivial amount of time. Instead,\r\n          to describe a particular topology on $X$ a <strong>basis</strong>{\" \"}\r\n          {\"$\\\\mathcal{B}$\"} is usually provided, which takes as elements\r\n          subsets of $X$ such that\r\n        </p>\r\n        <ol>\r\n          <li>\r\n            for any $x\\in X$ there exists some {\"$B\\\\in\\\\mathcal{B}$\"} such that\r\n            $x\\in B$; and\r\n          </li>\r\n          <li>\r\n            for any $x\\in X$ such that $x$ lies in the intersection two distinct{\" \"}\r\n            {\"$B_1,B_2\\\\in\\\\mathcal{B}$\"}, there exists some $B_3\\subset B_1\\cap\r\n            B_2$ such that $x\\in B_3$.\r\n          </li>\r\n        </ol>\r\n        <p>\r\n          Then, we define the topology {\"$\\\\mathcal{T}$\"} on $X${\" \"}\r\n          <strong>generated</strong> by {\"$\\\\mathcal{B}$\"} by having $U$ be open\r\n          in $X$ if for all $x\\in U$ there exists some {\"$B\\\\in\\\\mathcal{B}$\"}{\" \"}\r\n          such that $x\\in B$ and $B\\subset U$. Showing that {\"$\\\\mathcal{T}$\"}{\" \"}\r\n          is indeed a topology involves showing that it adheres to the first 3\r\n          conditions listed; the first two are trivial and the third can be\r\n          shown by induction.\r\n        </p>\r\n        <p>\r\n          To more constructively show <i>what</i> is exactly in {\"$\\\\mathcal{T}$\"},\r\n          rather than just saying <i>if</i> something is, let {\"$\\\\mathcal{B}$\"}{\" \"}\r\n          generate some topology. Then, given some {\"$U\\\\in\\\\mathcal{T}$\"} note\r\n          that for any $x\\in U$ we can choose some {\"$B_x\\\\in\\\\mathcal{B}$\"}{\" \"}\r\n          such that $x\\in B_x\\subset U$ by our definition of open. Then,\r\n          {\"$$U=\\\\bigcup_{x\\\\in U}B_x.$$\"}\r\n          Additionally, given that this implies every {\"$B\\\\in\\\\mathcal{B}$\"} is\r\n          in the topology, $B$ is then open and so any union of elements of the\r\n          basis gives another element of the topology. Thus, both sides are\r\n          subsets of each other and so {\"$\\\\mathcal{T}$\"} is just every possible\r\n          union of every element of $B$. The notion of open and closed sets\r\n          related to interior and limit points in {\"$\\\\mathbb{R}^n$\"} can be\r\n          recovered by taking as a basis every open $n$-ball.\r\n        </p>\r\n        <p>\r\n          This is important because now we can define the object of interest:\r\n          the <strong>Moore plane</strong>. First, consider the upper half of\r\n          the {\"$\\\\mathbb{R}^2$\"}-plane,\r\n          {\r\n            \"$$\\\\Gamma=\\\\left\\\\{\\\\left(x,y\\\\right)\\\\in\\\\mathbb{R}^2:y\\\\geq 0\\\\right\\\\}.$$\"\r\n          }\r\n          Then, given some $(p,q)\\in\\Gamma$, we define a local basis at that\r\n          point by various open discs. Namely, if $q\\neq0$, then we considered\r\n          every open disc in $\\Gamma$ centred at $(p,q)$. If $q=0$, then we\r\n          consider every open disc in $\\Gamma$ tangent to the $x$-axis at\r\n          $(p,0)$, but also including the point of tangency. More formally,\r\n          {`$$\\\\mathcal{B}(p,q)=\\\\begin{cases}\r\n        \\\\bigcup\\\\limits_{0\\\\,\\\\lt\\\\,\\\\varepsilon\\\\,\\\\leq\\\\, q}\\\\left\\\\{(x,y)\\\\in\\\\mathbb{R}^2:(x-p)^2+(y-q)^2\\\\lt\\\\,\\\\varepsilon^2\\\\right\\\\} & \r\n        q\\\\,\\\\ge\\\\, 0\\\\\\\\ \\\\bigcup\\\\limits_{\\\\varepsilon\\\\,\\\\gt\\\\, 0}\\\\left\\\\{p,0\\\\right\\\\}\\\\cup\\\\left\\\\{(x,y)\\\\in\\\\mathbb{R}^2:(x-p)^2+(y-\\\\varepsilon)^2\\\\lt\\\\,\\\\varepsilon^2\\\\right\\\\} \r\n        & q=0.\\\\end{cases}$$`}\r\n        </p>\r\n        <p>\r\n          One can do this for every $(p,q)\\in\\Gamma$ to find the complete basis.\r\n          Now, we define the entire reason this post exists. We call a space $X${\" \"}\r\n          <strong>normal</strong> if for any disjoint closed subsets $A$ and\r\n          $B$, there exist disjoint open $U$ and $V$ such that $A\\subset U$\r\n          and $B\\subset V$. In other words, you can separate $A$ and $B$ by\r\n          neighborhoods.\r\n        </p>\r\n        <p>\r\n          To me this was confusing, because it seems very difficult to imagine\r\n          in a (non-trivial) space. After all, taking {\"$\\\\mathbb{R}^n$\"} for\r\n          intuition, it seems absurd that a space could not be normal. However,\r\n          the Moore plane is just so. Now, we will set abound to prove it via\r\n          contradiction (or rather a more tidy contrapositive) beginning with a\r\n          small result on normal spaces, and following with another for a\r\n          particular subset of the rationals.\r\n        </p>\r\n        <Theorem\r\n          no=\"1\"\r\n          statement=\"\r\n        If $X$ is a normal space, then for any closed $C\\subset X$ with an open $U$ such that $C\\subset U$, there exists an open $V$ such that\r\n        $$C\\subset V\\subset\\overline{V}\\subset U$$\r\n        where $\\overline{V}$ is the closure of $V$.\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        Consider some such $C$ and $U$. We know then $C\\cap X\\setminus U=\\varnothing$, and as $U$ is open $X\\setminus U$ is closed. Then, given that $X$ is normal we can find some disjoint open $V\\supset C$ and open $W\\supset X\\setminus U$. Given they are disjoint, we know $V\\subset X\\setminus W$, and so\r\n        $$C\\subset V\\subset\\overline{V}\\subseteq X\\setminus W\\subset U$$\r\n        as $X\\setminus W$ is closed.\"\r\n        />\r\n        <Theorem\r\n          no=\"2\"\r\n          statement={\r\n            <span>\r\n              The <strong>dyadic rationals</strong>, {\"$\\\\mathbb{Q}_d$\"},\r\n              defined by{\" \"}\r\n              {\r\n                \"$$\\\\mathbb{Q}_d=\\\\left\\\\{\\\\frac{p}{2^q}\\\\in\\\\mathbb{Q}:p\\\\in\\\\mathbb{Z},q\\\\in\\\\mathbb{N}\\\\right\\\\}$$\"\r\n              }{\" \"}\r\n              where the naturals include 0, are dense in {\"$\\\\mathbb{R}$\"}.\r\n            </span>\r\n          }\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        We merely need to show every $x\\in\\mathbb{R}\\setminus\\mathbb{Q}_d$ is a limit point of $\\mathbb{Q}_d$. Let $\\varepsilon \\gt 0$. Then, there exists some $q\\in\\mathbb{N}$ such that $2^q\\varepsilon\\gt 1.$ We know there exists some $p$ such that\r\n        $$p-1\\lt 2^qx\\lt p$$\r\n        and then we get\r\n        $$2^qx\\lt p\\lt 2^qx+1\\lt 2^q(x+\\varepsilon)$$\r\n        meaning $\\left|x-\\frac{p}{2^q}\\right|\\lt\\varepsilon$. \"\r\n        />\r\n        <p>\r\n          Now, we set out to prove a famous result connecting normal spaces and\r\n          continuous functions, using the above subclosure property in its\r\n          construction.\r\n        </p>\r\n        <Theorem\r\n          no=\"3\"\r\n          name=\"Urysohn\"\r\n          statement=\"\r\n        For any two disjoint closed sets $A$ and $B$ in normal $X$, there exists a continuous mapping $f:X\\rightarrow [0,1]$ such that for all $x\\in A, f(x)=0$ and for all $x\\in B, f(x)=1$.\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        Let $C_0=A$, and then $U_1=X\\setminus B$. We know $C_0\\subset U_1$, and so by (1) we can find some subclosure, say $C_{\\frac12}$, and then from this some open $U_{\\frac12}$ such that\r\n        $$C_0\\subset U_{\\frac12}\\subset C_{\\frac12}\\subset U_1.$$\r\n        However, we can then repeat this process with $C_0$ and $U_{\\frac12}$, and $C_{\\frac12}$ and $U_1$, and then again after that, eventually getting the construction\r\n        $$C_0\\subset\\cdots\\subset C_{\\frac14}\\subset U_{\\frac14}\\subset\\cdots\\subset U_{\\frac12}\\subset C_{\\frac12}\\subset\\cdots\\subset U_{\\frac34}\\subset C_{\\frac34}\\subset\\cdots\\subset U_1$$\r\n        where we choose to index by $\\mathbb{Q}_d$.\\[\\]\r\n        Let $(0,1]_d=\\mathbb{Q}_d\\cap (0,1]$. Then, we define $f:X\\rightarrow [0,1]$ by\r\n            $$f(x)=\r\n            \\begin{cases}\r\n            1 & x\\in B\\\\\r\n            \\inf\\left\\{r\\in (0,1]_d: \\left\\{x\\right\\}\\subset U_r\\right\\} & x\\notin B. \r\n            \\end{cases}\r\n        $$\r\n        We must define $f$ on $B$ as no element of $B$ will be in any $U_r$. We also see this infimum will return $0$ for any $x\\in A$. It stands to show that $f$ is continuous on $X$.\\[\\]\r\n        First, notice that if $x\\in\\overline{U_r}$ then $f(x)\\leq r$. This is because $\\mathbb{Q}_d$ is dense in $\\mathbb{R}$ as per (2), so for any $\\varepsilon\\gt 0$ we know there is some $r'$ such that $r\\lt r'\\lt r+\\varepsilon$. Then, $\\overline{U_r}\\subset U_{r'}$, so $f(x)\\lt r'$.\\[\\]\r\n        Consider now some arbitrary $(a,b)\\subset [0,1]$. Choose some $x\\in f^{-1}(a,b)$. We know we can find some $p,q\\in (0,1]_d$ such that\r\n            $$a\\lt p\\lt f(x)\\lt q\\lt b$$ \r\n            and then $x\\notin\\overline{U_p}$ and $x\\in U_q$.\\[\\]\r\n            Then, we let $V_x=U_q\\setminus\\overline{U_p}$. Consider some $v\\in V_x$. We know $v\\in U_q$ but $v\\notin\\overline{U_p}$, meaning $p\\lt v\\lt q$. Thus, $f(V_x)=(p,q)\\subset (a,b)$. As $V_x$ is open, we know every point in $f^{-1}(a,b)$ is interior, and hence the entire preimage is open. As these open intervals are arbitrary, we know $f$ is continuous on all of $X$. \"\r\n        />\r\n        <p>\r\n          Note that although the above proof uses {\"$\\\\mathbb{Q}_d$\"}, it is not\r\n          necessary. In fact, any countable and dense set will do; one just\r\n          needs to ensure it is easily enumerable for the argument to be\r\n          straightforward and readable, and the dyadic rationals are one such\r\n          choice. Additionally, every set similar to this will be dense in{\" \"}\r\n          {\"$\\\\mathbb{R}$\"}; the proof I demonstrated is just a trivial\r\n          adaptation of the standard proof that {\"$\\\\mathbb{Q}$\"} in its\r\n          entirety is dense.\r\n        </p>\r\n        <p>\r\n          We now quickly provide one more definition. We say a space $X$ is{\" \"}\r\n          <strong>Hausdorff</strong> if any two distinct points in $X$ also have\r\n          disjoint neighborhoods. This important as the Moore plane is\r\n          Hausdorff, but is not normal, and that will come into play in both the\r\n          next theorem and our eventual conclusion.\r\n        </p>\r\n        <Theorem\r\n          no=\"4\"\r\n          statement=\"\r\n        If $X$ is Hausdorff with dense $E\\subset X$, and $f$ and $g$ are continuous functions on $X$ with $f(e)=g(e)$ for all $e\\in E$, then $f=g$.\r\n        \"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        Suppose this is not the case. Then, there exists $x_0\\in X\\setminus E$ such that $f(x_0)\\neq g(x_0)$. Given $X$ is Hausdorff, there exist open neighborhoods of $f(x_0)$ and $g(x_0)$, $U_f$ and $U_g$ respectively, such that\r\n        $$U_f\\cap U_g=\\varnothing .$$\r\n        We know\r\n        $$x_0\\in f^{-1}(U_f)\\cap g^{-1}(U_g)=V$$\r\n        and $V$ is known to be open as both $f$ and $g$ are continuous. As $V$ is open and $E$ is dense, however, there is some $e\\in E$ also in $V$, and $f(e)=g(e)=\\lambda$, meaning\r\n        $$\\lambda\\in  U_f\\cap U_g$$\r\n        giving a contradiction.\"\r\n        />\r\n        <p>\r\n          A few more definitions are useful in the next proof. We say a topology\r\n          $X$ is <strong>discrete</strong> if every single possible subset is\r\n          included in the topology. Note that this contrasts with the{\" \"}\r\n          <strong>indiscrete</strong> topology which would only include $X$ and\r\n          $\\varnothing$. They are called so as in the discrete topology every\r\n          element is distinguishable (in the sense that if $x\\in X$, then{\" \"}\r\n          {\"$\\\\left\\\\{ x\\\\right\\\\}\\\\in\\\\mathcal{T}$\"}), whereas in the\r\n          indiscrete topology every single point is grouped together into one\r\n          big open set (as we would have{\" \"}\r\n          {\"$\\\\mathcal{T}=\\\\left\\\\{\\\\varnothing, X\\\\right\\\\}$\"} ). The reason\r\n          why the discrete topology is useful in the upcoming proof is because{\" \"}\r\n          {\"$\\\\left\\\\{x\\\\right\\\\}$\"} is both open and closed in it (given that\r\n          its complement is too an open set).\r\n        </p>\r\n        <p>\r\n          The specific type of discreteness we will use is the one induced by\r\n          the <strong>subspace topology</strong>. Given some $X$ with topology{\" \"}\r\n          {\"$\\\\mathcal{T}$\"}, the subspace topology on a subset $S\\subset X$ is\r\n          defined as{\" \"}\r\n          {\r\n            \"$$\\\\mathcal{T}_S =\\\\left\\\\{ S\\\\cap U:U\\\\in\\\\mathcal{T}\\\\right\\\\} .$$\"\r\n          }\r\n        </p>\r\n        <Theorem\r\n          no=\"5\"\r\n          name=\"Jones\"\r\n          statement=\"\r\n        If $X$ is normal and infinite, with dense $D\\subset X$, and  $C\\subset X$  closed and discrete by the subspace topology, then $2^{\\left| C\\right|}\\leq 2^{\\left| D\\right|}$, where $\\left| X\\right|$ is the cardinality of $X$.\"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        Consider a non-empty $A\\subsetneq C$. We know $A$ and $C\\setminus A$ are closed and disjoint, so by Urysohn we can find a continuous function\r\n        $$f_A :X\\rightarrow \\left[ 0,1\\right]$$\r\n        such that $f\\left( A\\right) =\\left\\{ 0\\right\\}$ and  $f\\left( C\\setminus A\\right) =\\left\\{ 1\\right\\}$.\\[\\]\r\n        Consider any continuous function $f :X\\rightarrow \\left[ 0,1\\right]$. As it is uniquely determined by the values it takes on $D$, as per (4), we could could give a full description by matching every element of $D$ with the functions output in $\\left[ 0,1\\right]$. Thus, the set of all such functions has cardinality\r\n        $$\\left|\\left[ 0,1\\right]^D\\right| =\\left(2^{\\aleph_0}\\right)^{\\left| D\\right|}=2^{\\aleph_0} .$$\r\n        We know that the set of functions of the form $f_A$ is a subset of all possible continuous functions. Thus, as $A$ is just any element of the powerset of $C$,\r\n        $2^{\\left| C\\right|}\\leq  2^{\\aleph_0}$.\"\r\n        />\r\n        <p>\r\n          Now, we return to the Moore plane. Our goal, as one would expect, is\r\n          to find sets corresponding to $C$ and $D$ above whose cardinalities do\r\n          not follow.\r\n        </p>\r\n        <Theorem\r\n          no=\"6\"\r\n          statement=\"\r\n        With respect to the subspace topology, the $x$-axis, $\\mathbb{R}\\times\\left\\{ 0\\right\\}$, is discrete and closed in $\\Gamma$.\r\n        \"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        Let $\\mathcal{X}$ be the $x$-axis. We know the only open sets in $\\Gamma$ which intersect $\\mathcal{X}$ are those generated by the local basis at any point $(p,0)$, $p\\in\\mathbb{R}$, as they include $(p,0)$. Thus, the subspace topology is on $\\mathcal{X}$ is\r\n        $$T_\\mathcal{X}=\\left\\{\\left\\{\\left(p,0\\right)\\right\\}\\in\\mathcal{X}:p\\in\\mathbb{R}\\right\\}$$\r\n        which means $\\mathcal{X}$ is discrete. As its complement is $\\varnothing$, we also know $\\mathcal{X}$ is closed. \r\n        \"\r\n        />\r\n        <Theorem\r\n          no=\"7\"\r\n          statement=\"\r\n        The set $\\mathbb{Q}\\times\\mathbb{Q}_+$ is dense in $\\Gamma$.\r\n        \"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        Let $\\mathcal{Q}=\\mathbb{Q}\\times\\mathbb{Q}_+$. Trivially, any $x\\in\\mathcal{Q}$ is also in $\\Gamma$. Consider some $x\\in\\Gamma \\setminus\\mathcal{Q}$. We know $x=(a,b)$ for some $(a,b)\\in\\mathbb{R}\\times\\mathbb{R}_+$. Let $N$ be an arbitrary neighborhood of $x$. Let $U$ be an open set such that $x\\in U\\subseteq N$.\\[\\]\r\n        If $b\\neq 0$, then $U$ is an open disc around $x$ and so some $\\varepsilon\\gt 0$ is its radius. As $\\mathbb{Q}$ is dense in $\\mathbb{R}$, and likewise for $\\mathbb{Q}_+$ and $\\mathbb{R}_+$, we know we can find some point $p\\in\\mathbb{Q}$ and $q\\in\\mathbb{Q}_+$ such that\r\n        $$\\left| p-a\\right|\\lt\\frac{\\varepsilon}{\\sqrt2}\\qquad \\left| q-b\\right|\\lt\\frac{\\varepsilon}{\\sqrt2}$$\r\n        meaning\r\n        $$\r\n            \\left(p-a\\right)^2+\\left(q-b\\right)^2\\lt\\left(\\frac{\\varepsilon}{\\sqrt2}\\right)^2+\\left(\\frac{\\varepsilon}{\\sqrt2}\\right)^2=\\varepsilon^2\r\n        $$\r\n        hence $(p,q)\\in U$.\r\n        Suppose now that $b=0$. We know then that some  $\\varepsilon\\gt 0$ defines the open disc centred around $(a,\\varepsilon )$ tangent to $x$. Again by density, we find some $p\\in\\mathbb{Q}$ and $q\\in\\mathbb{Q}_+$ such that\r\n        $$\\left| p-a\\right|\\lt\\frac{\\varepsilon}{\\sqrt2}\\qquad\\frac{\\sqrt2-1}{\\sqrt2}\\varepsilon\\lt q\\lt\\frac{\\sqrt2+1}{\\sqrt2}\\varepsilon$$\r\n        noting that our choice of $q$ implies too that $\\left| q-\\varepsilon\\right|\\lt\\frac{\\varepsilon}{\\sqrt2}$. Similarly then,\r\n        $$\r\n            \\left(p-a\\right)^2+\\left(q-\\varepsilon\\right)^2\\lt\\left(\\frac{\\varepsilon}{\\sqrt2}\\right)^2+\\left(\\frac{\\varepsilon}{\\sqrt2}\\right)^2=\\varepsilon^2\r\n        $$\r\n        thus $(p,q)\\in U$.\\[\\]\r\n        Given the arbitrary neighborhood, any $x\\in\\Gamma$ that is not also in $\\mathcal{Q}$ is a limit point thereof. \"\r\n        />\r\n        <p>At last, we can finally prove what was intended.</p>\r\n        <Theorem\r\n          no=\"8\"\r\n          statement=\"\r\n        The Moore plane is not normal.\r\n        \"\r\n        />\r\n        <Proof\r\n          proof=\"\r\n        By (6) we know $\\mathcal{X}=\\mathbb{R}\\times\\left\\{ 0\\right\\}$ is closed and discrete in $\\Gamma$ with respect to the subspace topology. By (7), we know $\\mathcal{Q}=\\mathbb{Q}\\times\\mathbb{Q}_+$ is dense (and therefore infinite) in $\\Gamma$.\\[\\]\r\n        We know $\\left|\\mathcal{X}\\right| =\\left|\\mathbb{R}\\right|$ and $\\left|\\mathcal{Q}\\right| =\\aleph_0$. Since $2^{\\left|\\mathbb{R}\\right|}\\gt 2^{\\aleph_0}$ we know $\\Gamma$ is not normal by Jones.\"\r\n        />\r\n        <p>\r\n          This was really fun to make! I had little experience with topology\r\n          outside of metric spaces prior to this, and going in I had no idea how\r\n          to visualize topological spaces at all, nor why something like this\r\n          could even be possible.\r\n        </p>\r\n        <p>\r\n          The way I intuitively understand this begins with Urysohn, whose\r\n          construction involved taking advantage of the space around closed sets\r\n          (if the space is normal) to make a function based on shrinking a\r\n          neighborhood covering it, until by limiting behaviour you end up back\r\n          at the closed set itself.\r\n        </p>\r\n        <p>\r\n          Then given that a dense set fully characterizes a continuous function,\r\n          if you are able to do this Urysohn process on a closed and discrete\r\n          subset of the space then it can only be so big (limited by the size of\r\n          the dense set), as you are taking advantage of space between closures.\r\n          If it turns out the set is actually larger than that, then it must be\r\n          because the everything is so tightly packed together that you cannot\r\n          separate closed sets - the space is non-normal.\r\n        </p>\r\n      </div>\r\n    );\r\n  }\r\n\r\n}\r\n\r\nexport default Normal;","import React, { Component } from \"react\";\r\n/* environments */\r\nimport Theorem from \"../../../components/Theorem\";\r\nimport Proof from \"../../../components/Proof\";\r\n\r\nclass LogIso extends Component {\r\n  componentDidMount() {\r\n    window.KaTeXRender();\r\n  }\r\n\r\n  render() {\r\n    return (\r\n      <div className=\"postContent leftMargin\">\r\n        <p>\r\n          Logarithms are pretty simple functions first introduced in early high\r\n          school as the answer to the question \"What is the opposite of\r\n          exponentiation?\". However, there is actually a deeper history behind\r\n          them, and that lies with their connection in group theory, which my\r\n          friend mentioned to me and I presented today when I ran the problem\r\n          solving session at my university.\r\n        </p>\r\n        <p>\r\n          It is obvious that adding and subtracting numbers is easier than\r\n          multiplying or dividing. After all, kids in elementary school become\r\n          experts in the former, however even adults can have difficulty with\r\n          fractions. Computationally, multiplication and division require far\r\n          more resources as well, with the most optimal multiplication algorithm\r\n          running in {\"$\\\\mathcal{O}(n\\\\cdot \\\\log(n))$\"}, while addition is\r\n          simply {\"$\\\\mathcal{O}(n)$\"}. Thus, there is a lot of motivation to\r\n          transform multiplication tasks into addition tasks, and from this came\r\n          the concept of logarithms. However, it is worth examining what the\r\n          idea of \"transforming\" an operations actually means. Hence, we examine\r\n          groups.{\" \"}\r\n        </p>\r\n        <p>\r\n          Consider some set $G$ with an operation $\\ast$ defined on it, both of\r\n          which are often written together as $(G,\\ast)$. In order for this to\r\n          become a <strong>group</strong>, we must have four requirements:\r\n        </p>\r\n        <ol>\r\n          <li>For all $a,b\\in G$, $a\\ast b\\in G$;</li>\r\n          <li>For all $a,b,c\\in G$, $(a\\ast b)\\ast c = a\\ast(b\\ast c)$;</li>\r\n          <li>\r\n            There exists some $e\\in G$ (often called the identity) such that\r\n            $e\\ast a=a\\ast e=e$ for all $a\\in G$;\r\n          </li>\r\n          <li>\r\n            Every $a\\in G$ has associated with it some unique element{\" \"}\r\n            {\"$a^{-1}\\\\in G$\"} such that {\"$a\\\\ast a^{-1}=e$\"}.\r\n          </li>\r\n        </ol>\r\n        <p>\r\n          Now, consider two groups, say $(G,\\ast)$ and $(H,\\cdot)$. Suppose we\r\n          have some function $\\varphi : G \\longrightarrow H$ which satisfies\r\n          $$\\varphi(a\\ast b)=\\varphi(a)\\cdot\\varphi(b)$$ for all $a,b\\in G$. We\r\n          call this a group <strong>homomorphism</strong>. Note that nothing is\r\n          specified about bijectivity or anything of the sort.\r\n        </p>\r\n        <p>\r\n          This specific property is nice because it preserves group structure as\r\n          we will see. For example, consider the identity of $G$, say $e$. Then,\r\n          let $a\\in G$. We see\r\n          {\"$$\\\\varphi(a)=\\\\varphi(e\\\\ast a)=\\\\varphi(e)\\\\cdot\\\\varphi(a).$$\"}\r\n          This necessitates $\\varphi(e)$ to be the identity of $H$. So, group\r\n          homomorphisms preserve identities.\r\n        </p>\r\n        <p>\r\n          Now let us consider inverses, using $a$ again. We have\r\n          {\r\n            \"$$\\\\varphi(e)=\\\\varphi(a\\\\ast a^{-1})=\\\\varphi(a)\\\\cdot\\\\varphi(a^{-1}).$$\"\r\n          }\r\n          However as we know that $\\varphi(e)$ is the identity of $H$, this\r\n          means that {\"$\\\\varphi(a^{-1})$\"} is the inverse of $\\varphi(a)$. In\r\n          other words, {\"$\\\\varphi(a^{-1})=(\\\\varphi(a))^{-1}$\"}; inverses are\r\n          preserved too.\r\n        </p>\r\n        <p>\r\n          Lastly, we will consider powers. We use the intuitive notation\r\n          $a\\ast\\cdots\\ast a=a^n$ if we perform the operation $n$ times. Of\r\n          course, $\\varphi(a^1)=(\\varphi(a))^1$. Now suppose this holds for all{\" \"}\r\n          {\"$k\\\\in\\\\mathbb{N}$\"} where $k\\gt 1$. Then, consider $k+1$. We have\r\n          {\r\n            \"$$\\\\begin{aligned}\\r\\n\\\\varphi(a^{k+1})&=\\\\varphi(a^k\\\\ast a)\\\\\\\\\\r\\n&=\\\\varphi(a^k)\\\\cdot\\\\varphi(a)\\\\\\\\\\r\\n&=(\\\\varphi(a))^k\\\\cdot\\\\varphi(a)\\\\\\\\\\r\\n&=(\\\\varphi(a))^{k+1}\\r\\n\\\\end{aligned}$$\"\r\n          }\r\n          and so this holds for any natural number, by induction. Thus,\r\n          $\\varphi$ preserves exponentiation.\r\n        </p>\r\n        <p>\r\n          We know for all positive real numbers $x,y$ we have\r\n          $$\\log(xy)=\\log(x)+\\log(y).$$ The domain of the logarithm lets us\r\n          interpret this as a group homomorphism between{\" \"}\r\n          {\"$(\\\\mathbb{R}^{+},\\\\cdot)$\"} (where $\\cdot$ is just multiplication)\r\n          and {\"$(\\\\mathbb{R},+)$\"}; the identity elements are 1 and 0\r\n          respectively; and inverses are given by inverting the number (since we\r\n          do not have to worry about 0) and by subtraction, again respectively.\r\n          We can then prove all commonly used log laws immediately from this\r\n          fact. Even more significantly, as the logarithm is bijective with\r\n          respect to these groups, this is actually a group{\" \"}\r\n          <strong>isomorphism</strong>, and thus {\"$(\\\\mathbb{R}^{+},\\\\cdot)$\"}{\" \"}\r\n          and {\"$(\\\\mathbb{R},+)$\"} are isomorphic. This is actually the heart\r\n          of why the logarithm is so good at transforming these operations.\r\n        </p>\r\n        <p>\r\n          I think this is a great example of deep mathematical structure behind\r\n          something which can be very easily understood, and shows that \"higher\r\n          level\" maths isn't necessarily inaccessible or super abstract to the\r\n          point that no tangible examples exist. I also don't want to study for\r\n          my microeconomics exam, so writing this post lets me procrastinate\r\n          while still feeling productive.\r\n        </p>\r\n      </div>\r\n    );\r\n  }\r\n}\r\n\r\nexport default LogIso;\r\n","import React, { Component } from \"react\";\r\nimport PostPreview from \"../components/PostPreview\";\r\n\r\n/* posts */\r\nimport Entanglement from \"./writing/2021-08-21/Entanglement\";\r\nimport SOME1 from \"./writing/2021-08-16/SOME1\";\r\nimport JordanBrouwer from \"./writing/2020-12-05/JordanBrouwer\";\r\nimport HeisigKanji from \"./writing/2020-08-09/HeisigKanji\";\r\nimport UniversalIsomorphism from \"./writing/2020-08-01/UniversalIsomorphism\";\r\nimport StackOfRecords from \"./writing/2020-03-05/StackOfRecords\";\r\nimport Normal from \"./writing/2019-12-22/Normal\";\r\nimport LogIso from \"./writing/2019-10-19/LogIso\";\r\n\r\nclass Posts extends Component {\r\n  componentDidMount() {\r\n    window.KaTeXRender();\r\n  }\r\n\r\n  render() {\r\n    return (\r\n      <div id=\"KaTeXSec\" className=\"coDiv posts\">\r\n        <ul>\r\n          <PostPreview\r\n            date=\"2021-08-21\"\r\n            dummyID=\"8\"\r\n            name=\"But What Is Entanglement Really?\"\r\n            summary=\"<p>Quantum entanglement, morally, has an intuitive definition: that some system cannot be understood as a combination of individual components, only holistically as an inseparable whole. Unsurprisingly, the precise mathematical definition herein is slightly more involved, introduced through the tensor product of Hilbert spaces. Some ways of measuring entanglement, specifically those related to entanglement entropy, are also surveyed.</p>\r\n            <p style='padding-top: 1vh;'>My talk at the <a target='_blank' style='font-weight: bold; color: #9e42f5;' href='https://cumc2021.ca'>2021 CUMC</a> is an abridged version of this write-up; a recording is available within the post.</p>\"\r\n            full={<Entanglement />}\r\n            html={true}\r\n          ></PostPreview>\r\n          <PostPreview\r\n            date=\"2021-08-16\"\r\n            dummyID=\"7\"\r\n            name=\"Spectral Theorem For Dummies\"\r\n            summary=\"<p>\r\n            The spectral theorem may be viewed as nothing more than a technical set of conditions for when a matrix may be diagonalized. However, there is a geometric notion underpinning this statement, made visible here by elevating the theorem to one for linear operators with diagonalization interpreted through vector projections.</p>\r\n            <p style='padding-top: 1vh;'>\r\n            This video was made for the <a target='_blank' style='font-weight: bold; color: #9e42f5;' href='https://www.3blue1brown.com/blog/some1'>2021 Summer of Math Exposition</a> in collaboration with <a target='_blank' style='font-weight: bold; color: #9e42f5;' href='https://www.jacquelinedoan.com/home'>Jackie Doan</a>.\r\n            </p>\"\r\n            full={<SOME1 />}\r\n            html={true}\r\n          ></PostPreview>\r\n          <PostPreview\r\n            date=\"2020-12-05\"\r\n            dummyID=\"6\"\r\n            name=\"Colouring Inside the Lines: the Jordan-Brouwer Separation Theorem\"\r\n            summary=\"Children learn in elementary school how to colour inside the lines. In the late 1800s, mathematicians argued for over a decade whether this is always possible or not. This is a brief discussion of the Jordan curve theorem and what it tells us about the inside and outside of curves, and how manifolds with boundaries are used to state its generalization: the separation theorem. Transversal intersections and homotopy are introduced in order to discuss some techniques used in the proof of theorem.\"\r\n            full={<JordanBrouwer />}\r\n          ></PostPreview>\r\n          <PostPreview\r\n            date=\"2020-08-09\"\r\n            dummyID=\"5\"\r\n            name=\"Learning All Jōyō Kanji in a Month: A Reflection on and Criticism of Heisig's RTK\"\r\n            summary=\"I share my experience with arguably the most controversial book related to learning Japanese, pointing out the flaws I personally noticed as well as the strengths, and summarize my experience at different stages as well as overall. I try to describe what I believe its best use-case is, so that you may decide for yourself whether it will be a suitable technique.\"\r\n            full={<HeisigKanji />}\r\n          ></PostPreview>\r\n          <PostPreview\r\n            date=\"2020-08-01\"\r\n            dummyID=\"4\"\r\n            name=\"Universal Isomorphism Theorems\"\r\n            summary='Many algebraic structures and theorems have a similar feeling, ostensibly seen by the isomorphism theorems common to many of them. This is the motivation for universal algebra, and this post shows how it can be used to formulate the most general form of these isomorphism theorems. Lattices are also covered and used to more generally state and prove the \"fourth\" isomorphism theorem: the correspondence theorem. '\r\n            full={<UniversalIsomorphism />}\r\n          />\r\n          <PostPreview\r\n            date=\"2020-03-05\"\r\n            dummyID=\"3\"\r\n            name=\"Stacking (Mathematical) Records on a (Locally) Flat Earth\"\r\n            summary='Manifolds have a nice geometric intuition, with many examples seen when looking out any window. This is an introduction which formalizes (Euclidean) manifolds and smooth maps, culiminating to proving a cute theorem with nice visual intution: showing how you can pull apart a disk on one manifold to the union of multiple smaller disks on another manifold, \"stacking\" them on top of each other.'\r\n            full={<StackOfRecords />}\r\n          />\r\n          <PostPreview\r\n            date=\"2019-12-22\"\r\n            dummyID=\"2\"\r\n            name=\"Non-normal Spaces: the Moore Plane and Continuous Functions\"\r\n            summary='Topological normality, the ability to find space between distinct closed sets, seems like it should always be present (hence the name). However, this is not the case; the Moore plane is an easy-to-visualize counter-example. A theorem due to Jones which relies on different sizes of infinity is used to show that the Moore plane is, informally speaking, simply too \"tightly packed\" to be normal.'\r\n            full={<Normal />}\r\n          />\r\n          <PostPreview\r\n            date=\"2019-10-19\"\r\n            dummyID=\"1\"\r\n            name=\"Viewing Logarithms as Group Isomorphisms\"\r\n            summary=\"Logarithms are often used to make certain computations faster or easier to visualize. This is the result of a connection to group theory, with the logarithm being a special case of homomorphism, explicitly demonstrating why these types of maps are so useful.\"\r\n            full={<LogIso />}\r\n          />\r\n        </ul>\r\n      </div>\r\n    );\r\n  }\r\n}\r\n\r\nexport default Posts;\r\n","export default __webpack_public_path__ + \"static/media/tottori.f5f93e62.jpg\";","import React, { Fragment } from \"react\";\r\nimport { IconContext } from \"react-icons\";\r\nimport MobileDetector from \"../components/MobileDetector\";\r\n/* handles */\r\nimport {\r\n  RiInstagramFill,\r\n  RiMailSendFill,\r\n  RiGithubFill,\r\n  RiLinkedinBoxFill\r\n} from \"react-icons/ri\";\r\n/* contact photo */\r\nimport pfp from \"../media/tottori.jpg\";\r\n/* info from css */\r\nvar accentColour = \"#4c2a6e\";\r\nvar vh = window.innerHeight / 100;\r\n\r\nfunction Contact() {\r\n  const pfpAlt = \"Me riding a camel in the Tottori sanddunes\";\r\n  const isMobile = MobileDetector();\r\n  return (\r\n    <div className=\"coDiv contact\">\r\n      <table className=\"contactHead\">\r\n        {isMobile ? (\r\n          <span>\r\n            <tr>\r\n              <td className=\"contactPhoto\">\r\n                <img src={pfp} alt={pfpAlt}></img>\r\n              </td>\r\n            </tr>\r\n            <tr>\r\n              <td className=\"contactMessage\">\r\n                <h1>Thank you for reaching out!</h1>\r\n              </td>\r\n            </tr>\r\n          </span>\r\n        ) : (\r\n          <tr>\r\n            <td className=\"contactMessage\">\r\n              <h1>Thank you for reaching out!</h1>\r\n            </td>\r\n            <td className=\"contactPhoto\">\r\n              <img src={pfp} alt={pfpAlt}></img>\r\n            </td>\r\n          </tr>\r\n        )}\r\n      </table>\r\n      <IconContext.Provider value={{ color: accentColour, size: 8 * vh }}>\r\n        <table className=\"contactInfo\">\r\n          {isMobile ? (\r\n            <span>\r\n              <tr>\r\n                <td className=\"handleIcon\">\r\n                  <a href=\"https://www.instagram.com/kazachekalex/\">\r\n                    <RiInstagramFill />\r\n                  </a>\r\n                </td>\r\n                <td className=\"handle\">\r\n                  <a href=\"https://www.instagram.com/kazachekalex/\">\r\n                    {\" \"}\r\n                    @kazachekalex{\" \"}\r\n                  </a>\r\n                </td>\r\n              </tr>\r\n              <tr>\r\n                <td className=\"handleIcon\">\r\n                  <a href=\"mailto: alexdkazachek@gmail.com\">\r\n                    <RiMailSendFill />\r\n                  </a>\r\n                </td>\r\n                <td className=\"handle\">\r\n                  <a href=\"mailto: alexdkazachek@gmail.com\">\r\n                    {\" \"}\r\n                    alexdkazachek@gmail.com{\" \"}\r\n                  </a>\r\n                </td>\r\n              </tr>\r\n              <tr>\r\n                <td className=\"handleIcon\">\r\n                  <a href=\"https://github.com/akazachek\">\r\n                    <RiGithubFill />\r\n                  </a>\r\n                </td>\r\n                <td className=\"handle\">\r\n                  <a href=\"https://github.com/akazachek\"> akazachek </a>\r\n                </td>\r\n              </tr>\r\n              <tr>\r\n                <td className=\"handleIcon\">\r\n                  <a href=\"https://linkedin.com/in/kazachek\">\r\n                    <RiLinkedinBoxFill />\r\n                  </a>\r\n                </td>\r\n                <td className=\"handle\">\r\n                  <a href=\"https://linkedin.com/in/kazachek\"> kazachek </a>\r\n                </td>\r\n              </tr>\r\n            </span>\r\n          ) : (\r\n            <Fragment>\r\n              <tr>\r\n                <td className=\"handleIcon\">\r\n                  <a href=\"https://www.instagram.com/kazachekalex/\">\r\n                    <RiInstagramFill />\r\n                  </a>\r\n                </td>\r\n                <td className=\"handle\">\r\n                  <a href=\"https://www.instagram.com/kazachekalex/\">\r\n                    {\" \"}\r\n                    @kazachekalex{\" \"}\r\n                  </a>\r\n                </td>\r\n                <td className=\"handleIcon\">\r\n                  <a href=\"mailto: alexdkazachek@gmail.com\">\r\n                    <RiMailSendFill />\r\n                  </a>\r\n                </td>\r\n                <td className=\"handle\">\r\n                  <a href=\"mailto: alexdkazachek@gmail.com\">\r\n                    {\" \"}\r\n                    alexdkazachek@gmail.com{\" \"}\r\n                  </a>\r\n                </td>\r\n              </tr>\r\n              <tr>\r\n                <td className=\"handleIcon\">\r\n                  <a href=\"https://github.com/akazachek\">\r\n                    <RiGithubFill />\r\n                  </a>\r\n                </td>\r\n                <td className=\"handle\">\r\n                  <a href=\"https://github.com/akazachek\"> akazachek </a>\r\n                </td>\r\n                <td className=\"handleIcon\">\r\n                  <a href=\"https://linkedin.com/in/kazachek\">\r\n                    <RiLinkedinBoxFill />\r\n                  </a>\r\n                </td>\r\n                <td className=\"handle\">\r\n                  <a href=\"https://linkedin.com/in/kazachek\"> kazachek </a>\r\n                </td>\r\n              </tr>\r\n            </Fragment>\r\n          )}\r\n        </table>\r\n      </IconContext.Provider>\r\n    </div>\r\n  );\r\n}\r\n\r\nexport default Contact;\r\n","import React from \"react\";\nimport \"./App.css\";\nimport { BrowserRouter as Router, Route } from \"react-router-dom\";\nimport NavBar from \"./components/NavBar\";\n\n/* pages in navbar */\nimport About from \"./contents/About\";\nimport Posts from \"./contents/Posts\";\nimport Contact from \"./contents/Contact\";\n\nfunction App() {\n  \n  return (\n    <Router>\n      <div className=\"App\">\n        <NavBar />\n        {/* this will load the 'About' page by default but will not work locally */}\n        <Route exact path=\"/\">\n          <About />\n        </Route>\n        <Route path=\"/Posts\">\n          <Posts />\n        </Route>\n        <Route path=\"/Contact\">\n          <Contact />\n        </Route>\n      </div>\n    </Router>\n  );\n  \n}\n\nexport default App;","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport \"./index.css\";\nimport App from \"./App\";\nimport reportWebVitals from \"./reportWebVitals\";\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}