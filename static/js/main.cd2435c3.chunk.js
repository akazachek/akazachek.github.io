(this["webpackJsonpakazachek.github.io"]=this["webpackJsonpakazachek.github.io"]||[]).push([[0],{32:function(e,t,a){},33:function(e,t,a){},42:function(e,t,a){"use strict";a.r(t);var i=a(1),n=a(2),s=a.n(n),o=a(24),r=a.n(o),h=(a(32),a(33),a(18)),l=a(8),c=a(4),d=a(7),m=a(6),u=a(5),b=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(e){var i;return Object(c.a)(this,a),(i=t.call(this,e)).state={classes:"hvr-sweep-to-right"},i}return Object(d.a)(a,[{key:"componentDidMount",value:function(){"Who Am I?"==this.props.item&&this.setState({classes:"hvr-sweep-to-right navActive"})}},{key:"render",value:function(){return Object(i.jsx)("li",{id:this.props.item,class:this.state.classes,children:Object(i.jsx)(h.b,{to:this.props.tolink,onClick:this.props.click.bind(this,this.props.item),children:this.props.item})})}}]),a}(n.Component),f=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(e){var i;return Object(c.a)(this,a),(i=t.call(this,e)).handleClick=function(e){i.state.NavActiveItem.length>0&&document.getElementById(i.state.NavActiveItem).classList.remove("navActive"),i.setState({NavActiveItem:e},(function(){document.getElementById(i.state.NavActiveItem).classList.add("navActive")}))},i.state={NavActiveItem:"Who Am I?"},i}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsx)("div",{class:"navContainer",children:Object(i.jsx)("nav",{children:Object(i.jsxs)("ul",{children:[Object(i.jsx)(b,{item:"Who Am I?",tolink:"/",click:this.handleClick}),Object(i.jsx)(b,{item:"Posts",tolink:"/Posts",click:this.handleClick}),Object(i.jsx)(b,{item:"Contact",tolink:"/Contact",click:this.handleClick})]})})})}}]),a}(n.Component),p=a.p+"static/media/me.0ea85df1.jpg",g=a.p+"static/media/cv.0ec6bd6a.pdf",j=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){var e;Object(c.a)(this,a);for(var i=arguments.length,n=new Array(i),s=0;s<i;s++)n[s]=arguments[s];return(e=t.call.apply(t,[this].concat(n))).state={pfpAlt:"Headshot",cvDate:"2021-01-13"},e}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsx)("div",{className:"coDiv",children:Object(i.jsxs)("div",{className:"about",id:"aboutSec",children:[Object(i.jsx)("img",{src:p,alt:this.state.pfpAlt,className:"pfp"}),Object(i.jsx)("br",{}),Object(i.jsx)("h1",{children:" Hey, I'm Alex! "}),Object(i.jsxs)("h3",{style:{paddingTop:"1vh"},children:[" ","I'm a second year undergraduate at"," ",Object(i.jsx)("a",{href:"https://www.uwo.ca/",children:"UWO"})," studying mathematics and data science."]}),Object(i.jsx)("br",{}),Object(i.jsxs)("p",{children:["Some things I've been involved with are organizing the"," ",Object(i.jsx)("a",{href:"http://cumc.math.ca/2020",children:"2020 CUMC"}),", a mathematics conference which brought in over 100 students across North America. A large part of my role was setting up the industry panel, consisting of a few former mathematics students now working in finance and software."]}),Object(i.jsxs)("p",{children:["I'm also an executive for"," ",Object(i.jsx)("a",{href:"https://www.uwo.ca/math/macaw/index.html",children:"MaCAW"}),". A few of the contributions I've made are starting biweekly mathematics contests (with prizes!), and student seminars, so everyone has a chance to share some of the things they've worked on throughout the year."]}),Object(i.jsxs)("p",{children:["A non-mathematical topic I find interesting is linguistics. I'm fascinated with the different approaches languages take to communicate the same ideas, and their unique perspectives. One of my favourite examples is describing colour: Japanaese doesn't distinguish between ",Object(i.jsx)("i",{children:"green"})," and ",Object(i.jsx)("i",{children:"blue"})," like English, and instead treats both as \u9752\u3044, whereas Russian further separates"," ",Object(i.jsx)("i",{children:"blue"})," and ",Object(i.jsx)("i",{children:"light blue"})," as ",Object(i.jsx)("i",{children:"\u0441\u0438\u043d\u0438\u0439"})," and ",Object(i.jsx)("i",{children:"\u0433\u043e\u043b\u0443\u0431\u043e\u0439"}),". Incidentally, I know (varying degrees of) those 3 languages."]}),Object(i.jsx)("p",{children:"Programming is also something I have picked up, both in school and on my own. My strongest languages are Python and Java, and I know a few others. This website is primarily written using React.js; mathematics is powered by \\(\\KaTeX\\)."}),Object(i.jsx)("p",{children:"In my free time I enjoy speedrunning (my favourite speedgames are Mirror's Edge and Fallout 4). I'm also interested in finance, working on the trading podcast Nikkei Bets with my friend. Typography is also somewhat of a passion of mine, and I spend perhaps a little bit too much time working on the small details in all my \\(\\LaTeX\\) templates."}),Object(i.jsxs)("p",{class:"cv",children:[" ","My full CV is available"," ",Object(i.jsx)("a",{id:"cvLink",href:g,children:"here"})," ","and was last updated ",this.state.cvDate,"."]})]})})}}]),a}(n.Component),y=a(26),w=a(23),v=function(e){var t=Object(n.useState)(!1),a=Object(y.a)(t,2),s=a[0],o=a[1],r=Object(w.b)(s,null,{from:{zIndex:-1,opacity:0,transform:"translateX(-30vw)"},enter:{zIndex:-1,opacity:1,transform:"translateX(0vw)"},leave:{zIndex:-1,opacity:0,transform:"translateX(-30vw)"}});return Object(i.jsxs)("div",{children:[Object(i.jsxs)("li",{className:"postPreview",id:e.date,onClick:function(){return o((function(e){return!e}))},children:[Object(i.jsx)("table",{className:"postHead",children:Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"postTitle",children:Object(i.jsx)("h2",{children:e.name})}),Object(i.jsx)("td",{className:"postDate",children:Object(i.jsx)("h4",{children:e.date})})]})}),Object(i.jsx)("div",{children:Object(i.jsx)("p",{id:e.dummyID,className:"postSummary",children:e.summary})})]}),r.map((function(t){var a=t.item,n=t.key,s=t.props;return a&&Object(i.jsx)(w.a.div,{className:"post",style:s,children:e.full},n)}))]})},x=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsxs)("table",{class:"figureContainer",children:[Object(i.jsx)("tr",{children:Object(i.jsx)("td",{class:"figure",children:Object(i.jsx)("img",{src:this.props.src,alt:this.props.caption})})}),Object(i.jsx)("tr",{children:Object(i.jsx)("td",{class:"caption",children:Object(i.jsxs)("h4",{children:["Figure ",this.props.no,": ",this.props.caption]})})})]})}}]),a}(n.Component),k=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(e){var i;return Object(c.a)(this,a),(i=t.call(this,e)).state={theoremTitle:null==i.props.name?null==i.props.no?"Theorem. ":"Theorem "+e.no+". ":null==i.props.no?"Theorem ("+e.name+"). ":"Theorem "+e.no+" ("+e.name+"). "},i}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsx)("div",{class:"theorem",children:Object(i.jsxs)("p",{children:[Object(i.jsx)("strong",{children:this.state.theoremTitle}),Object(i.jsx)("i",{children:this.props.statement})]})})}}]),a}(n.Component),_=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsx)("div",{class:"proof",children:Object(i.jsxs)("p",{children:[Object(i.jsx)("i",{children:"Proof. "}),this.props.proof,Object(i.jsx)("span",{style:{float:"right"},children:"\\(\\square\\)"})]})})}}]),a}(n.Component),O=a.p+"static/media/fig1(koch).b55a4c6d.png",I=a.p+"static/media/fig2(transv).eaa3dc15.png",A=a.p+"static/media/fig3(wind).3c138aea.png",T=a.p+"static/media/fig4(gp).52edce34.jpg",B=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"componentDidMount",value:function(){window.KaTeXRender()}},{key:"render",value:function(){return Object(i.jsxs)("div",{class:"postContent",children:[Object(i.jsx)("p",{children:"If I were to draw a circle or some polygon, like a square, on a piece of paper, and ask you to identify the inside and outside, you would likely look at me as if I had gone mad. It is incredibly easy to both define what the inside is and identify where it lies, as these curves can be described by a product of intervals, or some simple parametrization. But what of, say, the Koch snowflake, as in figure 1? The precise curve is actually the limit case of the figure - a fractal. The curve is still continuous, being without holes, and does not overlap (except at the beginning and end). However, its perimetre is infinite, and its parametrization is nowhere differentiable. How would you formally describe what lies inside it? In fact, for a curve like this it is not unreasonable to suspect that may not be well-defined in the first place; perhaps some point behaves weirdly in the limit case and cannot be simply classified."}),Object(i.jsx)(x,{no:"1",src:O,caption:"Koch snowflake"}),Object(i.jsxs)("p",{children:["Thankfully someone, specifically Jordan, proved we don't need to worry about such a thing. His result on these curves gave them a special name, ",Object(i.jsx)("strong",{children:"Jordan curves"}),". These are simple closed curves on the plane, meaning they are continuous curves in"," ","\\(\\mathbb{R}^2\\)"," with no self-intersections, except at the start and end. His precise result was as follows."]}),Object(i.jsx)(k,{name:"Jordan",statement:"\r Every Jordan curve divides the plane into two components, an unbounded exterior and a bounded interior, such that the curve is the boundary of each component."}),Object(i.jsx)("p",{children:'What is interesting is that such a seemingly "obvious" result, something that every school child understands implicitly when they are told to "colour inside the lines", has an entirely non-obvious proof. Indeed, even today there are no easy proofs of it. They all span multiple pages, and use machinery which, at least on the surface, appears to be overkill for such a simple sounding statement.'}),Object(i.jsxs)("p",{children:["This can actually be considered as a special case of a stronger result proved by Brouwer a few decades after Jordan's initial publication. However, to get there we will need a few definitions. I have already discussed manifolds in the past, however there is an object which slightly generalizes them. We call these"," ",Object(i.jsx)("strong",{children:"manifolds with boundary"}),". While a \\(k\\)-manifold is diffeomorphic to ","\\(\\mathbb{R}^k\\)",", we require only that manifolds with boundary are diffeomorphic to the"," ",Object(i.jsx)("strong",{children:"upper-half plane "}),"\\[\\mathcal{H}^k:=\\{(x_1,\\dots x_k)\\in\\mathbb{R}^k : x_k\\geq 0\\}.\\]"]}),Object(i.jsxs)("p",{children:["Visually, the obvious notion of a boundary on the upper-half plane occurs precisely where \\(x_k=0\\), and we denote it by"," ","\\(\\partial\\mathcal{H}^k\\)",". It is important to note that this is completely different from a topological boundary, even though we use the same notation. A manifold with boundary \\(X\\) of dimension \\(k\\), then, has a neighbourhood around each point diffeomorphic to"," ","\\(\\mathcal{H}^k\\)",", and its boundary \\(\\partial X\\) is the set of points which lie in ","\\(\\partial\\mathcal{H}^k\\)"," under some set of local coordinates (one can show this is well-defined and will in fact be identical for any arbitrary system). It is immediate the boundary then is itself a manifold of dimension \\(k-1\\), as we can parametrize it to ","\\(\\mathbb{R}^{k-1}\\)"," by cutting off the last coordinate (as it will always be \\(0\\)), and composing."]}),Object(i.jsx)("p",{children:"Of note is that any compact, connected \\(1\\)-manifold with boundary is diffeomorphic to the unit interval \\([0,1]\\) or to the unit circle \\(S^1\\) (visually, compactness and connectedness means you can only end somewhere or loop back to where you started). This is actually non-trivial to show as well, much like the Jordan curve theorem, despite being intuitively quite obvious. We will take it for granted, as we will need the following fact later."}),Object(i.jsx)(k,{no:"1",statement:"\r Every compact \\(1\\)-manifold with boundary has an even number of points in its boundary."}),Object(i.jsx)(_,{proof:"\r Every component will be diffeomorphic to \\([0,1]\\) or \\(S^1\\), which have \\(2\\) and \\(0\\) points in the boundary, respectively."}),Object(i.jsxs)("p",{children:["This is the only definition we need to generalize Jordan's result. We call a manifold ","\\(X\\subseteq\\mathbb{R}^n\\)"," a"," ",Object(i.jsx)("strong",{children:"hypersurface"})," if it is of dimension \\(n-1\\) (note that this can be generalized to submanifolds and codimensions, but we will not need that)."]}),Object(i.jsx)(k,{name:"Jordan-Brouwer",statement:"\r If \\(X\\) is a compact, connected hypersurface in \\(\\mathbb{R}^n\\), then \\(\\mathbb{R}^n\\setminus X\\) consists of two open connected components, \\(D_0\\) and \\(D_1\\), such that \\(\\overline{D_0}\\) is a compact manifold with boundary, and in particular \\(\\partial\\overline{D_0}=X\\)."}),Object(i.jsx)("p",{children:"Perhaps being slightly misleading, I will not be talking about the Jordan-Brouwer theorem itself in this post. Instead, I will be talking about something intimately related to it. To prove this theorem, we must at some point have candidates for \\(D_0\\) and \\(D_1\\), and this is what I will be discussing: how do we define inside and outside in the first place?"}),Object(i.jsxs)("p",{children:["The first stop is at the intersections of curves. Recall that there is a nice condition for when the preimage of a map \\(f\\colon X\\to Y\\) would have ","\\(f^{-1}(y)\\)"," be a manifold. Specifically, it was when \\(y\\) was a regular value, meaning \\(df_x\\) was surjective at each point ","\\(x\\in f^{-1}(y)\\)",". This is, in fact, a special case of the more general concept of"," ",Object(i.jsx)("strong",{children:"transversal intersections"}),". In particular, \\(f\\) is transversal to a submanifold \\(Z\\subseteq Y\\), written \\(f\\pitchfork Z\\), if ","\\(T_{f(x)}(Z)+\\operatorname{im}df_x=T_{f(x)}(Y)\\)"," for every ","\\(x\\in f^{-1}(Z)\\)","."]}),Object(i.jsx)(k,{no:"2",statement:"\r For smooth \\(f\\colon X\\to Y\\) with \\(Z\\) a submanifold of \\(Y\\), then \\(f^{-1}(Z)\\) is a submanifold of \\(X\\) if \\(f\\pitchfork Z\\)."}),Object(i.jsx)(_,{proof:"Consider some \\(x\\in f^{-1}(Z)\\), and let \\(y=f(x)\\). Let \\(\\ell=\\operatorname{codim}Z\\). Take local coordinates around \\(y\\) such that the last \\(\\ell\\) coordinates vanish on \\(Y\\setminus Z\\) (locally); call these last \\(\\ell\\) coordinates \\(g=(g_1,\\dots,g_\\ell)\\). Consider the composition \\(g\\circ f\\colon f^{-1}(Z)\\to\\mathbb{R}^\\ell\\), and note \\[d(g\\circ f)_x=dg_y\\circ df_x.\\] As\\(f\\pitchfork Z\\), this derivative is surjective at \\(x\\). However, \\(x\\) was an arbitrary point in the preimage and we have \\((g\\circ f)(x)=0\\), meaning \\(0\\) is a regular value of \\(f\\). Then, \\(f^{-1}(Z)=(g\\circ f)^{-1}(0)\\) is a submanifold. "}),Object(i.jsx)("p",{children:"This is a very visual idea, essentially meaning that tangent spaces add up to the ambient space. However, this has the caveat of therefore being dependent on the ambient space, and so intersections transversal in one setting may not be transversal elsewhere. This is demonstrated in figure 2 below."}),Object(i.jsx)(x,{no:"2",src:I,caption:"Transversal intersection (left) and non-transversal intersection (right)"}),Object(i.jsxs)("p",{children:["This is quite a nice, simple condition to verify if a preimage will be a submanifold, and captures the spirit of differential topology: for us to learn about behaviour globally (being a manifold), we reduce it to local linear behaviour (a union of vector spaces). However, there is the very real question of whether intersections like this exist, in general. After all, intersections can be very tricky. If we take any function ","\\(\\mathbb{R}\\to\\mathbb{R}\\)"," which crosses the \\(x\\)-axis, any slight variation of that function will undoubtedly move that crossing point, and so it is very hard, in general, to find a function which has a root at a specific value (outside of contrived examples). Might it be the same for transversal intersections? Thankfully, no; in fact, essentially all intersections are transversal, and these intersections are not affected by perturbations. To formalize this idea, we introduce homotopy."]}),Object(i.jsxs)("p",{children:["Two maps \\(f_0,f_1\\colon X\\to Y\\) are ",Object(i.jsx)("strong",{children:"homotopic"}),", written \\(f_0\\sim f_1\\), if there exists some smooth map \\(F\\colon X\\times [0,1]\\to Y\\) such that \\(F(x,0)=f_0(x)\\) and \\(F(x,1)=f_1(x)\\). A property of \\(f_0\\) is said to be"," ",Object(i.jsx)("strong",{children:"stable"})," if for any homotopy \\(F(x,t)\\eqqcolon f_t(x)\\), there exists some \\(\\varepsilon \\gt 0\\) such that \\(f_t\\) has that property when \\(t \\lt \\varepsilon\\). A great deal of interesting properties are stable, such as embeddings, submersions, etc. In particular, as transversal intersections at the heart rely on submersions, it follows that they are stable as well. The proofs for these all essentially rely on these conditions being a statement about the determinant of some matrix, by the inverse function theorem, and the determinant function being continuous."]}),Object(i.jsx)("p",{children:"What is far more interesting is that transversality is generic, meaning that given any smooth map \\(f\\) and any submanifold \\(Z\\), we can find some \\(g\\) homotopic to \\(f\\) so \\(g\\pitchfork Z\\). This is quite remarkable given that the behaviour of \\(f\\) with respect to \\(Z\\) can be as pathological as we want - we need only to slightly wiggle it to get a nice intersection. Proving transversal intersections are generic is dry and lengthy (it would involve numerous technical lemmas, all for a rather technical result). It could be a whole post in and of itself, so instead I will simply state the two results we will need."}),Object(i.jsx)(k,{no:"2",name:"Transversality-Homotopy",statement:"\r Let \\(f\\colon X\\to Y\\) be smooth between a manifold \\(X\\) and a boundaryless manifold \\(Y\\). If \\(Z\\) is a boundaryless submanifold of \\(Y\\), there is some smooth \\(g\\sim f\\) such that \\(g\\pitchfork Z\\) and \\(\\partial g\\pitchfork Z\\), where \\(\\partial g :\\equiv g\\vert_{\\partial X}\\)."}),Object(i.jsxs)("p",{children:["For \\(f\\colon X\\to Y\\) we say that \\(f\\pitchfork Z\\) on a subset \\(C\\) of \\(X\\) if ","\\(f\\vert_{C\\cap f^{-1}(Z)}\\pitchfork Z\\)",". We can slightly strengthen theorem 2, useful in some situations."]}),Object(i.jsx)(k,{no:"3",name:"Extension",statement:"\r Let \\(f\\colon X\\to Y\\) be smooth between a manifold \\(X\\) and a boundaryless manifold \\(Y\\), and \\(C\\subseteq X\\) be closed. If \\(Z\\) is a closed boundaryless submanifold of \\(Y\\) such that \\(f\\pitchfork Z\\) on \\(C\\) and \\(\\partial f\\pitchfork Z\\) on \\(C\\cap\\partial X\\), there is some \\(g\\sim f\\) such that \\(g\\pitchfork Z\\) and \\(\\partial g\\pitchfork Z\\) and \\(g\\equiv f\\) on a neighbourhood of \\(C\\)."}),Object(i.jsxs)("p",{children:["We will use these to continue our trek toward the main result, and that is determining what lies inside and outside a hypersurface. We will do this with transversal intersections of a specific function and a special invariant. This invariant will come from the"," ",Object(i.jsx)("strong",{children:"intersection number"}),". For \\(f\\colon X\\to Y\\) and \\(f\\pitchfork Z\\) a closed submanifold of \\(Y\\), such that"," ","\\(\\operatorname{dim}X+\\operatorname{dim}Z=\\operatorname{dim}Y\\)",", we define the intersection number modulo 2 of \\(f\\) with respect to \\(Z\\), written \\(I_2(f,Z)\\), to be"," ","\\(\\left|f^{-1}(Z)\\right|_2\\)"," (the cardinality of the preimage modulo 2). Observe that due to the condition on our dimensions,"," ","\\(f^{-1}(Z)\\)"," will be a manifold of dimension \\(0\\) (hence a finite set), so the intersection number is well-defined. Of course, not all maps will intersect \\(Z\\) transversally, but recall that transversality is generic, and theorem 1 gives us a nice statement about cardinalities of boundaries modulo 2, to get the following result."]}),Object(i.jsx)(k,{no:"4",statement:"\r If \\(f_0,f_1\\colon X\\to Y\\) are homotopic so \\(f_0\\pitchfork Z\\) and \\(f_1\\pitchfork Z\\), where \\(Z\\) is a closed submanifold of \\(Y\\) so \\(\\operatorname{dim}X+\\operatorname{dim}Z=\\operatorname{dim}Y\\), then \\(I_2(f_0,Z)=I_2(f_1,Z)\\)."}),Object(i.jsx)(_,{proof:"\r Let \\(F\\colon X\\times [0,1]\\to Y\\) be a homotopy of \\(f_0\\) and \\(f_1\\). Without loss of generality, take \\(F\\pitchfork Z\\), for otherwise observe that \\(F\\pitchfork Z\\) on \\(X\\times \\{0,1\\}\\) (as \\(f_0\\) and \\(f_1\\) are both transversal), which is closed in \\(X\\times [0,1]\\). Then, the extension theorem lets us take some \\(G\\sim F\\) so \\(G\\pitchfork Z\\) yet \\(G\\equiv F\\) on \\(X\\times \\{0,1\\}\\) (in fact, it will be true on a neighbourhood thereof), hence \\(G(x,0)=f_0(x)\\) and \\(G(x,1)=f_1(x)\\).\\[\\] \r Now, note that \\(\\partial (X\\times [0,1])=X\\times\\{0\\}\\cup X\\times\\{1\\}\\), hence \\(F\\equiv f_0\\) or \\(F\\equiv f_1\\) on \\(\\partial (X\\times [0,1])\\), so \\(\\partial F\\pitchfork Z\\). Then,\r \\[\r \\operatorname{dim}(X\\times [0,1])-\\operatorname{dim}F^{-1}(Z) =\\operatorname{dim}X+1-\\operatorname{dim}F^{-1}(Z)=\\operatorname{dim}Y-\\operatorname{dim}Z\r \\]\r and our assumptions on dimensions means \\(\\operatorname{dim}F^{-1}(Z)=1\\). Observe that\r \\[\r \\begin{aligned}\r \\partial F^{-1}(Z)&=F^{-1}(Z)\\cap\\partial(X\\times [0,1])\\\\\r &=F^{-1}(Z)\\cap(X\\times\\{0\\})\\cup F^{-1}(Z)\\cap(X\\times\\{1\\})\\\\\r &=f_0^{-1}(Z)\\cup f_1^{-1}(Z)\r \\end{aligned}\r \\]\r however, by theorem 1, this means \\(I_2(f_0,Z)=I_2(f_1,Z)\\), as desired. "}),Object(i.jsx)(k,{no:"5",name:"Boundary",statement:"\r If \\(W\\) is compact with \\(\\partial W=X\\), and \\(g\\colon X\\to Y\\) can be extended to \\(W\\), then \\(I_2(g,Z)=0\\) for all closed submanifolds \\(Z\\) in \\(Y\\) such that \\(\\operatorname{dim}X+\\operatorname{dim}Z=\\operatorname{dim}Y\\)."}),Object(i.jsx)(_,{proof:"\r Say \\(G\\) is the extension of \\(g\\). By transversality-homotopy, take \\(F\\sim G\\) so \\(F\\pitchfork G\\) and \\(\\partial F\\pitchfork G\\). Observe that \\(\\partial G=g\\) and \\(\\partial F=: f\\sim g\\). Therefore, \\(I_2(g,Z)=|f^{-1}(Z)|_2\\) by theorem 4, but as \\(F^{-1}(Z)\\) is a \\(1\\)-manifold with boundary, \\(I_2(g,Z)=0\\) by theorem 1."}),Object(i.jsx)("p",{children:"Then, for an arbitrary map \\(g\\) (with all the same conditions as before), we can define \\(I_2(g,Z)=I_2(f,Z)\\), where \\(f\\sim g\\) is an arbitrary homotopy transversal to \\(Z\\), which will exist by transversality-homotopy. Our next step in constructing this invariant is to exploit that our hypersurface will be connected."}),Object(i.jsx)(k,{no:"6",statement:"If \\(f\\colon X\\to Y\\) is smooth with equidimensional compact \\(X\\) and connected \\(Y\\), then \\(I_2(f,\\{y\\})\\) is invariant under choice of \\(y\\in Y\\)."}),Object(i.jsx)(_,{proof:"\r Without loss of generality, assume \\(f\\pitchfork \\{y\\}\\) (note this is identical to assuming \\(y\\) is a regular value). By the stack of records theorem (proved in an earlier post of mine), there is a neighbourhood \\(U\\) of \\(y\\) such that \\(f^{-1}(U)=\\dot{\\bigcup}_{k=1}^n V_k\\) where each \\(V_k\\) is open in \\(X\\) and \\(f\\) is locally diffeomorphic on each.\\[\\]\r Then, \\(I_2(f,\\{z\\})=n\\) for any \\(z\\in U\\), and so the map \\(y\\mapsto I_2(f,\\{y\\})\\) is locally constant on \\(U\\). As \\(Y\\) is connected, this extends to a globally constant map."}),Object(i.jsxs)("p",{children:["We call this value the modulo 2 ",Object(i.jsx)("strong",{children:"degree"})," of \\(f\\), written ","\\(\\operatorname{deg}_2 f\\)",". Now, we begin the construction. Let \\(X\\) be a compact, connected manifold (we will shortly examine hypersurfaces in particular) in"," ","\\(\\mathbb{R}^n\\)",", with ","\\(f\\colon X\\to\\mathbb{R}^n\\)"," ","smooth and for ","\\(z\\in\\mathbb{R}^n\\setminus f(X)\\)"," define the"," ",Object(i.jsx)("strong",{children:"unit vector"}),"\\[u_z\\colon X\\to S^{n-1}\\textrm{ by }u_z(x)=\\frac{f(x)-z}{|f(x)-z|}.\\]"]}),Object(i.jsxs)("p",{children:["Note that \\(u_z\\) satisfies the hypotheses of theorem 6, hence we can consider ","\\(\\operatorname{deg}_2 u_z\\)",". Observe that, geometrically, this is the number (modulo 2) of points \\(x\\in X\\) whose unit vector from \\(f(x)\\) to \\(z\\) will point in a particular direction (as we compute the degree by fixing some vector in"," ","\\(S^{n-1}\\)","). Thus, we call this the winding number modulo 2 of \\(f\\) around \\(z\\), written"," ","\\(W_2(f,z):=\\operatorname{deg}_2 u_z\\)",". A visual representation is seen below in figure 3."]}),Object(i.jsx)(x,{no:"3",src:A,caption:"A particular unit vector \\(u_z\\) with points in its preimage (blue). Here, \\(W_2(f,z)=1\\)."}),Object(i.jsx)("p",{children:'This winding number is the key to the separation theorem. We will use it to compute what is "inside" and "outside", and we begin with a technical result.'}),Object(i.jsx)(k,{no:"7",statement:"\r Let \\(f\\colon X\\to\\mathbb{R}^n\\) be smooth with \\(D\\) a compact manifold with boundary \\(X\\) such that \\(F\\colon D\\to\\mathbb{R}^n\\) extends \\(f\\). If \\(z\\notin f(X)\\) is a regular value of \\(F\\), then \\(F^{-1}(Z)\\) is finite and \\(|F^{-1}(z)|\\equiv_2 W_2(f,z)\\). "}),Object(i.jsx)(_,{proof:"\r Suppose \\(F^{-1}(z)=\\varnothing\\). As \\(f\\) can be extended to \\(D\\), so can the unit vector \\(u_z\\) as \\(F(x)\\neq z\\) for all \\(x\\in D\\), so it is well-defined. Then, by the boundary theorem, we have that\r \\[\r \\operatorname{deg}_2 u_z=0=W_2(f,z)=|\\varnothing|\r \\]\r as the degree is defined as an intersection number. \\[\\]\r Suppose now \\(F^{-1}(z)=\\{x_1,\\dots ,x_\\ell\\}\\). For each \\(x_i\\), take a closed ball of radius \\(\\varepsilon_i\\) around \\(x_i\\), call it \\(\\mathcal{B}_i(x_i,\\varepsilon_i)\\), small enough such that the \\(\\mathcal{B}_i\\) are disjoint from each other and from \\(X\\). Define \\(g_i\\colon\\partial\\mathcal{B}_i\\to\\mathbb{R}^n\\) as a restriction of \\(F\\), and let \\(D_k:=D\\setminus\\dot{\\bigcup}_{i=1}^k\\operatorname{int}\\mathcal{B}_i\\), \\(X_k:=\\partial D_k\\), and \\(f_k:=F\\vert_{X_k}\\). \\[\\]\r Now, note that \\(W_2(f_0,z)=W_2(f,z)\\), and\r \\[\r W_2(f_k,z)=W_2(f_{k-1},z)+W_2(g_k,z).\r \\]\r Thus,\r \\[\r W_2(f_\\ell,z)=W_2(f_{\\ell-1},z)+W_2(g_\\ell,z)=W_2(g_1,z)+\\cdots +W_2(g_1,z)+W_2(f_0,z).\r \\]\r As \\(z\\notin D_\\ell\\), we can extend \\(f_\\ell\\) to \\(D_\\ell\\), hence by the boundary theorem \\(W_2(f_\\ell,z)=0\\), meaning\r \\[\r -W_2(f_0,z)=-W_2(f,z)=W_2(g_1,z)+\\cdots+W_2(g_\\ell,z).\r \\]\r By \\(z\\) being a regular value and the balls being disjoint, we know \\(F\\) is locally diffeomorphic in some neighbourhood of the closed balls. Restricting the unit vector map (induced by \\(g_k\\)) will have it be bijective, hence \\(W_2(g_k,z)=1\\), and taking everything modulo \\(2\\) we are done."}),Object(i.jsx)("p",{children:'One can apply theorem 7 to the case where \\(X\\) is a hypersurface and \\(f=\\imath\\) is the inclusion. If one can prove that the complement of \\(X\\) consists of two connected sets, each open with \\(X\\) being their boundary, with one bounded and one unbounded, then it will precisely state that \\(W_2(X,z):=W_2(\\imath,z)\\) (this is what we mean when we talk about winding numbers of manifolds) is equal to the number of points in the preimage of the extension of the inclusion map. That is, the winding number will be equal to \\(1\\) if it lies "inside" and \\(0\\) if it lies "outside". This is the invariant we seek to compute, which we will do using the following curve.'}),Object(i.jsxs)("p",{children:["Given ","\\(z\\in\\mathbb{R}^n\\setminus X\\)"," in the complement of our compact, connected hypersurface, we define a ",Object(i.jsx)("strong",{children:"ray"})," ","emanating from \\(z\\) in the direction of \\(v\\) to be"," ","\\[r:=\\{z+tv:0\\leq t\\in\\mathbb{R}\\}.\\]","."]}),Object(i.jsx)(k,{no:"8",statement:"\r A ray \\(r\\) from \\(z\\) in the direction of \\(v\\) is transversal to \\(X\\) if and only if \\(v\\) is a regular value of the unit vector \\(u_z\\)."}),Object(i.jsx)(_,{proof:"\r Suppose that \\(r\\pitchfork X\\). Then,\r \\[\r T_x(X)+\\operatorname{im}dr_t=T_x(\\mathbb{R}^n)=\\mathbb{R}^n\r \\]\r for any \\(x\\in X\\cap r\\), where \\(x=z+tv\\). With \\(v=(v_1,\\dots, v_n)\\), we know that\r \\[\r dr_t=\\begin{pmatrix}\r v_1 & \\cdots & v_n\r \\end{pmatrix}^T(t)\r \\]\r and so the image under \\(\\mathbb{R}\\) is just the ray extended to the line. Then, recall that \\(u_z(x)=(x-z)/|x-z|\\) (as our map \\(f\\) here is just the inclusion), and \\(v\\) is a regular value if and only if for all \\(x\\) such that \\(u_z(x)=v\\) we have \\(d(u_z)_x=\\mathbb{R}^{n-1}\\). This, however, happens if and only if \\(T_x(X)\\perp \\{tv:t\\in\\mathbb{R}\\}\\), precisely equivalent to our transversality condition."}),Object(i.jsx)(k,{no:"9",statement:"\r Let \\(r\\) be a ray emanating from \\(z_0\\) in the direction \\(v\\) so \\(r\\pitchfork X\\). Let \\(z\\neq z_0\\) be in the complement of \\(X\\) but on \\(r\\), with \\(\\ell\\) being the number of intersections of \\(r\\) and \\(X\\) between \\(z\\) and \\(z_0\\). Then, \\(W_2(X,z_0)=W_2(X,z)+\\ell\\) all modulo \\(2\\). "}),Object(i.jsx)(_,{proof:"\r Observe that, by theorem 8, we must have that \\(v\\) is a regular value of both \\(u_z\\) and \\(u_{z_0}\\) by theorem 8. Therefore, \\(W_2(X,z)=|u_z^{-1}(v)|_2\\) and \\(W_2(X,z_0)=|u_{z_0}^{-1}(v)|_2\\). Therefore, \\(W_2(X,z_0)=W_2(X,z)+\\ell\\), for if \\(x\\in u_z^{-1}(v)\\) lies after \\(z\\) but before \\(z_0\\), then \\(u_{z_0}(x)=-v\\), hence not contributing to the winding number. "}),Object(i.jsx)("p",{children:"At last, we have our central result. Recall that we are assuming we have already proven the complement of our hypersurface consists of the two components as posited in the Jordan-Brouwer theorem statement, and so theorem 7 tells points in the same component have the same winding number."}),Object(i.jsx)(k,{no:"10",statement:"\r Let \\(r\\) be a ray emanating from \\(z\\) in the direction of \\(v\\), such that \\(r\\pitchfork X\\). Then, \\(z\\) lies inside \\(X\\) if and only if \\(r\\) intersects \\(X\\) an odd number of times."}),Object(i.jsx)(_,{proof:"\r Observe that, as \\(X\\) is compact, we can find some \\(z_0\\) outside of \\(X\\) such that \\(W_2(X,z)=0\\). By theorem 9, then, \\(W_2(X,z)+\\ell=W_2(X,z_0)=0\\), meaning \\(W_2(X,z)=-\\ell\\) all modulo 2. However, as \\(z_0\\) was outside with winding number \\(0\\), this means \\(z\\) will be outside as well if and only if \\(-\\ell=0\\) modulo 2, equivalently if and only if \\(\\ell\\) is even. "}),Object(i.jsxs)("p",{children:["I find this is a beautiful argument. Recalling figure 3, we can take the dashed line extending \\(u_z\\) to be our ray, and we see there are \\(5\\) intersections. If \\(f(X)=\\imath(X)=X\\), then we see \\(W_2(X,z)=1\\) and indeed, \\(z\\) lies inside the curve (which is just a hypersurface in ","\\(\\mathbb{R}^2\\)","). In fact, due to Sard, almost all values of \\(u_z\\) will be regular, hence by theorem 8 almost all such rays will intersect transversally. So, taking a hypersurface, we can just draw random rays, and with probability 1 we will have one to which we can apply theorem 10. This immediately gives the following."]}),Object(i.jsx)(k,{no:"11",statement:"\r A point \\(z\\) lies inside a hypersurface \\(X\\) if and only if almost all rays emanating from \\(z\\) intersect \\(X\\) an odd number of times."}),Object(i.jsx)("p",{children:"This is astoundingly simple, so I can now rest easy, knowing if I ever find myself in a life-or-death situation where the only escape is by knowing whether a point lies inside or outside a picture, I just need a pencil and straightedge."}),Object(i.jsx)(x,{no:"4",src:T,caption:"Figure 2-19 (89), Guillemin and Pollack"})]})}}]),a}(n.Component),z=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsxs)("div",{class:"postContent",children:[Object(i.jsx)("p",{children:Object(i.jsx)("i",{children:"As a preface to everything I say below: I am no expert in Japanese. I am still learning, and still very early in my learning too. Below are just my personal experiences, and this post is not in any way an authoritative recommendation."})}),Object(i.jsxs)("p",{children:["In the Japanese language-learning community (which is surprisingly large for a language so localized), Heisig's ",Object(i.jsx)("i",{children:"Remembering the Kanji"})," ('RTK') is an incredibly divisive book. Even worse, it's a clean division: most people either blindly swear by it and insist it's the only way to begin learning Japanese, or denounce the book and aver it's a complete waste of time. For me, community sentiment was irrelevant when I began learning, simply because I wasn't aware of it. Rather, I asked a friend of mine who went from no Japanese to passing N1 in a little over a year, and simply planned to emulate his journey. However, I can imagine if someone is planning to learn the language and they're getting their advice strictly online, it would be very hard to consolidate all of these inconsistent views. Should they read it? Should they not? The situation is not so simple as to warrant a blanket \"Yes\" or \"No\", in my opinion, and I aim to elucidate my reasoning as to why in this post, as well as how I think it should be answered instead."]}),Object(i.jsxs)("p",{children:["I will assume you are familiar with what kanji are. If not, there are plenty of explanations online about the difference between the three Japanese scripts. To many, kanji are a fairly intimidating aspect of Japanese. I find this is related to that fact that language is, of course, solely an oral construction, and completely disjoint from orthography. Thus, even if you have a very strong vocabulary and solid understanding of grammar, you will remain functionally illiterate if you do not know kanji. In particular, this means that even if your knowledge of the ",Object(i.jsx)("i",{children:"language"})," surpasses a level, that does not necessarily mean you can also ",Object(i.jsx)("i",{children:"read"})," the next level, as more difficult texts begin to use both more kanji and less furigana. This gap in orthography exists for quite a while; depending on the end-material you wish to read it can require you to learn somewhere between 1500-3000 kanji until it goes away. Of course, Japanese people don't have (too many - character amnesia is an interesting phenomenon) issues with this, because the level of material they can understand will generally match their orthographic knowledge as they grow up. However, as an adult, it can be frustrating enough to read children's books when learning any language, but being limited to children's books even though you could read more complex material if it was written ",Object(i.jsx)("i",{children:"in a different script"})," is even more frustrating, and not an issue that is even possible in most languages. Most do not have an orthography that works like this - you can learn how to nearly fluently read Hangul over lunch, or even both kanas over the weekend. However, Japanese people don't care how difficult it is for foreigners to learn their orthography (and rightfully so) because, like I said, they don't usually encounter such a gap, and kanji have many benefits for Japanese (e.g. density:\u300c\u3053\u3053\u308d\u3088\u3044\u300dversus\u300c\u5feb\u3044\u300d; disambiguation: look up\u300c\u304b\u3051\u308b\u300din a dictionary). Thus, you will eventually have to learn kanji, and quite a few: at least 1000 at a bare minimum, but realistically far more."]}),Object(i.jsxs)("p",{children:["This is where Heisig's book comes in. He took a list of the 2136 J\u014dy\u014d kanji (plus a few extra), broke them down into their component sub-kanji, and then broke those sub-kanji down again, and continued until he arrived at atomic kanji - radicals. He then took a few basic radicals, and found all kanji which are combinations of those or combinations of the combinations (c.f. the sub-kanji). Once that list was exhausted, he introduced a new radical and repeated the process, continuing until he ordered all of the kanji. Afterward, Heisig ",Object(i.jsx)("u",{children:"assigned"})," (the phrasing here is important and I will recount it later) all of these kanji a unique keyword. Now, given his ordering process, each kanji has with it a minimal list of sub-kanji or radicals, which also have a unique keyword assigned. His technique then was to take a kanji, look at its keyword, look at the list of keywords that compose it, and then come up with some sort of visual imagery based on that list to remind him of the greater keyword. Repeat this for each kanji, and you end up with a process which, certainly at least mathematically, is the most efficient way to learn the kanji."]}),Object(i.jsxs)("p",{children:["So then, where is the criticism? Surely the most efficient way is the best way, right? Well, as in economics, theoretically efficiency here does not (necessarily) translate to pragmatism. The thing is, if your goal is literally to just learn the kanji, there is absolutely no question - Heisig's method is the only way to go. However, most (and in fact, I would wager all) people who are looking to learn kanji are doing it in the context of the greater goal of ",Object(i.jsx)("i",{children:"learning Japanese"}),". And the thing is, RTK does absolutely nothing to help in that regard, on the surface (as I mentioned before, this is just orthography). At around 5 minutes per character, going through the book will take 180 hours ",Object(i.jsx)("i",{children:"not including reviews"}),", and you will understand just as much Japanese content at hour 180 as you did at hour 0."]}),Object(i.jsxs)("p",{children:["If you have not gone through the book you might be confused as to how this is possible. Aren't the keywords teaching you the meaning of kanji? What does it even mean to learn kanji if that isn't it? Doesn't this mean RTK is useless? I certainly wondered this. Well, recall how I specified Heisig ",Object(i.jsx)("u",{children:"assigned"})," keywords to the kanji. The purpose of these keywords is primarily to distinguish the kanji from each other - a memory and bookkeeping tool. It doesn't actually matter exactly what they are; they're not super special or sacred words. Take any set of 2200 words, biject those to the kanji, and you have a new set of keywords that will work just as well as the keywords Heisig gave (in terms of completing the book). This is because many kanji have multiple meanings, or their meanings are very abstract. For example, Heisig assigns\u300c\u91cd\u300dthe keyword \"Heavy\". This appears in many words, from\u300c",Object(i.jsxs)("ruby",{children:["\u91cd",Object(i.jsx)("rt",{children:"\u304a\u3082"})]}),"\u3044\u300d, also meaning ",Object(i.jsx)("strong",{children:"Heavy"}),", to\u300c",Object(i.jsxs)("ruby",{children:["\u91cd",Object(i.jsx)("rt",{children:"\u3058\u3085\u3046"}),"\u8981",Object(i.jsx)("rt",{children:"\u3088\u3046"})]}),"\u300dmeaning ",Object(i.jsx)("strong",{children:"Important"}),", or\u300c",Object(i.jsxs)("ruby",{children:["\u91cd",Object(i.jsx)("rt",{children:"\u304b\u3055"})]}),"\u306a\u308b\u300dmeaning ",Object(i.jsx)("strong",{children:"To be piled up"}),'. In some sense these all come from the keyword, but as you can see it\'s a very vague idea; you can easily replace it with something like "Large", "Stacked", or "Multiple" and you don\'t lose nor gain any information. On the other hand, we can take\u300c\u672c\u300dwhich is assigned the word "Book" and see it appears in the word\u300c',Object(i.jsxs)("ruby",{children:["\u65e5",Object(i.jsx)("rt",{children:"\u306b"}),"\u672c",Object(i.jsx)("rt",{children:"\u307b\u3093"})]}),"\u300dmeaning ",Object(i.jsx)("strong",{children:"Japan"}),",\u300c",Object(i.jsxs)("ruby",{children:["\u672c",Object(i.jsx)("rt",{children:"\u307b\u3093"})]}),"\u300dmeaning ",Object(i.jsx)("strong",{children:"Book"}),",\u300c",Object(i.jsxs)("ruby",{children:["\u672c",Object(i.jsx)("rt",{children:"\u307b\u3093"}),"\u80fd",Object(i.jsx)("rt",{children:"\u306e\u3046"})]}),"\u300dmeaning ",Object(i.jsx)("strong",{children:"Instinct"}),", or\u300c",Object(i.jsxs)("ruby",{children:["\u672c",Object(i.jsx)("rt",{children:"\u307b\u3093"}),"\u6c17",Object(i.jsx)("rt",{children:"\u304d"})]}),"\u300dmeaning ",Object(i.jsx)("strong",{children:"Earnestness"}),". Here, it's quite obvious that not all of its uses are accounted for by the keyword."]}),Object(i.jsxs)("p",{children:["Of course though, some keywords are better than others, and Heisig's are overall pretty good. Although the keyword \"Heavy\" doesn't communicate all of the ideas \u300c\u91cd\u300d gives off, it ",Object(i.jsx)("i",{children:"did"}),' come pretty close in most of them, and sometimes exactly matched the meaning, as seen in\u300c\u91cd\u3044\u300d. This is something I think a lot of people neglect to bring up. Sure, a kanji like\u300c\u672c\u300ddoesn\'t solely mean "Book", but can also mean something like "Main", "Reality", or "Japan", but that doesn\'t change that it ',Object(i.jsx)("i",{children:"does"}),' does sometimes mean "Book". Overall, it does a really good job at helping you understand what basic words mean, and certainly what words using just the kanji alone mean.']}),Object(i.jsxs)("p",{children:["What this means is that going through RTK makes it easier to learn Japanese, but it alone doesn't teach you anything. The payoff in trudging through the mind-numbing memorization isn't when you finish the book. It isn't even when you first start learning grammar and words. For me, I only appreciated it after I memorized several hundred words and could begin to read basic texts by myself. This is where I began to realize that I wasn't burdened by kanji at all. One reason is that I had the ability to learn every word in its kanji-form from the get-go, meaning I do not have to worry about how frequently a word is written in kanji nor at what reading level the kanji is preferred over the kana. For example, I have seen both\u300c\u66ab\u304f\u300dand\u300c\u3057\u3070\u3089\u304f\u300d(",Object(i.jsx)("strong",{children:"For a while"}),"), as well as\u300c\u304d\u308c\u3044\u300dand\u300c\u7dba\u9e97\u300d(",Object(i.jsx)("strong",{children:"Pretty"})," or ",Object(i.jsx)("strong",{children:"Pure"}),'), while reading pretty basic texts despite both words being listed as "Usually kana" in dictionaries. Another is that knowing keywords gave huge a huge boost to my effective word-count. One of the first sentence cards I made exemplifies this:\u300c',Object(i.jsxs)("ruby",{children:["\u5c4b\u6839",Object(i.jsx)("rt",{children:"\u3084\u306d"})]}),"\u306e",Object(i.jsxs)("ruby",{children:["\u866b",Object(i.jsx)("rt",{children:"\u3080\u3057"})]}),"\u304c",Object(i.jsxs)("ruby",{children:["\u9cf4",Object(i.jsx)("rt",{children:"\u306a"})]}),"\u304f\u305e\u3088\u3002\u300d. This was my first time seeing the words\u300c\u5c4b\u6839\u300d(",Object(i.jsx)("strong",{children:"Roof"}),"), \u300c\u866b\u300d(",Object(i.jsx)("strong",{children:"Insect"}),"), or\u300c\u9cf4\u304f\u300d(",Object(i.jsx)("strong",{children:"To chirp"}),') (which is literally every single word in sentence), yet I knew exactly what the sentence meant because I could read the kanji as "Roof... roots", "Insect", and "Chirp". Of course, not every word is this straightforward. For example, good luck with\u300c',Object(i.jsxs)("ruby",{children:["\u7acb",Object(i.jsx)("rt",{children:"\u308a\u3063"}),"\u6d3e",Object(i.jsx)("rt",{children:"\u3071"})]}),"\u300d(",Object(i.jsx)("strong",{children:"Exquisite"}),') being parsed as "Stand up... faction", or\u300c',Object(i.jsxs)("ruby",{children:["\u6a5f",Object(i.jsx)("rt",{children:"\u304d"}),"\u95a2",Object(i.jsx)("rt",{children:"\u304b\u3093"})]}),"\u300d(",Object(i.jsx)("strong",{children:"Engine"})," or ",Object(i.jsx)("strong",{children:"Institution"}),') being parsed as "Mechanism... connection". However, I find that many words are, particularly in very short or very long compounds. Furthermore, I noticed that I never mistook certain kanji for others, even though they may look similar on the surface, due to the fact that rigorously going through them means they all look completely unique.']}),Object(i.jsxs)("p",{children:["However, RTK does not somehow eliminate the need to worry about kanji. It merely repositions it. And that is where its largest downfall comes in. Going through the book ",Object(i.jsx)("i",{children:"sucks"}),". A ",Object(i.jsx)("i",{children:"lot"}),". Recall that I said it takes around 180 hours total. This means that I read the book for, on average, 6 hours a day. My review time was usually around 2 hours a day (~250 cards at ~25 seconds per). I could only do this because I was an unemployed student during the summer. If I had a job? Then I could only keep this pace on the days I worked less than 4 hours - any more and I have to start swapping work for reading, meaning a full 8 hour day leaves only 2 hours of studying. If I was in school? I could maybe pull 2 hours a day during a slow part of the semester (but as I will show you, this would require it being exceptionally slow). Now, there's nothing inherently wrong with taking longer to get through RTK. After all, the kanji aren't going anywhere. However, it becomes so much harder when you do. I know this from personal experience. I originally started the book during the school year, and on an average (read: light) day I could read for maybe 30 minutes. At that pace, it would take a full ",Object(i.jsx)("i",{children:"year"}),' to finish the book (obviously this is false because the school year only lasts 8 months, but this is irrelevant given what I\'m about to say right now) and I ended up giving up 3 months in, having finished ~200 kanji, simply because I could not maintain any motivation in this journey to "learn Japanese" as I was seeing no progress - ',Object(i.jsx)("i",{children:"because that wasn't what I was doing."})," Getting it done in a month was doable, and 2 or 3 months might even be easier because it's less work every day, but going past 4 months seems like you would be pushing it dangerously close to the territory I was in."]}),Object(i.jsx)("p",{children:"When I started again, having forgotten basically everything more intricate than\u300c\u53e3\u300d, I realized that if I wanted to get this done, I need to get it done as fast as possible, so that this burnout cannot catch up to me again. I initially set a goal to do at least 40 kanji a day. As I ended up doing closer to 50, I upped my goal to do a minimum of 60. In the end, I was doing around 80 per day. The good thing is that despite being boring, RTK is not hard or stressful. Memorizing kanji becomes fairly easy after your first 100, and although diminishing returns set in pretty quickly afterward, it does become slightly easier with each extra one you learn. This means that whether I spent 4 hours or 8 hours reading the book and creating these stories, I was just as effective at the beginning as I was at the end, and I didn't feel mentally fatigued. A digression: I wish reading maths textbooks was this easy - I start becoming antsy and frustrated after around an hour of reading and struggle to comprehend anything after the second. Even with breaks, it is hard to do anything more than 2-4 hours in a day."}),Object(i.jsxs)("p",{children:["However, I would occasionally encounter kanji for which I could not come up with a compelling story. Interestingly, this had nothing to do with the number of strokes, position in the book, ambiguity in the keyword, or anything like that. It seemed to happen at random. Notable examples that I recorded were\u300c\u654f\u300d,\u300c\u6cb3\u300d,\u300c\u8cbc\u300d,\u300c\u8aad\u300d,\u300c\u5224\u300d,\u300c\u932f\u300d, and, rather embarrassingly,\u300c\u5f15\u300d. However, I obviously know all of these now, so what did I do to make the story compelling? Well, I slightly ignored Heisig. For some of these, I just brute-forced them in Anki until I got them. I really do not recommend doing this, because if you forget them later, you're screwed, as you have nothing to fall back on. There are a handful (literally, as in less than 10) of kanji for which I did this. For others, I used some cheap tricks such as verbal mnemonics. Heisig covers in detail why these shouldn't be the primary approach (basically it's because visual imagery is usually an intuitive response to the words, whereas verbal tricks have no basis), however if the words prompt nothing, it's better than brute-force. The most helpful backup, however, was ",Object(i.jsx)("a",{href:"https://kanji.koohii.com/",children:"Kanji Koohii"})," (however I used it indirectly through ",Object(i.jsx)("a",{href:"https://hochanh.github.io/rtk/",children:"rtk-search"}),"). Although those stories weren't my personal stories, they were stories nonetheless, and oftentimes I didn't need to rip a full one from a user, but just read some to get inspired."]}),Object(i.jsxs)("p",{children:['There is another reason to use these websites, and that is to correct some of Heisig\'s mistakes. There are a few suspicious keywords, such as using "Ghost" for\u300c\u9b3c\u300dinstead of just saying "Oni", giving\u300c\u6821\u300dthe keyword "Exam" despite it appearing in every single word involving schools ',Object(i.jsx)("i",{children:"and"}),' the word "School" never being used as a keyword elsewhere, or teaching only the simplified kanji for ',Object(i.jsx)("strong",{children:"Dragon"}),",\u300c",Object(i.jsxs)("ruby",{children:["\u7adc",Object(i.jsx)("rt",{children:"\u308a\u3085\u3046"})]}),'\u300d, despite\u300c\u9f8d\u300dalso being extremely common (enough to be a top-1800 kanji despite not being j\u014dy\u014d) and looking sick (it\'s the only kanji I\'ve memorized through stroke-order alone). There are also better meanings to give to kanji as radicals: assigning\u300c\u7cf8\u300dthe meaning of "Spiderman" on the left and "Venom" on the bottom, rather than the dull "Thread" wherever, makes all its derivatives fairly easy. There are also a few ingenious stories made by some users, such as user fiminor coming up with one story to encapsulate\u300c\u9678\u300d,\u300c\u7766\u300d,\u300c\u52e2\u300d,\u300c\u71b1\u300d,\u300c\u83f1\u300d, and\u300c\u9675\u300d. In general, I would check the user-submitted stories for each kanji before I moved on, even if I made a good story myself, to make sure I would be aware of these things.']}),Object(i.jsxs)("p",{children:['In order to come up with these good stories in the first place, there are a few things I found helpful to keep in mind. The biggest, by far, is to try to combine multiple kanji into one story. Heisig\'s book orders the kanji in a way that naturally lends itself to this, and there are around 100-200 kanji that I learned "for free", as I didn\'t have to come up with a separate story for them. For example, I did this for\u300c\u76e3\u300d,\u300c\u89a7\u300d,\u300c\u6feb\u300d, and\u300c\u9451\u300d, and I continue to do this today when I encounter new kanji (which I will discuss in detail soon) such as appending\u300c\u7dbe\u300dto fiminor\'s saga. I also found it important to give very specific images. For example, I struggled to distinguish\u300c\u5e1d\u300dand\u300c\u738b\u300dbecause both of their keywords ("Sovereign" and "King", respectively) are pretty similar and I pictured generic male royalty for both. I solved this by emphasizing  a sceptre held in the latter (as I took it to be a pictograph of one), and picturing Julius Caesar in the former. When the primitive "Altar" came up, it appears to the left as in\u300c\u8996\u300dor underneath as in\u300c\u6b3e\u300d, and I always pictured the former as more of a statue and the latter as an offering table, in order to identify their physical position in the kanji. I also tried to include real-life components, such as friends or recounting events, to have a stronger and more grounded story. For example, for\u300c\u68a2\u300dthe keyword "Treetop" and components "Tree... extinguish" reminded me of the time I went to the Arashiyama grove with my friend, who insisted there would be lights on, only to get off the train at night and walk to a completely pitch-black set of treetops. Be aware though that sometimes you ',Object(i.jsx)("i",{children:"don't"}),' need intricate stories for kanji. Something like\u300c\u5206\u300dwith the keyword "Part" can be taken instantly as a pictograph of a dagger splitting a board (or something). In general, I felt that it was only around kanji 1000 or so that I got a feel for kanji and could feel that certain combinations or positions were unnatural, and began to play fast-and-loose with my stories; before that I kept everything very deliberate.']}),Object(i.jsx)("p",{children:'That is essentially all the advice I can give. Going through RTK is a fairly personal journey, and like I mentioned before, you will struggle at seemingly random points that others will not, and likely find kanji someone else finds exceedingly hard to be quite straightforward. Overall, I found the hardest part of the book to be the section of around 20 kanji beginning at number 595, where Heisig introduces the "Turkey" primitive (funnily enough, I use the memory of my struggle here to remember the later-learned\u300c\u96e3\u300d, given the keyword "Difficult"). The hardest kanji to come up with stories for were\u300c\u85cd\u300dand\u300c\u74bd\u300d, although I don\'t think either of these took longer than 15 minutes. Mentally, the hardest parts were around kanji 700 and 1400, where I really wanted to quit for no particular reason other than being sick of the book and doing flashcards.'}),Object(i.jsxs)("p",{children:["The kanji\u300c\u74bd\u300dbrings up an important critique of Heisig's RTK too. An analysis of around 800 million kanji uses, ",Object(i.jsx)("a",{href:"http://scriptin.github.io/kanji-frequency/",children:"available here"}),", lists it as the 2938th most used character in the best case, Wikipedia, and in one week of Twitter analysis it never came up at all. For some context, 1500 kanji generally gives you 97-99% coverage, depending on the material. So why is it in Heisig's book? Because the j\u014dy\u014d list has nothing to do with frequency. Sure, some (actually, a supermajority of) parts conveniently overlap, but the list is just a set of characters approved for general-use (as is the literal name). Due to the nature of kanji and literacy that I discussed at the beginning, it should be clear that the government needs some official list to which they can adhere, and so they need to ensure political topics are covered, which is why that kanji (keyword \"Imperial Seal\") made the cut. Do you need to know it? I doubt it. Thankfully, it's near the end of the book, so you can skip it without a loss. However, there are many kanji like this that appear throughout Heisig's book, and in general, the order in which they are presented in RTK has nothing to do with how important they are. This poses to me a problem much more significant than learning a few scores of uncommon kanji - an absurdly large amount of the most common kanji appear near the end of the book. And unfortunately, you can't skip to them and do them first (generally speaking), because they are built upon kanji learned earlier, so the method won't work. Plus, the first 500 or so kanji in the book have exposition written by Heisig through which he slowly teaches you how to come up with stories on your own; immediately skipping to\u300c\u5e30\u300dand reading \"Spear... broom... apron\" will seem impossible to handle. This means Heisig's book loses a lot of its usefulness unless you're willing to push to at least the 1600 or 1800 mark."]}),Object(i.jsxs)("p",{children:["This also means a few fairly simple kanji that ",Object(i.jsx)("i",{children:"aren't"})," j\u014dy\u014d, such as the\u300c\u5b09\u300dof\u300c",Object(i.jsxs)("ruby",{children:["\u5b09",Object(i.jsx)("rt",{children:"\u3046\u308c"})]}),"\u3057\u3044\u300d(",Object(i.jsx)("strong",{children:"Pleased"}),") or both kanji in\u300c",Object(i.jsxs)("ruby",{children:["\u55a7",Object(i.jsx)("rt",{children:"\u3051\u3093"}),"\u5629",Object(i.jsx)("rt",{children:"\u304b"})]}),"\u300d(",Object(i.jsx)("strong",{children:"Argument"}),"), hence are not in RTK. However, this doesn't really matter, because there aren't too many of them, and once you've gotten that far learning new kanji is very easy. Whenever they come up, I don't need to sit down for 5 minutes again and try to look up stories online. The whole process (plus coming up with a keyword on my own!) - identifying components and making a story - rarely takes more than 45 seconds. And since you are learning at most 5 new ones in a day, you won't forgot them. This is another thing that I refer to when I say I don't have to worry about kanji anymore: that handling them now is second nature."]}),Object(i.jsxs)("p",{children:["Those are my thoughts on Heisig's ",Object(i.jsx)("i",{children:"Remembering the Kanji"}),". I found it incredibly helpful. I was free for a summer, grinded out the book in a very short amount of time, and began learning Japanese with a large effective-vocabulary, an easy time memorizing new words, never stressing when I encountered new kanji - which happened fairly rarely anyways - and never having to worry about not knowing enough kanji to read a piece of literature. At the same time, I tried it beforehand and (thankfully only temporarily) gave up on learning the language and wasted a few months of my time, but potentially could've turned a blind-eye to Japanese for the rest of my life. Is it worth it? That's for you to decide. I've experienced the good and the bad, and laid out to you why and when that happened. Hopefully that makes the decision simple for you. And if you choose to go through with it, hopefully my advice can help you through from learning\u300c\u4e00\u300dall the way to\u300c\u5df3\u300d."]})]})}}]),a}(n.Component),q=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsx)("table",{class:"figureContainer",children:Object(i.jsx)("tr",{children:Object(i.jsx)("td",{class:"figure",children:Object(i.jsx)("img",{src:this.props.src,alt:""})})})})}}]),a}(n.Component),F=a.p+"static/media/svg1.5c1a4c20.svg",X=a.p+"static/media/svg2.f20d0332.svg",W=a.p+"static/media/svg3.cecf0205.svg",C=a.p+"static/media/svg4.0e4d54c2.svg",H=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"componentDidMount",value:function(){window.KaTeXRender()}},{key:"render",value:function(){return Object(i.jsxs)("div",{class:"postContent",children:[Object(i.jsxs)("p",{children:["While reading Aluffi's ",Object(i.jsx)("i",{children:"Algebra: Chapter 0"})," and finishing the proofs for the isomorphism theorems for modules, I began to grow slightly suspect that there was something going on behind the scenes, as the proofs were exactly the same as the ones for rings, which were the same as the ones for groups. Presented in his book, they all essentially stem from the fact that for a set-map \\(f:A\\longrightarrow B\\) and the equivalence relation \\(\\sim\\) defined by \\(a\\sim b\\) if and only if \\(f(a)=f(b)\\),"]}),Object(i.jsx)(q,{src:F}),Object(i.jsx)("p",{style:{textIndent:"0"},children:"where \\(\\pi_\\sim\\) is the projection to the equivalence class: \\(\\pi_\\sim(a)=[a]_\\sim\\)."}),Object(i.jsxs)("p",{children:["How do we know ","\\(\\tilde{f}\\)"," exists, let alone is unique? As the diagram must commute, given any"," ","\\(\\tilde{f}: A/\\!\\!\\sim\\longrightarrow B\\)"," we must have"," ","\\(\\tilde{f}\\circ\\pi_\\sim(a)=f(a)\\)"," for all \\(a\\in A\\), and so ","\\(\\tilde{f}\\)"," is forced to be \\([a]_\\sim\\mapsto f(a)\\). This is well-defined, recalling our definition of \\(\\sim\\). In recognition of the fact that this map is unique and can be deduced from any arbitrary set-map, we say that this quotient, \\(A/\\!\\!\\sim\\), satisfies a ",Object(i.jsx)("strong",{children:"universal property"})," in a particular category."]}),Object(i.jsxs)("p",{children:["What is a ",Object(i.jsx)("strong",{children:"category"}),"? It is just a collection of objects and ",Object(i.jsx)("strong",{children:"morphisms"})," between them, which are just ways to send one object to another. There are also a few checkmarks to glance over (such as existence of an identity and composition) to make sure your morphisms behave well, however they are not too important for us to formally cover. Above, for example, our objects are the ordered pair \\((B,f)\\) where \\(B\\) is a set and \\(f\\) is a map \\(A\\longrightarrow B\\); it is much cleaner to write them as a diagram"]}),Object(i.jsx)(q,{src:X}),Object(i.jsx)("p",{children:'A morphism between two objects \\((B,f)\\) and \\((C,g)\\) must then be some way to transform the map \\(f:A\\longrightarrow B\\) to \\(g:A\\longrightarrow C\\). This can be done by any map \\(j:B\\longrightarrow C\\) such that \\(j\\circ f = g\\); lucidity can be found by thinking of \\(j\\) as a morphism "between diagrams", meaning the following commutes:'}),Object(i.jsx)(q,{src:W}),Object(i.jsxs)("p",{children:["Note that we are not guaranteed to have such a \\(j\\) to exist. However, this diagram seems awfully suspicious to the one involving quotients at the very beginning, and that is because one does exist there. In fact we say \\(A/\\!\\!\\sim\\) (or rather, the diagram represented by \\((A/\\!\\!\\sim,\\pi_\\sim)\\)) is ",Object(i.jsx)("strong",{children:"initial"})," ","in this category, because there exists a unique morphism from it to any other object."]}),Object(i.jsx)("p",{children:"Now, with the concept of universal properties clarified, one can consider the canonical decomposition of our original map \\(f\\), which is the commutative diagram"}),Object(i.jsx)(q,{src:C}),Object(i.jsxs)("p",{children:["From here, much of the work in proving the isomorphism theorems is done. Indeed, this is because groups and rings all have underlying sets, and we can restrict ourselves by ensuring \\(f\\) is a homomorphism, as that is just a set-map which preserves the artificially-imposed structure. The formal way to do this is to work in a separate category, such as ","\\(\\mathbf{Grp}\\)",", whose objects are groups and morphisms are group homomorphisms - precisely these structure-preserving set-maps. Once in this domain, define the quotient and prove it is initial again, and we can see why the first isomorphism theorem holds instantly, as if \\(f\\) is a surjective homomorphism then ","\\(\\mathrm{im}\\,f = B\\)",". Note that I didn't even specify what type of homomorphism \\(f\\) was; the reasoning holds identically for groups, rings, and modules. The remaining theorems just aim to construct such a surjective \\(f\\)."]}),Object(i.jsxs)("p",{children:["Above, however, is a massive asterisk. It is not always straightforward to define \\(\\sim\\). For example, in"," ","\\(\\mathbf{Grp}\\)"," we cannot merely take a subgroup, but must also insist it is normal. Meanwhile in ","\\(\\mathbf{Ring}\\)",', we don\'t even bother with subrings, and instead provide the (rather obtuse, if you arrive directly from subgroups) definition of an ideal. This is where my suspicion mentioned at the beginning was inlaid - is there any relationship between these quotients? Although algebra is often tautological in this way, with definitions being nice to work with because the definitions were changed until they were (c.f. the word "normal" appearing everywhere), it seemed too coincidental that a quotient could always be found, regardless of what structure was imposed. My suspicion lasted merely a few minutes, however, because the simple query "isomorphism theorems" immediately led to the answer - universal algebra.']}),Object(i.jsxs)("p",{children:["Universal algebra begins by recognizing that all of these different structures boil down to two things - a set with operations. In particular, we call \\(f\\) an \\(n\\)-",Object(i.jsx)("strong",{children:"ary operation"})," on a set \\(A\\) if \\(f:A^n\\longrightarrow A\\). Then, we define a"," ",Object(i.jsx)("strong",{children:"type"})," to be a set"," ","\\(\\mathfrak{F}=\\left\\{(f_1,n_1),(f_2,n_2),\\dots\\right\\}\\)"," ","where each \\(f_i\\) is called an \\(n_i\\)-",Object(i.jsx)("strong",{children:"ary operation symbol"}),". Be aware that the subscript will be dropped if distinguishing it from another symbol is not of concern. An ",Object(i.jsx)("strong",{children:"algebra"})," ","\\(\\mathcal{A}\\)"," of type"," ","\\(\\mathfrak{F}\\)"," is just an ordered pair \\((A,F)\\) where \\(A\\) is a set and \\(F\\) is a set of \\(n\\)-ary operations so that for each \\(n_i\\)-ary operation symbol ","\\(f_i\\in\\mathfrak{F}\\)",", there is a corresponding \\(n_i\\)-ary operation ","\\(f_i^\\mathcal{A}\\in F\\)",". We call \\(A\\) the ",Object(i.jsx)("strong",{children:"universe"})," of"," ","\\(\\mathcal{A}\\)"," and \\(F\\) its"," ",Object(i.jsx)("strong",{children:"fundamental operations"}),"."]}),Object(i.jsxs)("p",{children:["For example, an algebra ","\\(\\mathcal{G}\\)"," of type"," ","\\(\\mathfrak{F}=\\left\\{(1,0),(^{-1},1),(\\cdot,2)\\right\\}\\)"," ","is an ordered pair \\((G,F)\\) with \\(G\\) any set and \\(F\\) a set containing a nullary (\u203d), unary, and binary operation on \\(G\\). What is a nullary operation? It must be an operation which returns something despite taking in no inputs - in other words, a constant function. We write ","\\(\\mathcal{G}=(G,1,^{-1},\\cdot)\\)"," to consolidate our operations in \\(F\\) with the symbols in"," ","\\(\\mathfrak{F}\\)",". We call ","\\(\\mathcal{G}\\)"," a"," ",Object(i.jsx)("strong",{children:"group"})," if","\n                    \\[\n                    \\begin{aligned}\n                    &\\cdot (1,x)=x=\\cdot\\,(x,1);\\\\\n                    &\\cdot(x,^{-1}\\!(x))=1=\\cdot\\,(^{-1}\\!(x),x);\\\\\n                    &\\cdot(x,y\\cdot z)=\\cdot\\,(x\\cdot y,z).\n                    \\end{aligned}\n                    \\]\n                    "]}),Object(i.jsxs)("p",{children:["This is all looks quite cumbersome when written strictly treating these operations as functions. Thankfully, by taking liberty with the operation symbols, and giving the element to which \\(1\\) maps a rather suggestive symbol like \\(e\\), we can intuitively rewrite this as","\n                    \\[\n                        \\begin{aligned}\n                        &e\\cdot x=x=x\\cdot e;\\\\\n                        &x\\cdot x^{-1}=e=x^{-1}\\cdot x;\\\\\n                        &x\\cdot(y\\cdot z)=(x\\cdot y)\\cdot z.\n                        \\end{aligned}\n                    \\]\n                    ","This is all very familiar - after all, it is just a group. However, note that we have fully described it without using any quantifying symbols. For example, the existence of an identity isn't denoted by \"For all ","\\(x\\in\\mathcal{G}\\)",'...", but rather a consequence of an operation and how it interacts with other operations.']}),Object(i.jsxs)("p",{children:["What might our subgroups look like? We know we need them to behave like a regular algebra on their own, but also be identified within its parent. So, for two algebras ","\\(\\mathcal{A}=(A,F_A)\\)"," and"," ","\\(\\mathcal{B}=(B,F_B)\\)"," of type ","\\(\\mathfrak{F}\\)",", we say that ","\\(\\mathcal{B}\\)"," is a ",Object(i.jsx)("strong",{children:"subalgebra"})," of"," ","\\(\\mathcal{A}\\)"," if its universe is a"," ",Object(i.jsx)("strong",{children:"subuniverse"})," of ","\\(\\mathcal{A}\\)",", meaning \\(B\\subseteq A\\) and \\(B\\) is closed under \\(F_A\\), and the operations on ","\\(\\mathcal{B}\\)"," can be recovered by restricting the ones on"," ","\\(\\mathcal{A}\\)",", meaning","\n                    \\[\n                        f^\\mathcal{B}_i(b_1,\\cdots,b_n)=f^\\mathcal{A}_i\\vert_\\mathcal{B}(b_1,\\dots,b_n)\n                    \\]\n                    ","for all ","\\(f^\\mathcal{B}_i\\in F_B\\)"," and"," ","\\(f^\\mathcal{A}_i\\in F_A\\)","."]}),Object(i.jsxs)("p",{children:["Now, take an algebra ","\\(\\mathcal{A}=(A,F)\\)"," of type"," ","\\(\\mathfrak{F}\\)",". Let \\(\\sim\\) be an equivalence relation on"," ","\\(\\mathcal{A}\\)",". It is important that we recall the set definition of an equivalence relation:","\n                    \\[\n                        \n\\sim\\,=\\left\\{(a,b)\\in A\\times A: \\mathrm{ (1), (2), (3)}\\right\\}\n\n                    \\]\n\n                    \\[\n                        \n a\\in A\\Rightarrow (a,a)\\in A;\n\n                    \\]\n\n                    \\[ \n                        \n(a,b),(b,c)\\in A\\Rightarrow (a,c)\\in A;\n\n                    \\]\n\n                    \\[\n                        \n(a,b)\\in A\\Rightarrow (b,a)\\in A.\n\n                    \\] \n                    ","We call \\(\\sim\\) a ",Object(i.jsx)("strong",{children:"congruence"})," on"," ","\\(\\mathcal{A}\\)"," if given any \\(n\\)-ary"," ","\\(f\\in\\mathfrak{F}\\)"," and for all \\(1\\leq i\\leq n\\), we have","\n                    \\[\na_i\\sim b_i\\Rightarrow f^\\mathcal{A}(a_1,\\dots,a_n)\\sim f^\\mathcal{A}(b_1,\\dots,b_n).\n\\]\n                    ","The definition of congruence is reminiscent of normal subgroups. The set of all congruences on ","\\(\\mathcal{A}\\)"," is denoted"," ","\\(\\mathrm{Con}\\,\\mathcal{A}\\)",". An element of this that we will need in the distant future is \\(\\nabla_A=A\\times A\\), called the"," ",Object(i.jsx)("strong",{children:"all relation"}),"."]}),Object(i.jsxs)("p",{children:["Naturally then, we go on to define quotients. For any \\(a\\in A\\) we call the equivalence class under \\(\\sim\\) the set","\\[\na/\\!\\!\\sim\\,=\\left\\{b\\in\\mathcal{A}:a\\sim b\\right\\}\n\\]","and then we denote quotient of \\(A\\) by \\(\\sim\\) to be","\\[\nA/\\!\\!\\sim\\,=\\left\\{a/\\!\\!\\sim:a\\in A\\right\\}.\n\\]"]}),Object(i.jsxs)("p",{children:["Note that for the above, congruencey isn't important at all. Any equivalence relation will do. However, to define an algebra with universe \\(A/\\!\\!\\sim\\) that carries over the operations from"," ","\\(\\mathcal{A}\\)",", we need the following to be well-defined:","\\[\nf^{\\mathcal{A}/\\sim}(a_1/\\!\\!\\sim,\\dots,a_n/\\!\\!\\sim)=f^\\mathcal{A}(a_1,\\dots,a_n)/\\!\\!\\sim.\n\\]","Indeed, congruences let us achieve that. We then say the quotient algebra of ","\\(\\mathcal{A}\\)"," by \\(\\sim\\),"," ","\\(\\mathcal{A}/\\!\\!\\sim\\)",", is the algebra \\((A/\\!\\!\\sim,F_\\sim)\\) where \\(F_\\sim\\) is simply the set operations gained after performing the above for all \\(f\\in F\\). Note that"," ","\\(\\mathcal{A}/\\!\\!\\sim\\)"," is clearly also an algebra of type"," ","\\(\\mathfrak{F}\\)",". Of note is that quotients, in a sense, preserve inclusions:"]}),Object(i.jsx)(k,{no:"1",statement:"\r Let \\(\\sim_1,\\sim_2\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\) so that \\(\\sim_2\\,\\subseteq\\,\\sim_1\\). Then, \\(\\sim_1\\! /\\!\\sim_2\\) is a congruence on \\(\\mathcal{A}/\\!\\!\\sim_2\\)."}),Object(i.jsx)(_,{proof:"\r Take some \\((\\alpha_i,\\beta_i)\\in\\sim_1\\!/\\!\\sim_2\\) for \\(1\\leq i\\leq n\\). Then, \\((\\alpha_i,\\beta_i)=(a_i/\\!\\!\\sim_2,b_i/\\!\\!\\sim_2)\\) where \\((a_i,b_i)\\in\\,\\sim_1\\). As \\(\\sim_1\\) is a congruence, we know for any \\(n\\)-ary \\(f\\), it holds that\r \\[\r (f^\\mathcal{A}(a_1,\\dots,a_n),f^\\mathcal{A}(b_1,\\dots,b_n))\\in\\,\\sim_1\r \\]\r and so\r \\[\r \\begin{aligned}\r (f^\\mathcal{A}&(a_1,\\dots,a_n)/\\!\\!\\sim_2,f^\\mathcal{A}(b_1,\\dots,b_n)/\\!\\!\\sim_2)= \\\\\r &(f^{\\mathcal{A}/\\sim_2}(a_1/\\!\\!\\sim_2,\\dots,a_n/\\!\\!\\sim_2),f^{\\mathcal{A}/\\sim_2}(b_1/\\!\\!\\sim_2,\\dots,b_n/\\!\\!\\sim_2)\\in\\sim_1\\! /\\!\\!\\sim_2\r \\end{aligned}\r \\]\r because \\(\\sim_2\\) is also a congruence. "}),Object(i.jsxs)("p",{children:["The last thing we need is a way to communicate between different algebras. This is done as one would expect. Given two algebras"," ","\\(\\mathcal{A}=(A,F_A)\\)"," and ","\\(\\mathcal{B}=(B,F_B)\\)"," of type ","\\(\\mathfrak{F}\\)",", a map \\(\\alpha:A\\longrightarrow B\\) is called an ",Object(i.jsx)("strong",{children:"algebra homomorphism"})," between"," ","\\(\\mathcal{A}\\)"," and ","\\(\\mathcal{B}\\)"," if","\\[\n\\alpha f_i^\\mathcal{A}(a_1,\\dots,a_n)=f_i^\\mathcal{B}(\\alpha a_1,\\dots,\\alpha a_n)\n\\]","for every ","\\(f_i\\in\\mathfrak{F}\\)",". We call a homomorphism an"," ",Object(i.jsx)("strong",{children:"isomorphism"})," if the underlying map is bijective."]}),Object(i.jsxs)("p",{children:["We immediately have a homomorphism at our disposal. First, we define the ",Object(i.jsx)("strong",{children:"natural map"})," \\(\\nu_\\sim:A\\longrightarrow A/\\!\\!\\sim\\) to be \\(a\\mapsto a/\\!\\!\\sim\\). We call the homomorphism it induces the ",Object(i.jsx)("strong",{children:"natural homomorphism"}),". But is it actually a homomorphism, or am I lying?"]}),Object(i.jsx)(k,{no:"1",statement:"\r The natural map is a homomorphism from \\(\\mathcal{A}\\) to \\(\\mathcal{A}/\\!\\!\\sim\\)."}),Object(i.jsx)(_,{proof:"\r Take some \\(n\\)-ary operation symbol \\(f\\) in type \\(\\mathfrak{F}\\) of \\(\\mathcal{A}\\) and \\(a_1,\\dots,a_n\\in A\\). Then,\r \\[\r \\begin{aligned}\r \\nu_\\sim f^\\mathcal{A}(a_1,\\dots,a_n)&=f^\\mathcal{A}(a_1,\\dots,a_n)/\\!\\!\\sim\\\\\r &=f^{\\mathcal{A}/\\sim}(a_1/\\!\\!\\sim,\\dots,a_n/\\!\\!\\sim)\\\\\r &=f^{\\mathcal{A}/\\sim}(\\nu_\\sim a_1,\\dots,\\nu_\\sim a_n)\r \\end{aligned}\r \\] \r so indeed, my conscience is clean. "}),Object(i.jsxs)("p",{children:["The ",Object(i.jsx)("strong",{children:"kernel"}),' of a homomorphism has a definition that seems slightly odd, however recall that we can\'t freely speak about "sending elements to zero" or anything of the sort, since that hinges on a specific choice of operations and identities. So, we instead define it as',"\\[\n\\mathrm{ker}(\\alpha)=\\left\\{(a,b)\\in A\\times A: \\alpha(a)=\\alpha(b)\\right\\}.\n\\]","Note that if we take this definition and return to our definition of a group, for example, we quickly recover the usual definition of kernel."]}),Object(i.jsx)("p",{children:"Now, we have all the background we need to dig into the theorems. First, we handle some grunt-work."}),Object(i.jsx)(k,{no:"3",statement:"\r The kernel of a homomorphism \\(\\alpha:\\mathcal{A}\\longrightarrow\\mathcal{B}\\) is a congruence on \\(\\mathcal{A}\\)."}),Object(i.jsx)(_,{proof:"\r Take some \\(n\\)-ary \\(f\\) and Let \\((a_i,b_i)\\in\\mathrm{ker}\\,\\alpha\\) for \\(1\\leq i\\leq n\\). Then,\r \\[\r \\begin{aligned}\r \\alpha f^\\mathcal{A}(a_1,\\dots,a_n)&=f^\\mathcal{B}(\\alpha a_1,\\dots,\\alpha a_n)\\\\\r &=f^\\mathcal{B}(\\alpha b_1,\\dots,\\alpha b_n)\\\\\r &=\\alpha f^\\mathcal{A}(b_1,\\dots,b_n)\r \\end{aligned}\r \\]\r meaning \\((f^\\mathcal{A}(a_1,\\dots,a_n),f^\\mathcal{A}(b_1,\\dots,b_n))\\in\\mathrm{ker}\\,\\alpha\\)."}),Object(i.jsx)(k,{no:"4",statement:"\r Given homomorphisms \\(\\alpha:\\mathcal{A}\\longrightarrow\\mathcal{B}\\) and \\(\\beta:\\mathcal{B}\\longrightarrow\\mathcal{C}\\), the composition of the set-maps \\(\\beta\\circ\\alpha:A\\longrightarrow C\\) is a homomorphism from \\(\\mathcal{B}\\) to \\(\\mathcal{C}\\)."}),Object(i.jsx)(_,{proof:"\r Take some \\(n\\)-ary \\(f\\), and let \\(a_1,\\dots,a_n\\in A\\). Then,\r \\[\r \\begin{aligned}\r \\beta\\circ\\alpha f^\\mathcal{A}(a_1,\\dots,a_n)&=\\beta(\\alpha   f^\\mathcal{A}(a_1,\\dots,a_n))\\\\\r &=\\beta f^\\mathcal{B}(\\alpha a_1,\\dots,\\alpha a_n)\\\\\r &=f^\\mathcal{C}(\\beta(\\alpha a_1),\\dots,\\beta(\\alpha a_n))\\\\\r &=f^\\mathcal{C}(\\beta\\circ\\alpha a_1,\\dots,\\beta\\circ\\alpha a_n)\r \\end{aligned}\r \\]\r as desired. "}),Object(i.jsx)("p",{children:"Now, we tackle the first big result."}),Object(i.jsx)(k,{no:"5",name:"First Isomorphism Theorem (FIT)",statement:"\r If \\(\\alpha:\\mathcal{A}\\longrightarrow\\mathcal{B}\\) is a surjective homomorphism, then there exists an isomorphism from \\(\\mathcal{A}/\\mathrm{ker}\\,\\alpha\\) to \\(\\mathcal{B}\\). In particular, this isomorphism is defined by \\(a_{\\mathrm{ker}\\,\\alpha}\\mapsto\\alpha a\\).\r "}),Object(i.jsx)(_,{proof:"\r Let \\(\\beta:A/\\mathrm{ker}\\,\\alpha\\longrightarrow B\\) be the above mapping. Given some \\(b\\in B\\), we know there exists some \\(a\\in A\\) so that \\(\\alpha a=b\\), by hypothesis. Then, \\(\\beta a_{\\mathrm{ker}\\,\\alpha}=b\\), so our map is surjective. Suppose now we have \\(\\beta a_{\\mathrm{ker}\\,\\alpha} =\\beta a'_{\\mathrm{ker}\\,\\alpha} \\). Thus, \\(\\alpha a=\\alpha a'\\), however this means \\((a,a')\\in\\mathrm{ker}\\,\\alpha\\), and thus \\( a_{\\mathrm{ker}\\alpha}=a'_{\\mathrm{ker}\\,\\alpha}\\), so our map is injective.\\[\\]\r We just need to verify \\(\\beta\\) plays nice with our operations. So, take some \\(n\\)-ary \\(f\\) and \\(a_1,\\dots,a_n\\in A\\), and we see\r \\[\r \\begin{aligned}\r \\beta(f^{\\mathcal{A}/\\mathrm{ker}\\,\\alpha}(a_1/\\mathrm{ker}\\,\\alpha,\\dots,a_n/\\mathrm{ker}\\,\\alpha))&=\\beta(f^\\mathcal{A}(a_1,\\dots,a_n)/\\mathrm{ker}\\,\\alpha)\\\\\r &=\\alpha f^\\mathcal{A}(a_1,\\dots,a_n)\\\\\r &=f^\\mathcal{B}(\\alpha a_1,\\dots,\\alpha a_n)\\\\\r &=f^\\mathcal{B}(\\beta(a_1/\\mathrm{ker}\\,\\alpha),\\dots,\\beta(a_n/\\mathrm{ker}\\,\\alpha))\r \\end{aligned}\r \\]\r so \\(\\beta\\) is indeed a homomorphism."}),Object(i.jsx)("p",{children:"Using (2) and (4), we opt to write \\(\\alpha=\\beta\\circ\\nu_\\sim\\) to encapsulate the definition of \\(\\beta\\). Next, we recall (1) from the very beginning, and out-of-order tackle the third theorem:"}),Object(i.jsx)(k,{no:"6",name:"Third Isomorphism Theorem",statement:"\r If \\(\\sim_1,\\sim_2\\,\\in\\mathrm{Con}\\,A\\) with \\(\\sim_2\\,\\subseteq\\,\\sim_1\\), then\r \\[\r \\alpha:\\frac{A/\\!\\!\\sim_2}{\\sim_1\\! /\\!\\!\\sim_2}\\longrightarrow A/\\!\\!\\sim_1\\quad\\mathrm{by}\\quad \\frac{a/\\!\\!\\sim_2}{\\sim_1\\! /\\!\\!\\sim_2}\\mapsto a/\\!\\!\\sim_1\r \\]\r is an isomorphism from \\(\\frac{\\mathcal{A}/\\sim_2}{\\sim_1 /\\sim_2}\\) to \\(\\mathcal{A}/\\!\\!\\sim_1\\)."}),Object(i.jsx)(_,{proof:"\r Consider the map \\(\\alpha':A/\\!\\!\\sim_2\\longrightarrow A/\\!\\!\\sim_1\\) defined by \\(a/\\!\\!\\sim_2\\,\\mapsto a/\\!\\!\\sim_1\\). We see that this is well-defined, for if \\(a/\\!\\!\\sim_2=b/\\!\\!\\sim_2\\), then \\((a,b)\\in\\sim_2\\), and by inclusion, \\((a,b)\\in\\,\\sim_1\\) so \\(a/\\!\\!\\sim_1=b/\\!\\!\\sim_1\\). Now, take any \\(a/\\!\\!\\sim_1\\,\\in A/\\!\\!\\sim_1\\), and it clear that \\(\\alpha'(a/\\!\\!\\sim_2)\\) reaches this element. Thus, \\(\\alpha'\\) is surjective.\\[\\]\r Take now any \\(n\\)-ary \\(f\\), and \\(a_1/\\!\\!\\sim_2,\\dots,a_n/\\!\\!\\sim_2\\,\\in A/\\!\\!\\sim_2\\). We see\r \\[\r \\begin{aligned}\r \\alpha'f^{\\mathcal{A}/\\sim_2}(a_1/\\!\\!\\sim_2,\\dots,a_n/\\!\\!\\sim_2)&=\\alpha'(f^\\mathcal{A}(a_1,\\dots,a_n)/\\!\\!\\sim_2)\\\\\r &=f^\\mathcal{A}(a_1,\\dots,a_n)/\\!\\!\\sim_1\\\\\r &=f^{\\mathcal{A}/\\sim_1}(a_1/\\!\\!\\sim_1,\\dots,a_n/\\!\\!\\sim_1)\\\\\r &=f^{\\mathcal{A}/\\sim_1}(\\alpha'(a_1/\\!\\!\\sim_2),\\dots,\\alpha'(a_n/\\!\\!\\sim_2))\r \\end{aligned}\r \\]\r so this is actually a homomorphism as well. Now, take note that\r \\[\r \\begin{aligned}\r \\mathrm{ker}\\,\\alpha'&=\\left\\{(a/\\!\\!\\sim_2,b/\\!\\!\\sim_2)\\in (A/\\!\\!\\sim_2)^2:\\alpha'(a/\\!\\!\\sim_2)=\\alpha'(b/\\!\\!\\sim_2)\\right\\}\\\\\r &=\\left\\{(a/\\!\\!\\sim_2,b/\\!\\!\\sim_2)\\in (A/\\!\\!\\sim_2)^2:a/\\!\\!\\sim_1=b/\\!\\!\\sim_1\\right\\}\\\\\r &=\\left\\{(a/\\!\\!\\sim_2,b/\\!\\!\\sim_2)\\in (A/\\!\\!\\sim_2)^2:(a,b)\\in\\sim_1\\right\\}\\\\\r &=\\,\\sim_1\\! /\\!\\!\\sim_2\r \\end{aligned}\r \\]\r so by (FIT),\r \\[\r \\frac{A/\\!\\!\\sim_2}{\\sim_1\\! /\\!\\!\\sim_2}\\cong A/\\!\\!\\sim_1 \r \\]\r and we see indeed taking \\(\\alpha'=\\alpha\\circ\\nu_{\\sim_1/\\sim_2}\\) gives the claimed mapping."}),Object(i.jsxs)("p",{children:["We now need one more definition. Take an algebra"," ","\\(\\mathcal{A}\\)"," and take any \\(B\\subseteq A\\). Then, we define","\\[\n\\bigcap\\left\\{X:B\\subseteq X\\mathrm{\\ and\\ }X\\mathrm{\\ is\\ a\\ subuniverse\\ of\\ }\\mathcal{A}\\right\\}\n\\]","to be the ",Object(i.jsx)("strong",{children:"subuniverse generated"})," by \\(B\\). It is clear this induces a subalgebra, notably the"," ",Object(i.jsx)("strong",{children:"subalgebra generated"})," by \\(B\\). We are interested in one particular instance of this. Let"," ","\\(\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\)",". Define for \\(B\\subseteq A\\) the set","\\[B^\\sim=\\left\\{a\\in A:B\\cap a/\\!\\!\\sim\\,\\neq\\varnothing\\right\\}.\\]","We denote ","\\(\\mathcal{B}^\\sim\\)"," to be the subalgebra generated by \\(B^\\sim\\). If we have a subalgebra ","\\(\\mathcal{B}=(B,F)\\)",", then we write ","\\(\\mathcal{B}^\\sim\\)"," to describe this process on \\(B\\). Of note is that in this case our generated subalgebra does not grow:"]}),Object(i.jsx)(k,{no:"7",statement:"\r If \\(\\mathcal{B}\\) is a subalgebra of \\(\\mathcal{A}\\) and \\(\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\), then the universe of \\(\\mathcal{B}^\\sim\\) is \\(B^\\sim\\).\r "}),Object(i.jsx)(_,{proof:"\r Take some \\(n\\)-ary \\(f\\). Take any \\(a_1,\\dots,a_n\\in B^\\sim\\). By definition of \\(B^\\sim\\), there is some \\(b_i\\in B\\) so that \\((a_i,b_i)\\in\\,\\sim\\) for \\(1\\leq i\\leq n\\). Thus,\r \\[\r (f^\\mathcal{A}(a_1,\\dots,a_n),f^\\mathcal{A}(b_1,\\dots,b_n))\\in\\,\\sim\r \\]\r but this means \\(f^\\mathcal{A}(a_1,\\dots,a_n)\\in B^\\sim\\). We know \\(B^\\sim\\) is a subset of our universe, however we have just showed that \\(B^\\sim\\) is a subuniverse of \\(A\\), and therefore will generate itself. Thus, our universe is indeed \\(\\mathcal{B}^\\sim\\)."}),Object(i.jsxs)("p",{children:["Denote for a congruence \\(\\sim\\) on ","\\(\\mathcal{A}\\)"," the"," ",Object(i.jsx)("strong",{children:"restriction"})," of \\(\\sim\\) to \\(B\\subseteq A\\) to be the set \\(\\sim\\!\\vert_B=\\,\\sim\\cap\\,(B\\times B)\\). If \\(B\\) is a subuniverse, then this is clearly a congruence \\((B,F_B)\\)."]}),Object(i.jsx)(k,{no:"8",name:"Second Isomorphism Theorem",statement:"\r If \\(\\mathcal{B}\\) is a subalgebra of \\(\\mathcal{A}\\) and \\(\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\), then \\(\\mathcal{B}/\\!\\!\\sim\\!\\vert_B\\cong\\mathcal{B}^\\sim\\! /\\!\\!\\sim\\!\\vert_{B^\\sim}\\)."}),Object(i.jsx)(_,{proof:"\r Consider the map \\(\\alpha:\\mathcal{B}\\longrightarrow\\mathcal{B}^\\sim\\! /\\!\\!\\sim\\!\\vert_{B^\\sim}\\) defined by \\(b\\mapsto b/\\!\\!\\sim\\!\\vert_{B^\\sim}\\). This map is clearly well-defined. Now take some \\(n\\)-ary \\(f\\) and \\(b_1,\\dots,b_n\\in B\\) and we see\r \\[\r \\begin{aligned}\r \\alpha f^\\mathcal{B}(b_1,\\dots,b_n)&=f^\\mathcal{B}(b_1,\\dots,b_n)/\\!\\!\\sim\\!\\vert_{B^\\sim}\\\\\r &=f^{\\mathcal{B}/\\sim\\vert_{B^\\sim}}(b_1/\\!\\!\\sim\\!\\vert_{B^\\sim},\\dots,b_n/\\!\\!\\sim\\!\\vert_{B^\\sim})\\\\\r &=f^{\\mathcal{B}/\\sim\\vert_{B^\\sim}}(\\alpha b_1,\\dots,\\alpha b_n)\r \\end{aligned}\r \\]\r and noting that because \\(\\mathcal{B}/\\!\\!\\sim\\!\\vert_{B^\\sim}\\) is clearly a subalgebra of \\(\\mathcal{B}^\\sim/\\!\\!\\sim\\!\\vert_{B^\\sim}\\), we can pull our operation up, thus showing \\(\\alpha\\) is a homomorphism. Now, take some \\(b/\\!\\!\\sim\\!\\vert_{B^\\sim}\\in B^\\sim\\! /\\!\\!\\sim\\!\\vert_{B^\\sim}\\). We know that there is some \\(b'\\in B\\) so that \\(b'\\sim b\\), by definition of \\(B^\\sim\\). Thus, \\(\\alpha b'=b/\\!\\!\\sim\\!\\vert_{B^\\sim}\\), meaning it is surjective.\\[\\]\r Naturally, we proceed inspect the kernel of \\(\\alpha\\). As \r \\[\r \\begin{aligned}\r \\mathrm{ker}\\,\\alpha&=\\left\\{(b,b')\\in B^2:\\alpha(b)=\\alpha(b')\\right\\}\\\\\r &=\\left\\{(b,b')\\in B^2 : b/\\!\\!\\sim\\!\\vert_{B^\\sim}=b'/\\!\\!\\sim\\!\\vert_{B^\\sim} \\right\\}\\\\\r &=\\left\\{(b,b')\\in B^2:(b,b')\\in\\,\\sim\\!\\vert_{B^\\sim}\\right\\}\r \\end{aligned}\r \\]\r and given \\(B\\subseteq B^\\sim\\), this means \\(\\mathrm{ker}\\,\\alpha=\\,\\sim\\!\\vert_B\\). Then, by (FIT), we are done."}),Object(i.jsxs)("p",{children:["That's the three covered! However, there is one more theorem which is often presented alongside the isomorphism theorems - the correspondence theorem - which I will include for completeness. This is where the language of universal algebra takes a slight detour away from the conventional language used in, say, group theory. We call a non-empty set \\(L\\) endowed with two binary operations - \\(\\wedge\\) (",Object(i.jsx)("strong",{children:"meet"}),") and \\(\\vee\\) (",Object(i.jsx)("strong",{children:"join"}),") - a lattice if both meet and join are commutative and associative, along with being ",Object(i.jsx)("strong",{children:"idempotent"}),", meaning \\[ x\\vee x = x\\qquad x\\wedge x = x \\] and ",Object(i.jsx)("strong",{children:"absorptive"}),", meaning \\[ x\\vee(x\\wedge y)=x\\qquad x\\wedge(x\\vee y)=x. \\] A"," ",Object(i.jsx)("strong",{children:"sublattice"})," is a non-empty subset of a lattice, closed under meet and join."]}),Object(i.jsxs)("p",{children:["A map \\(\\alpha:L\\longrightarrow S\\) where \\(L\\) and \\(S\\) are lattices is called a ",Object(i.jsx)("strong",{children:"lattice homomorphism"})," if for \\(a,b\\in L\\), \\[ \\alpha(a\\wedge_Lb)=\\alpha a\\wedge_S\\alpha b\\qquad \\alpha(a\\vee_Lb)=\\alpha a\\vee_S\\alpha b. \\]"]}),Object(i.jsxs)("p",{children:["Next, we call a set \\(A\\) a ",Object(i.jsx)("strong",{children:"partially-ordered set"})," (",Object(i.jsx)("strong",{children:"poset"}),") if there exists a relation \\(\\leq\\) which is reflexive and transitive, along with being"," ",Object(i.jsx)("strong",{children:"antisymmetric"}),", meaning","\\[a\\leq b\\mathrm{\\ and\\ } b\\leq a\\Rightarrow a=b.\\]","We write \\((A,\\leq)\\). The only thing separating this from a"," ",Object(i.jsx)("strong",{children:"total-order"})," (e.g. the usual definition of \\(\\leq\\) on"," ","\\(\\mathbb{N}\\)",") is that a partial-order does not guarantee \\(a\\leq b\\) or \\(b\\leq a\\), in general. On posets, an"," ",Object(i.jsx)("strong",{children:"interval"})," \\(\\left[a,b\\right]\\) or \\((a,b)\\),"," ",Object(i.jsx)("strong",{children:"supremum"}),", and ",Object(i.jsx)("strong",{children:"infimum"})," are defined exactly the same as they are for totally-ordered sets."]}),Object(i.jsx)("p",{children:"The reason posets are important is that every lattice has a natural partial-order, namely writing \\(a\\leq b\\) if \\(a=a\\wedge b\\). Verifying this is actually a partial-order is just symbol-pushing, so I will not include it here."}),Object(i.jsx)(k,{no:"9",statement:"\r Every interval of a lattice is a sublattice."}),Object(i.jsx)(_,{proof:"\r Take \\([a,b]\\) to be our interval. Let \\(p,q\\in [a,b]\\). Then,\r \\[\r a\\wedge (p\\wedge q)=(a\\wedge p)\\wedge q=a\\wedge q=a\r \\]\r so \\(a\\leq p\\wedge q\\). Similarly, \\(p\\wedge q\\leq b\\). Then,\r \\[\r a\\wedge(p\\vee q)=a\\wedge((p\\vee (p\\wedge a))\\vee q)=a\\wedge((p\\vee a)\\vee q)=a\\wedge(a\\vee(p\\vee q))=a\r \\]\r meaning \\(a\\leq p\\vee q\\), and similarly \\(p\\vee q\\leq b\\). Thus, our interval is closed under both meet and join."}),Object(i.jsx)("p",{style:{textIndent:"0"},children:"We write \\(\\llbracket a,b\\rrbracket\\) to describe this lattice."}),Object(i.jsxs)("p",{children:["Similar to how we take a lattice and impose an ordering, we can take a poset and end up with a lattice by defining meet and join. In particular, we take","\\[\na\\wedge b=\\inf\\left\\{a,b\\right\\}\\qquad a\\vee b=\\sup\\left\\{a,b\\right\\}\n\\]","and verifying these satisfy the conditions for meet and join is straightforward. This all culminates into our final theorem, discussing the lattice"," ","\\((\\mathrm{Con}\\,\\mathcal{A},\\subseteq)\\)","."]}),Object(i.jsx)(k,{no:"10",name:"Correspondence Theorem",statement:"\r Let \\(\\mathcal{A}\\) be an algebra and let \\(\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}\\). Then,\r \\[\r \\llbracket\\sim,\\nabla_A\\rrbracket\\cong\\mathrm{Con}\\,\\mathcal{A}/\\!\\!\\sim\r \\]\r as lattices under \\(\\subseteq\\) by \\(r\\mapsto r/\\!\\!\\sim\\)"}),Object(i.jsx)(_,{proof:"\r Let \\(\\alpha\\) denote this mapping. Take some \\(r,s\\in[\\sim,\\nabla_A]\\) so that \\(r\\neq s\\). Without loss of generality, take some \\(a,b\\in A\\) so that \\((a,b)\\in r\\setminus s\\). This means \\((a/\\!\\!\\sim,b/\\!\\!\\sim)\\in r/\\!\\!\\sim\\!\\setminus\\, s/\\!\\!\\sim\\) meaning \\(\\alpha r\\neq\\alpha s\\).\\[\\]\r Now, take some congruence \\(r/\\!\\!\\sim\\,\\in\\mathrm{Con}\\,\\mathcal{A}/\\!\\!\\sim\\). Let \\(s=\\mathrm{ker}(\\nu_r\\circ\\nu_\\sim)\\). We see that \r \\[\r (a/\\!\\!\\sim,b/\\!\\!\\sim)\\in r/\\!\\!\\sim\\,\\Leftrightarrow (a,b)\\in s\\Leftrightarrow (a/\\!\\!\\sim,b/\\!\\!\\sim)\\in s/\\!\\!\\sim\r \\]\r meaning \\(\\alpha s=r\\). In total, our map is bijective.\\[\\]\r Now take \\(r,s\\in[\\sim,\\nabla_A]\\). Without loss of generality, take \\(s\\subseteq r\\). It is clear \\(s/\\!\\!\\sim\\,\\subseteq r/\\!\\!\\sim\\). Thus, \\(\\alpha\\) preserves inclusions, meaning it preserves our induced meet and join, and thus is a lattice homomorphism too."}),Object(i.jsx)("p",{children:"This took far longer than I thought it would. Going in, I assumed that everything would be fairly simple and clean, in the same way the proofs of the isomorphism theorems for specific structures are. However, given the variation between ideals and normal subgroups that I mentioned at the beginning, in hindsight I should have expected the overarching notion (i.e. congruences) to not necessarily be the friendliest or most familiar concept. Nonetheless, it is satisfying to have my curiosity quenched, even if it was slightly confusing at times."}),Object(i.jsx)("p",{children:"I have read that, apparently, universal algebra is pretty dead in terms of study today, supposedly having been subsumed into category theory. Although I find the hedonistic study of category theory to be quite sour, I will say that I find the category theory used in algebra to be more interesting and cleaner than universal algebra. It also far more powerful for identifying overarching ideas, whereas universal algebra limits itself to strictly algebra, by definition. However, I peeked into the end of Burris' and Sankappanavar's book and saw a large ampersand used as an operator over some set, so I am going to wager my freshman's opinion is quite ill-informed and there are deeper reasons the field is not very active today (if that's even true at all!)."})]})}}]),a}(n.Component),Z=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(d.a)(a,[{key:"componentDidMount",value:function(){window.KaTeXRender()}},{key:"render",value:function(){return Object(i.jsx)("div",{id:"KaTeXSec",className:"coDiv posts",children:Object(i.jsxs)("ul",{children:[Object(i.jsx)(v,{date:"2020-12-05",dummyID:"1",name:"Colouring Inside the Lines: the Jordan-Brouwer Separation Theorem.",summary:"I briefly discuss the Jordan curve theorem and how manifolds with boundary are used to state its generalization: the full separation theorem. I then introduce transversal intersections and homotopy in order to discuss some techniques used in the proof of theorem.",full:Object(i.jsx)(B,{})}),Object(i.jsx)(v,{date:"2020-08-09",dummyID:"2",name:"Learning All J\u014dy\u014d Kanji in a Month: A Reflection on and Criticism of Heisig's RTK",summary:"I share my experience with arguably the most controversial book related to learning Japanese, pointing out the flaws I personally noticed as well as the strengths, and summarize my experience overall. I then describe what I believe its best use-case is, so that you may decide for yourself whether it will be a suitable technique.",full:Object(i.jsx)(z,{})}),Object(i.jsx)(v,{date:"2020-08-01",dummyID:"3",name:"Universal Isomorphism Theorems",summary:'I discuss universal algebra, its motivation, and how it can be used to formulate the most general form of the isomorphism theorems found in group theory, ring theory, etc. I also bring up lattices, and how they can be used to also more generally prove the "fourth" isomorphism theorem: the correspondence theorem. ',full:Object(i.jsx)(H,{})}),Object(i.jsx)(v,{date:"",dummyID:"x",name:"Where's the rest?",summary:"I am still porting over posts from my old Wordpress blog, so not all of my content is here yet. However, it should be coming soon! Keep checking back."})]})})}}]),a}(n.Component),N=a(0),R=a(17),S=a.p+"static/media/camel.f5f93e62.jpg",D=window.innerHeight/100,J=function(e){Object(m.a)(a,e);var t=Object(u.a)(a);function a(){var e;Object(c.a)(this,a);for(var i=arguments.length,n=new Array(i),s=0;s<i;s++)n[s]=arguments[s];return(e=t.call.apply(t,[this].concat(n))).state={pfpAlt:"Me riding a camel in the Tottori sanddunes"},e}return Object(d.a)(a,[{key:"render",value:function(){return Object(i.jsxs)("div",{className:"coDiv contact",children:[Object(i.jsx)("table",{className:"contactHead",children:Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"contactMessage",children:Object(i.jsx)("h1",{children:"Thank you for reaching out!"})}),Object(i.jsx)("td",{className:"contactPhoto",children:Object(i.jsx)("img",{src:S,alt:this.state.pfpAlt})})]})}),Object(i.jsx)(N.b.Provider,{value:{color:"#4c2a6e",size:8*D},children:Object(i.jsxs)("table",{className:"contactInfo",children:[Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"https://www.instagram.com/kazachekalex/",children:Object(i.jsx)(R.b,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsxs)("a",{href:"https://www.instagram.com/kazachekalex/",children:[" ","@kazachekalex"," "]})}),Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"mailto: alexdkazachek@gmail.com",children:Object(i.jsx)(R.d,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsxs)("a",{href:"mailto: alexdkazachek@gmail.com",children:[" ","alexdkazachek@gmail.com"," "]})})]}),Object(i.jsxs)("tr",{children:[Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"https://github.com/akazachek",children:Object(i.jsx)(R.a,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsx)("a",{href:"https://github.com/akazachek",children:" akazachek "})}),Object(i.jsx)("td",{className:"handleIcon",children:Object(i.jsx)("a",{href:"https://linkedin.com/in/kazachek",children:Object(i.jsx)(R.c,{})})}),Object(i.jsx)("td",{className:"handle",children:Object(i.jsx)("a",{href:"https://linkedin.com/in/kazachek",children:" kazachek "})})]})]})})]})}}]),a}(n.Component);var L=function(){return Object(i.jsx)(h.a,{children:Object(i.jsxs)("div",{className:"App",children:[Object(i.jsx)(f,{}),Object(i.jsx)(l.a,{exact:!0,path:"/",children:Object(i.jsx)(j,{})}),Object(i.jsx)(l.a,{path:"/Posts",children:Object(i.jsx)(Z,{})}),Object(i.jsx)(l.a,{path:"/Contact",children:Object(i.jsx)(J,{})})]})})},Y=function(e){e&&e instanceof Function&&a.e(3).then(a.bind(null,43)).then((function(t){var a=t.getCLS,i=t.getFID,n=t.getFCP,s=t.getLCP,o=t.getTTFB;a(e),i(e),n(e),s(e),o(e)}))};r.a.render(Object(i.jsx)(s.a.StrictMode,{children:Object(i.jsx)(L,{})}),document.getElementById("root")),Y()}},[[42,1,2]]]);
//# sourceMappingURL=main.cd2435c3.chunk.js.map